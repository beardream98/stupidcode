{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f10dbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: TqdmExperimentalWarning:\n",
      "\n",
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from textblob import TextBlob\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner'])\n",
    "nlp.max_length = 4000000\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "import string\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe82feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./input/train.csv')\n",
    "sample_sub = pd.read_csv('./input/sample_submission.csv')\n",
    "train_files_path = './input/train'\n",
    "test_files_path = './input/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "292270b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取json文件 返回text数据 添加到dataframe中\n",
    "def read_append_return(filename, train_files_path=train_files_path, output='text'):\n",
    "    \"\"\"\n",
    "    Function to read json file and then return the text data from them and append to the dataframe\n",
    "    \"\"\"\n",
    "    json_path = os.path.join(train_files_path, (filename+'.json'))\n",
    "    headings = []\n",
    "    contents = []\n",
    "    combined = []\n",
    "    with open(json_path, 'r') as f:\n",
    "        json_decode = json.load(f)\n",
    "        for data in json_decode:\n",
    "            headings.append(data.get('section_title'))\n",
    "            contents.append(data.get('text'))\n",
    "            combined.append(data.get('section_title'))\n",
    "            combined.append(data.get('text'))\n",
    "    \n",
    "    all_headings = ' '.join(headings)\n",
    "    all_contents = ' '.join(contents)\n",
    "    all_data = '. '.join(combined)\n",
    "    \n",
    "    if output == 'text':\n",
    "        return all_contents\n",
    "    elif output == 'head':\n",
    "        return all_headings\n",
    "    else:\n",
    "        return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655aa509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe41959bfed449f1a902966c1b18ed61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "tqdm.pandas()\n",
    "train_df['text'] = train_df['Id'].progress_apply(read_append_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fba4c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dec26ba4c0540e6ae8432078d917a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 199 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tqdm.pandas()\n",
    "sample_sub['text'] = sample_sub['Id'].progress_apply(partial(read_append_return, train_files_path=test_files_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a4bb18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'pub_title', 'dataset_title', 'dataset_label', 'cleaned_label',\n",
       "       'text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4ce0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_df[\"dataset_label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee159c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import CRF   # CRF的具体实现太过复杂，这里我们借助一个外部的库\n",
    "\n",
    "\n",
    "def word2features(sent, i):\n",
    "    \"\"\"抽取单个字的特征\"\"\"\n",
    "    word = sent[i]\n",
    "    prev_word = \"<s>\" if i == 0 else sent[i-1]\n",
    "    next_word = \"</s>\" if i == (len(sent)-1) else sent[i+1]\n",
    "    # 因为每个词相邻的词会影响这个词的标记\n",
    "    # 所以我们使用：\n",
    "    # 前一个词，当前词，后一个词，\n",
    "    # 前一个词+当前词， 当前词+后一个词\n",
    "    # 作为特征\n",
    "    features = {\n",
    "        'w': word,\n",
    "        'w-1': prev_word,\n",
    "        'w+1': next_word,\n",
    "        'w-1:w': prev_word+word,\n",
    "        'w:w+1': word+next_word,\n",
    "        'bias': 1\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    \"\"\"抽取序列特征\"\"\"\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "class CRFModel(object):\n",
    "    def __init__(self,\n",
    "                 algorithm='lbfgs',\n",
    "                 c1=0.1,\n",
    "                 c2=0.1,\n",
    "                 max_iterations=100,\n",
    "                 all_possible_transitions=False\n",
    "                 ):\n",
    "\n",
    "        self.model = CRF(algorithm=algorithm,\n",
    "                         c1=c1,\n",
    "                         c2=c2,\n",
    "                         max_iterations=max_iterations,\n",
    "                         all_possible_transitions=all_possible_transitions)\n",
    "\n",
    "    def train(self, sentences, tag_lists):\n",
    "        \"\"\"训练模型\"\"\"\n",
    "        features = [sent2features(s) for s in sentences]\n",
    "        self.model.fit(features, tag_lists)\n",
    "\n",
    "    def test(self, sentences):\n",
    "        \"\"\"解码,对给定句子预测其标注\"\"\"\n",
    "        features = [sent2features(s) for s in sentences]\n",
    "        pred_tag_lists = self.model.predict(features)\n",
    "        return pred_tag_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa255fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0d65d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python36] *",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
