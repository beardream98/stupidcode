{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-18T00:56:43.811643Z","iopub.execute_input":"2022-01-18T00:56:43.812326Z","iopub.status.idle":"2022-01-18T00:56:43.816508Z","shell.execute_reply.started":"2022-01-18T00:56:43.812288Z","shell.execute_reply":"2022-01-18T00:56:43.815533Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport random\nimport time\n\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, logging\nfrom transformers import BertConfig, BertTokenizer, BertModel\nfrom transformers import AlbertConfig, AlbertTokenizer, AlbertModel\nfrom transformers import RobertaConfig,RobertaTokenizer, RobertaModel\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, TensorDataset, SequentialSampler, RandomSampler, DataLoader\n\nfrom tqdm.notebook import tqdm\n\nimport gc; gc.enable()\nfrom IPython.display import clear_output\n\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('whitegrid')\nlogging.set_verbosity_error()","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:44.533802Z","iopub.execute_input":"2022-01-18T00:56:44.534159Z","iopub.status.idle":"2022-01-18T00:56:44.547553Z","shell.execute_reply.started":"2022-01-18T00:56:44.534118Z","shell.execute_reply":"2022-01-18T00:56:44.546773Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"CONFIG={\n    \"TRAIN_BATCH_SIZE\":32,\n    \"MAX_LENGTH\":128,\n    \"DEV_BATCH_SIZE\": 64,\n    \"LR\":3.6e-6,\n    \"EPS\":1e-8,\n    \"weight_decay\":1e-6,\n    \n    \"scheduler\": 'CosineAnnealingLR',\n    \"min_lr\": 1e-6,\n    \"T_max\": 500,\n    \"T_0\":500,\n    \"margin\":0.5,\n    \"fold_num\":5,\n    \"seed\":2021,\n    \"num_class\":1,\n    \n    \"EPOCHS\":4,\n    \"evaluate_step\":None,\n    \"swa_start\":3,\n    \"model_init_lr\":3.5e-6,\n    \"multiplier\":0.9,\n    \"classifier_lr\":3.6e-6 ,\n    \"swa_lr\": 1e-5\n}\n\ninput_dir=\"../input/jigsaw-toxic-severity-rating\"","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:44.859633Z","iopub.execute_input":"2022-01-18T00:56:44.859982Z","iopub.status.idle":"2022-01-18T00:56:44.867291Z","shell.execute_reply.started":"2022-01-18T00:56:44.859944Z","shell.execute_reply":"2022-01-18T00:56:44.866561Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"#检查事项\n1. model_struct 如果需要更换模型检查更换结构部分  \n2.更新model path来源版本\n3.如果是来自firefox的更换 modelpaths\n4.fold是否正确 ","metadata":{}},{"cell_type":"code","source":"#OriginModel MeanPoolingModel LastLayerCLSModel MaxPoolingModel\n#SecondToLastLayerCLSModel ConcatenateLastFourModel WeightedLayerPoolingModel WeightedLayerPoolingModel\n#AttentionPoolingModel\nmodel_struct=\"OriginModel\"\n\n# MODEL_PATHS=[f\"../input/baseline1-toxic-value/bestmodel-{num}.pth\" for num in range(CONFIG[\"fold_num\"])]\nMODEL_PATHS=[f\"../input/jigsawserver/bestmodel-{num}.pth\" for num in range(CONFIG[\"fold_num\"])]\n\n# MODEL_PATHS=[f\"../input/bert-from-firefox/bestmodel-{num}.pth\" for num in range(CONFIG[\"fold_num\"])]","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:45.476164Z","iopub.execute_input":"2022-01-18T00:56:45.476424Z","iopub.status.idle":"2022-01-18T00:56:45.481057Z","shell.execute_reply.started":"2022-01-18T00:56:45.476394Z","shell.execute_reply":"2022-01-18T00:56:45.480078Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"更换模型","metadata":{}},{"cell_type":"code","source":"hidden_size=\"hidden_size\"\nnum_hidden_layers=\"num_hidden_layers\"\n#for xlnet\n# hidden_size=\"d_model\"\n# num_hidden_layers=\"n_layer\"\n\n# MODEL_DIR=\"../input/roberta-transformers-pytorch/roberta-base\"\n# MODEL_DIR=\"../input/roberta-transformers-pytorch/roberta-large\"\nMODEL_DIR=\"../input/pretrained-albert-pytorch/albert-xlarge-v2\"\n# MODEL_DIR=\"../input/transformers/xlnet-base-cased\"\n# MODEL_DIR=\"../input/hatebert/hateBERT\"\n\nModel_type=\"Albert\"\ntokenizer_func_dict={\"Albert\":AlbertTokenizer,\"auto\":AutoTokenizer,\"Roberta\":RobertaTokenizer}\nconfig_func_dict={\"Albert\":AlbertConfig,\"auto\":AutoConfig,\"Roberta\":RobertaConfig}\nmodel_func_dict={\"Albert\":AlbertModel,\"auto\":AutoModel,\"Roberta\":RobertaModel}\n","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:46.020251Z","iopub.execute_input":"2022-01-18T00:56:46.020969Z","iopub.status.idle":"2022-01-18T00:56:46.026564Z","shell.execute_reply.started":"2022-01-18T00:56:46.020929Z","shell.execute_reply":"2022-01-18T00:56:46.025529Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH=128\nTRAIN_BATCH_SIZE = 32\nDEV_BATCH_SIZE = 64\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:46.355445Z","iopub.execute_input":"2022-01-18T00:56:46.355696Z","iopub.status.idle":"2022-01-18T00:56:46.407578Z","shell.execute_reply.started":"2022-01-18T00:56:46.355667Z","shell.execute_reply":"2022-01-18T00:56:46.406745Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data_df=pd.read_csv(os.path.join(input_dir,\"comments_to_score.csv\"))\ndata_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:46.756859Z","iopub.execute_input":"2022-01-18T00:56:46.757504Z","iopub.status.idle":"2022-01-18T00:56:46.887074Z","shell.execute_reply.started":"2022-01-18T00:56:46.757465Z","shell.execute_reply":"2022-01-18T00:56:46.886371Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class DatasetRetriever(Dataset):\n    def __init__(self,data,tokenizer,max_len=MAX_LENGTH):\n        self.data=data\n        self.tokenizer=tokenizer\n        self.max_len=max_len\n        self.text=self.data[\"text\"].values\n        \n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, item):\n        text=self.text[item]\n\n        features1=self.convert_examples_to_features(text)\n         ##roberta 没有tokentype ids 为了统一这里也不进行输入 反正训练也用不着\n        features1={\"input_ids\":features1[\"input_ids\"],\"attention_mask\":features1[\"attention_mask\"]}\n        return {\"text\":{key:torch.tensor(value,dtype=torch.long) for key,value in features1.items()}}\n    def convert_examples_to_features(self, example):\n        encoded = self.tokenizer.encode_plus(\n            example,\n            add_special_tokens=True,\n            padding=\"max_length\",\n            truncation=True,\n            max_length=self.max_len,\n            is_split_into_words=False,\n            )\n        return encoded\ndef make_dataloader(data,batch_size,model_dir=MODEL_DIR,max_len=MAX_LENGTH):\n    \n    tokenizer=tokenizer_func_dict.get(Model_type).from_pretrained(model_dir)\n    dataset=DatasetRetriever(data,tokenizer,max_len)\n    sampler=SequentialSampler(dataset)\n    \n    dataloader=DataLoader(dataset,\n                          batch_size=batch_size,\n                          sampler=sampler\n                         )\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:47.116014Z","iopub.execute_input":"2022-01-18T00:56:47.116769Z","iopub.status.idle":"2022-01-18T00:56:47.126760Z","shell.execute_reply.started":"2022-01-18T00:56:47.116722Z","shell.execute_reply":"2022-01-18T00:56:47.125913Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test_loader=make_dataloader(data_df,DEV_BATCH_SIZE,MODEL_DIR,MAX_LENGTH)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:47.633074Z","iopub.execute_input":"2022-01-18T00:56:47.633577Z","iopub.status.idle":"2022-01-18T00:56:47.731883Z","shell.execute_reply.started":"2022-01-18T00:56:47.633538Z","shell.execute_reply":"2022-01-18T00:56:47.731154Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class OriginModel(nn.Module):\n    def __init__(self,model_name):\n        super(OriginModel,self).__init__()\n\n        self.model=model_func_dict.get(Model_type).from_pretrained(model_name)\n#         AutoModel.from_pretrained(model_name)\n        self.drop=nn.Dropout(p=0.2)\n        self.config=config_func_dict.get(Model_type).from_pretrained(model_name)\n#         self.config=AutoConfig.from_pretrained(model_name)\n        self.linear=nn.Linear(self.config.to_dict()[hidden_size],CONFIG[\"num_class\"])\n        \n        self.dense = nn.Linear(self.config.to_dict()[hidden_size], self.config.to_dict()[hidden_size])\n        self.activation = nn.Tanh()\n    def forward(self,input_ids,attention_mask):\n        out=self.model(input_ids=input_ids,attention_mask=attention_mask,output_hidden_states=False)\n        last_hidden_state = out[0]\n        cls_embeddings = last_hidden_state[:,0]\n        pooled_output = self.dense(cls_embeddings)\n        pooled_output = self.activation(pooled_output)\n        \n        out=self.drop(pooled_output)\n        \n        outputs=self.linear(out)\n        \n        return outputs","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:48.276524Z","iopub.execute_input":"2022-01-18T00:56:48.276794Z","iopub.status.idle":"2022-01-18T00:56:48.285354Z","shell.execute_reply.started":"2022-01-18T00:56:48.276764Z","shell.execute_reply":"2022-01-18T00:56:48.284712Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def evaluate(model,test_dataloader):\n    model.eval()\n    Preds=[]\n    for index,batch in enumerate(test_dataloader):\n\n        text_inputs=batch[\"text\"]\n        \n        text_inputs={key: value.to(DEVICE) for key,value in text_inputs.items()}\n        with torch.no_grad():\n            out_more=model(**text_inputs)\n            Preds.append(out_more.view(-1).cpu().detach().numpy())\n    \n    Preds = np.concatenate(Preds) \n    gc.collect()\n    \n    return Preds\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:48.804406Z","iopub.execute_input":"2022-01-18T00:56:48.804985Z","iopub.status.idle":"2022-01-18T00:56:48.810977Z","shell.execute_reply.started":"2022-01-18T00:56:48.804945Z","shell.execute_reply":"2022-01-18T00:56:48.810057Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"func_dict={\"OriginModel\":OriginModel}\nJigsawModel=func_dict.get(model_struct)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:49.317250Z","iopub.execute_input":"2022-01-18T00:56:49.317943Z","iopub.status.idle":"2022-01-18T00:56:49.323565Z","shell.execute_reply.started":"2022-01-18T00:56:49.317898Z","shell.execute_reply":"2022-01-18T00:56:49.322694Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def inference(model_paths, dataloader):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JigsawModel(MODEL_DIR)\n        model.to(DEVICE)\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = evaluate(model, dataloader)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    return final_preds","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:53.836153Z","iopub.execute_input":"2022-01-18T00:56:53.836406Z","iopub.status.idle":"2022-01-18T00:56:53.842233Z","shell.execute_reply.started":"2022-01-18T00:56:53.836377Z","shell.execute_reply":"2022-01-18T00:56:53.841582Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"preds = inference(MODEL_PATHS, test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:56:55.069263Z","iopub.execute_input":"2022-01-18T00:56:55.069884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df['score'] = preds\ndata_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df['score'] = data_df['score'].rank(method='first')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df.drop('text', axis=1, inplace=True)\ndata_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}