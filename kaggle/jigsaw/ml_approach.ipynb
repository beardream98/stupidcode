{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d8dd64",
   "metadata": {
    "papermill": {
     "duration": 0.023768,
     "end_time": "2021-12-22T05:15:11.509759",
     "exception": false,
     "start_time": "2021-12-22T05:15:11.485991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f03dce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:15:11.559196Z",
     "iopub.status.busy": "2021-12-22T05:15:11.558573Z",
     "iopub.status.idle": "2021-12-22T05:15:13.862109Z",
     "shell.execute_reply": "2021-12-22T05:15:13.861319Z",
     "shell.execute_reply.started": "2021-12-22T04:03:38.840252Z"
    },
    "papermill": {
     "duration": 2.331896,
     "end_time": "2021-12-22T05:15:13.862275",
     "exception": false,
     "start_time": "2021-12-22T05:15:11.530379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import scipy.optimize as optimize\n",
    "import lightgbm as lgb\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import re \n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import gc \n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ff92c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:15:13.908869Z",
     "iopub.status.busy": "2021-12-22T05:15:13.908164Z",
     "iopub.status.idle": "2021-12-22T05:15:13.909553Z",
     "shell.execute_reply": "2021-12-22T05:15:13.910025Z",
     "shell.execute_reply.started": "2021-12-22T04:03:39.121796Z"
    },
    "papermill": {
     "duration": 0.026959,
     "end_time": "2021-12-22T05:15:13.910199",
     "exception": false,
     "start_time": "2021-12-22T05:15:13.883240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1 means kf 2 means sample\n",
    "Fold_type=2\n",
    "is_test=False\n",
    "translate_aug=False\n",
    "#记得改kdict 里面的tranlate的值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140f657b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:15:13.953895Z",
     "iopub.status.busy": "2021-12-22T05:15:13.953247Z",
     "iopub.status.idle": "2021-12-22T05:15:13.956182Z",
     "shell.execute_reply": "2021-12-22T05:15:13.956653Z",
     "shell.execute_reply.started": "2021-12-22T04:03:39.388393Z"
    },
    "papermill": {
     "duration": 0.026132,
     "end_time": "2021-12-22T05:15:13.956841",
     "exception": false,
     "start_time": "2021-12-22T05:15:13.930709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fold_num_k=5\n",
    "fold_num_s=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9046030e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:15:14.002511Z",
     "iopub.status.busy": "2021-12-22T05:15:14.001856Z",
     "iopub.status.idle": "2021-12-22T05:15:14.005343Z",
     "shell.execute_reply": "2021-12-22T05:15:14.004850Z",
     "shell.execute_reply.started": "2021-12-22T04:03:39.631572Z"
    },
    "papermill": {
     "duration": 0.028216,
     "end_time": "2021-12-22T05:15:14.005493",
     "exception": false,
     "start_time": "2021-12-22T05:15:13.977277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_names=[\"jc_\",\"juc_\",\"rud_\",\"jcc_\"]\n",
    "# model_choice=[\"ridge\",\"gbm\"]\n",
    "# factor=[0.5,0.5]\n",
    "\n",
    "data_names=[\"jcc_\"]\n",
    "translate_data=[\"jc_\"]\n",
    "\n",
    "model_choice=[\"ridge\"]\n",
    "factor=[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb815741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:15:14.051942Z",
     "iopub.status.busy": "2021-12-22T05:15:14.051178Z",
     "iopub.status.idle": "2021-12-22T05:15:14.054569Z",
     "shell.execute_reply": "2021-12-22T05:15:14.054071Z",
     "shell.execute_reply.started": "2021-12-22T04:03:39.898937Z"
    },
    "papermill": {
     "duration": 0.028241,
     "end_time": "2021-12-22T05:15:14.054756",
     "exception": false,
     "start_time": "2021-12-22T05:15:14.026515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_path=r\"C:\\Users\\Lenovo\\Desktop\\stupidcode\\data\\jigsaw\"\n",
    "# model_all=[\"ridge\",\"gbm\"]\n",
    "# for model_name in model_all:\n",
    "#     if model_name not in os.listdir():\n",
    "#         os.makedirs(f\"{model_name}\")\n",
    "out_path=r\"C:\\Users\\Lenovo\\Desktop\\stupidcode\\data\\jigsaw\\save_model\\temp_work_save\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d772abc",
   "metadata": {
    "papermill": {
     "duration": 0.020086,
     "end_time": "2021-12-22T05:15:14.095813",
     "exception": false,
     "start_time": "2021-12-22T05:15:14.075727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52660482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:15:14.143447Z",
     "iopub.status.busy": "2021-12-22T05:15:14.142781Z",
     "iopub.status.idle": "2021-12-22T05:15:14.145116Z",
     "shell.execute_reply": "2021-12-22T05:15:14.145665Z",
     "shell.execute_reply.started": "2021-12-22T04:03:40.951976Z"
    },
    "papermill": {
     "duration": 0.02962,
     "end_time": "2021-12-22T05:15:14.145854",
     "exception": false,
     "start_time": "2021-12-22T05:15:14.116234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#第一届 jigsaw比赛 数据（challenge） Toxic Comment Classification Challenge\n",
    "\n",
    "jc_path=os.path.join(system_path,\"jigsaw-toxic-comment-classification-challenge\")\n",
    "jc_trans_path=os.path.join(system_path,\"jigsaw-toxic-comment-classification-challenge\")\n",
    "#ruddit 数据\n",
    "run_path=os.path.join(system_path,\"ruddit-jigsaw-dataset/Dataset\")\n",
    "#第二届 jigsaw比赛 对少数人群不歧视\n",
    "juc_path=os.path.join(system_path,\"jigsaw-unintended-bias-in-toxicity-classification\")\n",
    "\n",
    "#本次比赛数据 作为val\n",
    "jts_path=os.path.join(system_path,\"jigsaw-toxic-severity-rating\")\n",
    "\n",
    "# #数据抽样存储路径\n",
    "gbm_save_path=os.path.join(out_path,\"gbm\")\n",
    "ridge_save_path=os.path.join(out_path,\"ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c5a66c",
   "metadata": {
    "papermill": {
     "duration": 0.019956,
     "end_time": "2021-12-22T05:15:14.186343",
     "exception": false,
     "start_time": "2021-12-22T05:15:14.166387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee2d18d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:15:14.230629Z",
     "iopub.status.busy": "2021-12-22T05:15:14.229959Z",
     "iopub.status.idle": "2021-12-22T05:15:14.842815Z",
     "shell.execute_reply": "2021-12-22T05:15:14.843292Z",
     "shell.execute_reply.started": "2021-12-22T04:03:41.782181Z"
    },
    "papermill": {
     "duration": 0.636998,
     "end_time": "2021-12-22T05:15:14.843485",
     "exception": false,
     "start_time": "2021-12-22T05:15:14.206487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#验证集和测试集\n",
    "df_val = pd.read_csv(os.path.join(jts_path,\"validation_data.csv\"))\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(jts_path,\"comments_to_score.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "770e87f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:15:14.889625Z",
     "iopub.status.busy": "2021-12-22T05:15:14.889031Z",
     "iopub.status.idle": "2021-12-22T05:15:16.722134Z",
     "shell.execute_reply": "2021-12-22T05:15:16.721399Z",
     "shell.execute_reply.started": "2021-12-22T04:03:42.572509Z"
    },
    "papermill": {
     "duration": 1.856382,
     "end_time": "2021-12-22T05:15:16.722344",
     "exception": false,
     "start_time": "2021-12-22T05:15:14.865962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments with toxic behaviour:16225\n"
     ]
    }
   ],
   "source": [
    "#第一届比赛数据 以0/1为分值 \n",
    "features = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "jc_train_df = pd.read_csv(os.path.join(jc_path,\"train.csv\"))\n",
    "# jc_test_df = pd.read_csv(os.path.join(jc_path,\"test.csv\"))\n",
    "# temp_df = pd.read_csv(os.path.join(jc_path,\"test_labels.csv\"))\n",
    "\n",
    "# jc_test_df = jc_test_df.merge ( temp_df, on =\"id\")\n",
    "# #drop test data not used for scoring\n",
    "# jc_test_df = jc_test_df.query (\"toxic != -1\")\n",
    "# jc_df = jc_train_df.append ( jc_test_df ) \n",
    "\n",
    "# print(f\"Train+Test:{jc_df.shape[0]}\")\n",
    "\n",
    "jc_df=jc_train_df\n",
    "\n",
    "# 将代表有毒行为的筛选出来\n",
    "jc_df[\"toxic_subtype_sum\"]=jc_df[features].sum(axis=1)\n",
    "jc_df[\"toxic_behaviour\"]=jc_df[\"toxic_subtype_sum\"].map(lambda x: x > 0)\n",
    "\n",
    "tot_toxic_behaviour = jc_df[\"toxic_behaviour\"].sum()\n",
    "print(f'comments with toxic behaviour:{tot_toxic_behaviour}')\n",
    "jc_df=jc_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fc6eaf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:15:16.775270Z",
     "iopub.status.busy": "2021-12-22T05:15:16.774159Z",
     "iopub.status.idle": "2021-12-22T05:15:16.814630Z",
     "shell.execute_reply": "2021-12-22T05:15:16.813997Z",
     "shell.execute_reply.started": "2021-12-22T04:03:44.85389Z"
    },
    "papermill": {
     "duration": 0.070779,
     "end_time": "2021-12-22T05:15:16.814788",
     "exception": false,
     "start_time": "2021-12-22T05:15:16.744009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第一届比赛 数据预处理\n",
    "# toxic = 1.0\n",
    "# severe_toxic = 2.0\n",
    "# obscene = 1.0\n",
    "# threat = 1.0\n",
    "# insult = 1.0\n",
    "# identity_hate = 2.0\n",
    "toxic = 0.32\n",
    "severe_toxic = 1.5\n",
    "obscene = 0.16\n",
    "threat = 1.5\n",
    "insult = 0.64\n",
    "identity_hate = 1.5\n",
    "\n",
    "def create_train (df):\n",
    "#     df['y'] = df[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]].max(axis=1)\n",
    "    df['y'] = df['toxic']*toxic\n",
    "    df['y'] = df[\"y\"]+df['severe_toxic']*severe_toxic\n",
    "    df['y'] = df[\"y\"]+df['obscene']*obscene\n",
    "    df['y'] = df[\"y\"]+df['threat']*threat\n",
    "    df['y'] = df[\"y\"]+df['insult']*insult\n",
    "    df['y'] = df[\"y\"]+df['identity_hate']*identity_hate\n",
    "    \n",
    "    df = df[[\"id\",'comment_text', 'y', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].rename(columns={'comment_text': 'text'})\n",
    "    return df\n",
    "        \n",
    "jc_df = create_train (jc_df)\n",
    "jc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ca587a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:15:16.917618Z",
     "iopub.status.busy": "2021-12-22T05:15:16.917000Z",
     "iopub.status.idle": "2021-12-22T05:15:52.403441Z",
     "shell.execute_reply": "2021-12-22T05:15:52.402742Z",
     "shell.execute_reply.started": "2021-12-22T04:03:44.932972Z"
    },
    "papermill": {
     "duration": 35.510285,
     "end_time": "2021-12-22T05:15:52.403613",
     "exception": false,
     "start_time": "2021-12-22T05:15:16.893328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juc_df:(601044, 46)\n"
     ]
    }
   ],
   "source": [
    "# 第二届比赛 以打分形式0~1\n",
    "features = [\"toxicity\",\"severe_toxicity\",\"obscene\",\"insult\",\"identity_attack\", \"sexual_explicit\"]\n",
    "cols = ['id', 'comment_text', 'toxicity', 'severe_toxicity', 'obscene', 'threat','insult', 'identity_attack', 'sexual_explicit', 'toxicity_annotator_count']\n",
    "\n",
    "juc_df = pd.read_csv(os.path.join(juc_path,\"all_data.csv\"))\n",
    "\n",
    "juc_df = juc_df.query (\"toxicity_annotator_count > 5\")\n",
    "print(f\"juc_df:{juc_df.shape}\")\n",
    "juc_df['y'] = juc_df[[ 'severe_toxicity', 'obscene', 'sexual_explicit','identity_attack', 'insult', 'threat']].sum(axis=1)\n",
    "\n",
    "#毒性<0.5 按标注 否则算所有有毒行为的标注和\n",
    "juc_df['y'] = juc_df.apply(lambda row: row[\"toxicity\"] if row[\"toxicity\"] <= 0.5 else row[\"y\"] , axis=1)\n",
    "juc_df = juc_df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\n",
    "# min_len = (juc_df['y'] > 0.5).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e9f92d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:15:52.450774Z",
     "iopub.status.busy": "2021-12-22T05:15:52.449775Z",
     "iopub.status.idle": "2021-12-22T05:15:52.524990Z",
     "shell.execute_reply": "2021-12-22T05:15:52.525502Z",
     "shell.execute_reply.started": "2021-12-22T04:04:31.005106Z"
    },
    "papermill": {
     "duration": 0.100296,
     "end_time": "2021-12-22T05:15:52.525707",
     "exception": false,
     "start_time": "2021-12-22T05:15:52.425411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rud_df:(5838, 5)\n"
     ]
    }
   ],
   "source": [
    "#ruddit 数据\n",
    "rud_df = pd.read_csv(os.path.join(run_path,\"ruddit_with_text.csv\"))\n",
    "\n",
    "print(f\"rud_df:{rud_df.shape}\")\n",
    "rud_df['y'] = rud_df['offensiveness_score'].map(lambda x: 0.0 if x <=0 else x)\n",
    "rud_df = rud_df[['txt', 'y']].rename(columns={'txt': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce889cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:15:52.574846Z",
     "iopub.status.busy": "2021-12-22T05:15:52.573807Z",
     "iopub.status.idle": "2021-12-22T05:16:44.304183Z",
     "shell.execute_reply": "2021-12-22T05:16:44.304714Z",
     "shell.execute_reply.started": "2021-12-22T04:04:31.094069Z"
    },
    "papermill": {
     "duration": 51.756682,
     "end_time": "2021-12-22T05:16:44.304888",
     "exception": false,
     "start_time": "2021-12-22T05:15:52.548206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 159571/159571 [01:02<00:00, 2537.52it/s]\n"
     ]
    }
   ],
   "source": [
    "#clean data\n",
    "def clean(data, col):\n",
    "    #数据清洗 \n",
    "    \n",
    "    # Clean some punctutations\n",
    "    data[col] = data[col].str.replace('\\n', ' \\n ')\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n",
    "    # Replace repeating characters more than 3 times to length of 3\n",
    "    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')    \n",
    "    # Add space around repeating characters\n",
    "    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ')    \n",
    "    # patterns with repeating characters \n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n",
    "    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n",
    "    \n",
    "    return data\n",
    "\n",
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form for NLP. Operations include the following:-\n",
    "    1. Remove special charecters like &, #, etc\n",
    "    2. Removes extra spaces\n",
    "    3. Removes embedded URL links\n",
    "    4. Removes HTML tags\n",
    "    5. Removes emojis\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text\n",
    "\n",
    "#第一届大赛 clean 数据\n",
    "# jcc_df=clean(jc_df,\"text\")\n",
    "\n",
    "tqdm.pandas()\n",
    "jcc_df=jc_df.copy()\n",
    "# jcc_df['text'] = jcc_df.apply(lambda row:text_cleaning(row[\"text\"]),axis=1)\n",
    "\n",
    "jcc_df['text']=jcc_df['text'].progress_apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0f923fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:16:44.645953Z",
     "iopub.status.busy": "2021-12-22T05:16:44.645268Z",
     "iopub.status.idle": "2021-12-22T05:16:44.659339Z",
     "shell.execute_reply": "2021-12-22T05:16:44.659840Z",
     "shell.execute_reply.started": "2021-12-22T04:05:36.794167Z"
    },
    "papermill": {
     "duration": 0.157849,
     "end_time": "2021-12-22T05:16:44.660030",
     "exception": false,
     "start_time": "2021-12-22T05:16:44.502181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D aww He matches this background colour I m se...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>More I can t make any real suggestions on impr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                               text    y  \\\n",
       "0  0000997932d777bf  Explanation Why the edits made under my userna...  0.0   \n",
       "1  000103f0d9cfb60f  D aww He matches this background colour I m se...  0.0   \n",
       "2  000113f07ec002fd  Hey man I m really not trying to edit war It s...  0.0   \n",
       "3  0001b41b1c6bb37e  More I can t make any real suggestions on impr...  0.0   \n",
       "4  0001d958c54c6e35  You sir are my hero Any chance you remember wh...  0.0   \n",
       "\n",
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0      0             0        0       0       0              0  \n",
       "1      0             0        0       0       0              0  \n",
       "2      0             0        0       0       0              0  \n",
       "3      0             0        0       0       0              0  \n",
       "4      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jcc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb243875",
   "metadata": {
    "papermill": {
     "duration": 0.136553,
     "end_time": "2021-12-22T05:16:44.937126",
     "exception": false,
     "start_time": "2021-12-22T05:16:44.800573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 消重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5afb378",
   "metadata": {
    "papermill": {
     "duration": 0.13767,
     "end_time": "2021-12-22T05:16:45.495936",
     "exception": false,
     "start_time": "2021-12-22T05:16:45.358266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 去关键字"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09454787",
   "metadata": {
    "papermill": {
     "duration": 0.13594,
     "end_time": "2021-12-22T05:16:46.052486",
     "exception": false,
     "start_time": "2021-12-22T05:16:45.916546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### aug_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bada83d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:16:46.327438Z",
     "iopub.status.busy": "2021-12-22T05:16:46.326855Z",
     "iopub.status.idle": "2021-12-22T05:16:46.332060Z",
     "shell.execute_reply": "2021-12-22T05:16:46.332553Z",
     "shell.execute_reply.started": "2021-12-22T04:05:36.849876Z"
    },
    "papermill": {
     "duration": 0.143822,
     "end_time": "2021-12-22T05:16:46.332761",
     "exception": false,
     "start_time": "2021-12-22T05:16:46.188939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if translate_aug==True:\n",
    "    jc_trans=pd.read_csv(os.path.join(jc_trans_path,\"jc_trans.csv\"))\n",
    "    jc_trans.set_index([\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "    jc_df=pd.merge(jc_df,jc_trans[[\"id\",\"fr_text\"]],on=\"id\",how=\"left\")\n",
    "    jc_df=pd.merge(jc_df,jc_trans[[\"id\",\"es_text\"]],on=\"id\",how=\"left\")\n",
    "    jc_df=pd.merge(jc_df,jc_trans[[\"id\",\"de_text\"]],on=\"id\",how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ceb877",
   "metadata": {
    "papermill": {
     "duration": 0.136987,
     "end_time": "2021-12-22T05:16:46.607258",
     "exception": false,
     "start_time": "2021-12-22T05:16:46.470271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# create fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a7dd740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:16:46.883633Z",
     "iopub.status.busy": "2021-12-22T05:16:46.882999Z",
     "iopub.status.idle": "2021-12-22T05:16:46.893467Z",
     "shell.execute_reply": "2021-12-22T05:16:46.894003Z",
     "shell.execute_reply.started": "2021-12-22T04:05:36.865903Z"
    },
    "papermill": {
     "duration": 0.150216,
     "end_time": "2021-12-22T05:16:46.894183",
     "exception": false,
     "start_time": "2021-12-22T05:16:46.743967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fold_kfold(df,FOLDS=5,select_num=0.5,frac_1=1.5,balance=False):\n",
    "    #select num challenge:1 unbias:0.5  \n",
    "\n",
    "    min_len = (df['y'] >= select_num).sum()\n",
    "    if balance==False:\n",
    "        #采样负样本\n",
    "        df_y0_undersample = df[df['y'] <select_num].sample(n=int(min_len*frac_1),random_state=201)\n",
    "        df = pd.concat([df[-(df['y'] <select_num)], df_y0_undersample])\n",
    "        df=df.reset_index(drop=True)\n",
    "    y=df[\"y\"].values\n",
    "    x=df[\"text\"]\n",
    "    stratified = np.around (y)\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=FOLDS,shuffle=True,random_state=123)\n",
    "    df_dict={}\n",
    "    for fold,(train_index,val_index) in enumerate(kf.split(x,stratified)):\n",
    "        df_train=df.iloc[train_index]\n",
    "        df_dict[fold]=df_train\n",
    "    \n",
    "    return df_dict\n",
    "\n",
    "def create_fold_sample(df,n_folds=3,frac_1=0.8,frac_1_factor=1.5,select_num=0,balance=False,translate=False):\n",
    "    df_dict={}\n",
    "    #正样本 大于等于select_num\n",
    "    select_list=-(df['y'] <select_num)\n",
    "    min_len=select_list.sum()\n",
    "    if translate==True:\n",
    "        min_len=4*min_len\n",
    "    for fld in range(n_folds):\n",
    "        if balance==False:\n",
    "#             df_y0_undersample=df[df.y<select_num].sample(n=int(min_len*frac_1*frac_1_factor), random_state = 10*(fld+1))\n",
    "            df_y0_undersample=df[df.y<select_num].sample(n=int(min_len*frac_1*frac_1_factor), random_state = 201)\n",
    "\n",
    "            tmp_df = pd.concat([df[select_list].sample(frac=frac_1, random_state = 10*(fld+1)),df_y0_undersample ])\n",
    "        else:\n",
    "            tmp_df = df.sample(frac=frac_1, random_state = 10*(fld+1))\n",
    "            \n",
    "        df_dict[fld]=tmp_df\n",
    "\n",
    "    return df_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "112db85b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:16:47.172854Z",
     "iopub.status.busy": "2021-12-22T05:16:47.172186Z",
     "iopub.status.idle": "2021-12-22T05:16:47.175912Z",
     "shell.execute_reply": "2021-12-22T05:16:47.176399Z",
     "shell.execute_reply.started": "2021-12-22T04:05:36.891534Z"
    },
    "papermill": {
     "duration": 0.144127,
     "end_time": "2021-12-22T05:16:47.176572",
     "exception": false,
     "start_time": "2021-12-22T05:16:47.032445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_test==True:\n",
    "    jc_df=jc_df[0:400]\n",
    "    juc_df=juc_df[0:400]\n",
    "    rud_df=rud_df[0:400]\n",
    "    jcc_df=jcc_df[0:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b97b031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:16:47.455113Z",
     "iopub.status.busy": "2021-12-22T05:16:47.454459Z",
     "iopub.status.idle": "2021-12-22T05:16:47.663018Z",
     "shell.execute_reply": "2021-12-22T05:16:47.662426Z",
     "shell.execute_reply.started": "2021-12-22T04:05:36.910882Z"
    },
    "papermill": {
     "duration": 0.347758,
     "end_time": "2021-12-22T05:16:47.663171",
     "exception": false,
     "start_time": "2021-12-22T05:16:47.315413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_test==True:\n",
    "#     jc_df_kdict=create_fold_kfold(jc_df,FOLDS=fold_num_k,select_num=1,frac_1=1.5,balance=True)\n",
    "#     juc_df_kdict=create_fold_kfold(juc_df,FOLDS=fold_num_k,select_num=0.5,frac_1=1.5,balance=True)\n",
    "#     rud_df_kdict=create_fold_kfold(rud_df,FOLDS=fold_num_k,select_num=0.5,frac_1=1.5,balance=True)\n",
    "#     jcc_df_kdict=create_fold_kfold(jcc_df,FOLDS=fold_num_k,select_num=1,frac_1=1.5,balance=True)\n",
    "\n",
    "    jc_df_sdict=create_fold_sample(jc_df,n_folds=fold_num_s,frac_1=0.8,frac_1_factor=1.5,select_num=1,balance=True,translate=False)\n",
    "    juc_df_sdict=create_fold_sample(juc_df,n_folds=fold_num_s,frac_1=0.8,frac_1_factor=1.5,select_num=0.5,balance=True)\n",
    "    rud_df_sdict=create_fold_sample(rud_df,n_folds=fold_num_s,frac_1=0.8,frac_1_factor=1.5,select_num=0.5,balance=True)\n",
    "    jcc_df_sdict=create_fold_sample(jcc_df,n_folds=fold_num_s,frac_1=0.8,frac_1_factor=1.5,select_num=1,balance=True)\n",
    "    \n",
    "if is_test==False:\n",
    "#     jc_df_kdict=create_fold_kfold(jc_df,FOLDS=fold_num_k,select_num=1,frac_1=1.5,balance=False)\n",
    "#     juc_df_kdict=create_fold_kfold(juc_df,FOLDS=fold_num_k,select_num=0.5,frac_1=1.5,balance=False)\n",
    "#     rud_df_kdict=create_fold_kfold(rud_df,FOLDS=fold_num_k,select_num=0.5,frac_1=1.5,balance=True)\n",
    "#     jcc_df_kdict=create_fold_kfold(jcc_df,FOLDS=fold_num_k,select_num=1,frac_1=1.5,balance=False)\n",
    "\n",
    "    jc_df_sdict=create_fold_sample(jc_df,n_folds=fold_num_s,frac_1=0.8,frac_1_factor=1.5,select_num=0.001,balance=False,translate=False)\n",
    "    juc_df_sdict=create_fold_sample(juc_df,n_folds=fold_num_s,frac_1=0.8,frac_1_factor=1.5,select_num=0.5,balance=False)\n",
    "    rud_df_sdict=create_fold_sample(rud_df,n_folds=fold_num_s,frac_1=0.8,frac_1_factor=1.5,select_num=0.5,balance=True)\n",
    "    jcc_df_sdict=create_fold_sample(jcc_df,n_folds=fold_num_s,frac_1=1,frac_1_factor=1,select_num=0.001,balance=False)\n",
    "    \n",
    "#     jc_df_kdict[0].shape\n",
    "#     juc_df_kdict[0].shape\n",
    "#     rud_df_kdict[0].shape\n",
    "#     jcc_df_sdict[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef730809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:16:47.946325Z",
     "iopub.status.busy": "2021-12-22T05:16:47.945446Z",
     "iopub.status.idle": "2021-12-22T05:16:47.948734Z",
     "shell.execute_reply": "2021-12-22T05:16:47.949209Z",
     "shell.execute_reply.started": "2021-12-22T04:05:37.2754Z"
    },
    "papermill": {
     "duration": 0.149627,
     "end_time": "2021-12-22T05:16:47.949379",
     "exception": false,
     "start_time": "2021-12-22T05:16:47.799752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00    16225\n",
       "0.32     5666\n",
       "1.12     3800\n",
       "0.48     1758\n",
       "2.62     1738\n",
       "0.96     1215\n",
       "4.12      385\n",
       "0.16      317\n",
       "0.64      301\n",
       "1.82      290\n",
       "1.98      204\n",
       "0.80      181\n",
       "2.46      164\n",
       "1.50       76\n",
       "5.62       31\n",
       "2.14       31\n",
       "3.32       21\n",
       "2.30       20\n",
       "3.96       10\n",
       "3.48       10\n",
       "1.66        5\n",
       "4.82        1\n",
       "3.96        1\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jcc_df_sdict[0][\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1a63c",
   "metadata": {
    "papermill": {
     "duration": 0.136454,
     "end_time": "2021-12-22T05:16:48.222880",
     "exception": false,
     "start_time": "2021-12-22T05:16:48.086426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76341a4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:16:48.502547Z",
     "iopub.status.busy": "2021-12-22T05:16:48.501503Z",
     "iopub.status.idle": "2021-12-22T05:16:48.516595Z",
     "shell.execute_reply": "2021-12-22T05:16:48.517074Z",
     "shell.execute_reply.started": "2021-12-22T04:05:37.291952Z"
    },
    "papermill": {
     "duration": 0.15747,
     "end_time": "2021-12-22T05:16:48.517271",
     "exception": false,
     "start_time": "2021-12-22T05:16:48.359801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "def ridge_cv(df_dic,n_folds,model_pre=\"jc_k_ridge_\",df_val=df_val,clean_prm=False,translate=False):\n",
    "    val_preds_arr1 = np.zeros((df_val.shape[0], n_folds))\n",
    "    val_preds_arr2 = np.zeros((df_val.shape[0], n_folds))\n",
    "    test_preds_arr = np.zeros((df_test.shape[0], n_folds))\n",
    "    for fld in tqdm(range(n_folds)):\n",
    "        df = df_dic[fld]\n",
    "        vec = TfidfVectorizer(analyzer='char_wb', max_df=0.5, min_df=3, ngram_range=(3, 5) )\n",
    "        vec_pre=model_pre+\"vec_\"\n",
    "        if translate!=True:\n",
    "            text=df[\"text\"]\n",
    "            y=df[\"y\"]\n",
    "        else:\n",
    "            trans_df=df.dropna(axis=0,subset = [\"fr_text\"])\n",
    "            text=pd.concat([df[\"text\"],trans_df[\"fr_text\"],trans_df[\"es_text\"],trans_df[\"de_text\"]])\n",
    "            y=pd.concat([df[\"y\"],trans_df[\"y\"],trans_df[\"y\"],trans_df[\"y\"]])\n",
    "        X=vec.fit_transform(text)\n",
    "        joblib.dump(vec,os.path.join(ridge_save_path,f'{vec_pre}{fld}.pkl')) #保存模型 文件后缀为.pkl\n",
    "        model=Ridge(alpha=0.5)\n",
    "        model.fit(X,y)\n",
    "\n",
    "        if clean_prm==True:\n",
    "#             X_less_toxic = vec.transform(clean(df_val,'less_toxic')['less_toxic'])\n",
    "#             X_more_toxic = vec.transform(clean(df_val,'more_toxic')['more_toxic'])\n",
    "#             X_test = vec.transform(clean(df_test,'text')['text'])\n",
    "            df_val=clean(df_val,'less_toxic')\n",
    "            df_val=clean(df_val,'more_toxic')\n",
    "#             df_test=clean(df_test,\"text\")\n",
    "            df_val['less_toxic'] = df_val.apply(lambda row :text_cleaning(row[\"less_toxic\"]),axis=1)\n",
    "            df_val['more_toxic'] = df_val.apply(lambda row :text_cleaning(row[\"more_toxic\"]),axis=1)\n",
    "            df_test['text'] = df_test.apply(lambda row :text_cleaning(row[\"text\"]),axis=1)\n",
    "        \n",
    "    \n",
    "#             df_val['less_toxic'] = df_val['less_toxic'].progress_apply(text_cleaning)\n",
    "#             df_val['more_toxic'] = df_val['more_toxic'].progress_apply(text_cleaning)\n",
    "#             df_test['text'] = df_test['text'].progress_apply(text_cleaning)\n",
    "\n",
    "            X_less_toxic = vec.transform(df_val['less_toxic'])\n",
    "            X_more_toxic = vec.transform(df_val['more_toxic'])\n",
    "            X_test = vec.transform(df_test['text'])\n",
    "        else:\n",
    "            X_less_toxic = vec.transform(df_val['less_toxic'])\n",
    "            X_more_toxic = vec.transform(df_val['more_toxic'])\n",
    "            X_test = vec.transform(df_test['text'])\n",
    "            \n",
    "        val_preds_arr1[:,fld] = model.predict(X_less_toxic)\n",
    "        val_preds_arr2[:,fld] = model.predict(X_more_toxic)\n",
    "\n",
    "        test_preds_arr[:,fld] = model.predict(X_test)\n",
    "            \n",
    "        joblib.dump(model,os.path.join(ridge_save_path,f'{model_pre}{fld}.pkl')) #保存模型 文件后缀为.pkl\n",
    "        del model,vec\n",
    "    p1=val_preds_arr1.mean(axis=1)\n",
    "    p2=val_preds_arr2.mean(axis=1)\n",
    "    pv=test_preds_arr.mean(axis=1)\n",
    "    print(f'Validation Accuracy is { np.round((p1 < p2).mean() * 100,2)}')        \n",
    "    return p1,p2,pv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c23f4f",
   "metadata": {
    "papermill": {
     "duration": 0.137045,
     "end_time": "2021-12-22T05:16:48.791446",
     "exception": false,
     "start_time": "2021-12-22T05:16:48.654401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "add29f4f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#verbose =-1 忽略警告\n",
    "depth=1000\n",
    "params = {'task':'train',\n",
    "    \"device\" : \"cpu\",\n",
    "    'boosting_type':'gbdt',\n",
    "    \"max_depth\":7,\n",
    "    \"num_leaves\":80,\n",
    "    \"bagging_fraction\":0.8,\n",
    "          \"bagging_freq\":5,\n",
    "    'objective':'regression',\n",
    "    \"learning_rate\":0.05,\n",
    "    \"max_bin\":63,\n",
    "    \"random_state\":2021,\n",
    "    'verbose':-1, \n",
    "    \"train_metric\":False,\n",
    "    \"force_col_wise\":False}\n",
    "\n",
    "\n",
    "def lightgbm_cv(df_dic,n_folds,model_pre=\"jc_k_gbm_\",df_val=df_val,clean_prm=False,translate=False):\n",
    "    ####lightgbm_cv 在aug情况下有bug\n",
    "    val_preds_arr1 = np.zeros((df_val.shape[0], n_folds))\n",
    "    val_preds_arr2 = np.zeros((df_val.shape[0], n_folds))\n",
    "    test_preds_arr = np.zeros((df_test.shape[0], n_folds))\n",
    "\n",
    "    for fld in tqdm(range(n_folds)):\n",
    "        df = df_dic[fld]\n",
    "        vec = TfidfVectorizer(analyzer='char_wb', max_df=0.5, min_df=3, ngram_range=(3, 5) )\n",
    "        if translate!=True:\n",
    "            text=df[\"text\"]\n",
    "            y=df[\"y\"]\n",
    "        else:\n",
    "            trans_df=df.dropna(axis=0,subset = [\"fr_text\"])\n",
    "            text=pd.concat([df[\"text\"],trans_df[\"fr_text\"],trans_df[\"es_text\"],trans_df[\"de_text\"]])\n",
    "            y=pd.concat([df[\"y\"],trans_df[\"y\"],trans_df[\"y\"],trans_df[\"y\"]])\n",
    "\n",
    "        X=vec.fit_transform(text)\n",
    "        vec_pre=model_pre+\"vec_\"\n",
    "        joblib.dump(vec,os.path.join(gbm_save_path,f'{vec_pre}{fld}.pkl')) #保存模型 文件后缀为.pkl\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.1,random_state = 0)\n",
    "        lgb_train = lgb.Dataset(X_train,y_train)\n",
    "        lgb_eval = lgb.Dataset(X_val,y_val,reference=lgb_train)\n",
    "        \n",
    "        gbm = lgb.train(params,lgb_train,\n",
    "            num_boost_round=300,\n",
    "            valid_sets=lgb_eval,\n",
    "            early_stopping_rounds=50\n",
    "            ) \n",
    "        \n",
    "        if clean_prm==True:\n",
    "            X_less_toxic = vec.transform(clean(df_val,'less_toxic')['less_toxic'])\n",
    "            X_more_toxic = vec.transform(clean(df_val,'more_toxic')['more_toxic'])\n",
    "            X_test = vec.transform(clean(df_test,'text')['text'])\n",
    "        else:\n",
    "            X_less_toxic = vec.transform(df_val['less_toxic'])\n",
    "            X_more_toxic = vec.transform(df_val['more_toxic'])\n",
    "            X_test = vec.transform(df_test['text'])\n",
    "    \n",
    "        val_preds_arr1[:,fld] = gbm.predict(X_less_toxic,num_iteration=gbm.best_iteration)\n",
    "        val_preds_arr2[:,fld] = gbm.predict(X_more_toxic,num_iteration=gbm.best_iteration)\n",
    "\n",
    "        test_preds_arr[:,fld] =gbm.predict(X_test,num_iteration=gbm.best_iteration)\n",
    "        \n",
    "        gbm.save_model(os.path.join(gbm_save_path,f'{model_pre}{fld}.txt'))\n",
    "        # 模型加载\n",
    "#         gbm = lgb.Booster(model_file='model.txt')\n",
    "        # 模型预测\n",
    "#         y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "        del gbm,vec\n",
    "    p1=val_preds_arr1.mean(axis=1)\n",
    "    p2=val_preds_arr2.mean(axis=1)\n",
    "    pv=test_preds_arr.mean(axis=1)\n",
    "    print(f'Validation Accuracy is { np.round((p1 < p2).mean() * 100,2)}')        \n",
    "    return p1,p2,pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "016fa70c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:16:49.378769Z",
     "iopub.status.busy": "2021-12-22T05:16:49.377715Z",
     "iopub.status.idle": "2021-12-22T05:21:00.471705Z",
     "shell.execute_reply": "2021-12-22T05:21:00.469355Z",
     "shell.execute_reply.started": "2021-12-22T04:05:37.357733Z"
    },
    "papermill": {
     "duration": 251.240561,
     "end_time": "2021-12-22T05:21:00.471861",
     "exception": false,
     "start_time": "2021-12-22T05:16:49.231300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:16<00:00, 76.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy is 67.05\n",
      " Validation Accuracy is 67.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p1=defaultdict()\n",
    "p2=defaultdict()\n",
    "pv=defaultdict()\n",
    "\n",
    "\n",
    "func_dict={\"ridge\":ridge_cv,\"gbm\":lightgbm_cv}\n",
    "# func_dict.get(x)\n",
    "\n",
    "if Fold_type==1:\n",
    "#     pre_names=[\"jc_k_\",\"juc_k_\",\"rud_k_\",\"jcc_k_\"]\n",
    "    pre_names=[ data_name+\"k_\" for data_name in data_names]\n",
    "    name2dict={\"jc_k_\":jc_df_kdict,\"juc_k_\":juc_df_kdict,\"rud_k_\":rud_df_kdict,\"jcc_k_\":jcc_df_kdict}\n",
    "    fold_num=fold_num_k\n",
    "elif Fold_type==2:\n",
    "    pre_names=[ data_name+\"s_\" for data_name in data_names]\n",
    "    name2dict={\"jc_s_\":jc_df_sdict,\"juc_s_\":juc_df_sdict,\"rud_s_\":rud_df_sdict,\"jcc_s_\":jcc_df_sdict}\n",
    "    fold_num=fold_num_s\n",
    "\n",
    "p1_ensenmble = np.zeros((df_val.shape[0]))\n",
    "p2_ensenmble = np.zeros((df_val.shape[0]))\n",
    "score=np.zeros((df_test.shape[0]))\n",
    "\n",
    "for pre_name in pre_names:\n",
    "    ###model_pre_ridge:jc_k_ridge_ pre_name:jc_k_ model:jc_k_ridge_{fold} vec:jc_k_ridge_vec_{fold}\n",
    "    #pre_name jc_k_ model_name jc_k_ridge_\n",
    "    clean_prm=False\n",
    "    translate=False\n",
    "    p1[pre_name],p2[pre_name]=np.zeros((df_val.shape[0])),np.zeros((df_val.shape[0]))\n",
    "    pv[pre_name]=np.zeros((df_test.shape[0]))\n",
    "    if \"jcc\" in pre_name:\n",
    "        clean_prm=True\n",
    "    if any([ trans_name in pre_name for trans_name in translate_data]) and translate_aug==True:\n",
    "        translate=True\n",
    "\n",
    "    for index,model_name in enumerate(model_choice):\n",
    "        cv_func=func_dict.get(model_name)\n",
    "        model_pre=pre_name+model_name+\"_\"\n",
    "        p1[model_pre],p2[model_pre],pv[model_pre]=cv_func(name2dict[pre_name],n_folds=fold_num,\n",
    "                                                        model_pre=model_pre,clean_prm=clean_prm,translate=translate)\n",
    "\n",
    "        p1[pre_name]= p1[pre_name]+ p1[model_pre]*factor[index]\n",
    "        p2[pre_name]= p2[pre_name]+ p2[model_pre]*factor[index]\n",
    "        pv[pre_name]= pv[pre_name]+ pv[model_pre]*factor[index]\n",
    "\n",
    "    kmax=max(p1[pre_name].max(),p2[pre_name].max())\n",
    "    p1_ensenmble=p1_ensenmble+p1[pre_name]/kmax\n",
    "    p2_ensenmble=p2_ensenmble+p2[pre_name]/kmax\n",
    "    score=score+pv[pre_name]/kmax\n",
    "\n",
    "print(f' Validation Accuracy is { np.round((p1_ensenmble < p2_ensenmble).mean() * 100,4)}') \n",
    "\n",
    "    \n",
    "df_test['score'] = rankdata(score, method='ordinal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "025886d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T05:21:00.764555Z",
     "iopub.status.busy": "2021-12-22T05:21:00.763845Z",
     "iopub.status.idle": "2021-12-22T05:21:00.779467Z",
     "shell.execute_reply": "2021-12-22T05:21:00.780002Z",
     "shell.execute_reply.started": "2021-12-22T04:09:25.753424Z"
    },
    "papermill": {
     "duration": 0.165015,
     "end_time": "2021-12-22T05:21:00.780186",
     "exception": false,
     "start_time": "2021-12-22T05:21:00.615171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc62e2",
   "metadata": {
    "papermill": {
     "duration": 0.145408,
     "end_time": "2021-12-22T05:21:01.069910",
     "exception": false,
     "start_time": "2021-12-22T05:21:00.924502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910bbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 359.351276,
   "end_time": "2021-12-22T05:21:02.323920",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-22T05:15:02.972644",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
