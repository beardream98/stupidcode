{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T14:12:18.178228Z",
     "iopub.status.busy": "2022-01-02T14:12:18.177770Z",
     "iopub.status.idle": "2022-01-02T14:12:25.300212Z",
     "shell.execute_reply": "2022-01-02T14:12:25.299431Z",
     "shell.execute_reply.started": "2022-01-02T14:12:18.178191Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import gc\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T14:12:25.303008Z",
     "iopub.status.busy": "2022-01-02T14:12:25.301807Z",
     "iopub.status.idle": "2022-01-02T14:12:49.992548Z",
     "shell.execute_reply": "2022-01-02T14:12:49.991798Z",
     "shell.execute_reply.started": "2022-01-02T14:12:25.302967Z"
    }
   },
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"../jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\")\n",
    "data2=pd.read_csv(\"../jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T14:12:49.995254Z",
     "iopub.status.busy": "2022-01-02T14:12:49.994852Z",
     "iopub.status.idle": "2022-01-02T14:12:50.055517Z",
     "shell.execute_reply": "2022-01-02T14:12:50.054695Z",
     "shell.execute_reply.started": "2022-01-02T14:12:49.995219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223549\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  score  \n",
      "0             0        0       0       0              0      0  \n",
      "1             0        0       0       0              0      0  \n",
      "2             0        0       0       0              0      0  \n",
      "3             0        0       0       0              0      0  \n",
      "4             0        0       0       0              0      0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>223549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.221857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.754190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               score\n",
       "count  223549.000000\n",
       "mean        0.221857\n",
       "std         0.754190\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         6.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data1))\n",
    "data1['score']=data1[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)\n",
    "print(data1.head())\n",
    "pre_data1=data1[['id','comment_text','score']]\n",
    "pre_data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T14:17:54.635152Z",
     "iopub.status.busy": "2022-01-02T14:17:54.634737Z",
     "iopub.status.idle": "2022-01-02T14:17:54.641516Z",
     "shell.execute_reply": "2022-01-02T14:17:54.640672Z",
     "shell.execute_reply.started": "2022-01-02T14:17:54.635120Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_preprocess(df):\n",
    "    value_not_zero=df[df.score>0]\n",
    "    value_zero=df[df.score==0]\n",
    "    subset = df.sample(n=len(value_not_zero))\n",
    "    op_data=pd.concat([value_not_zero, subset], ignore_index=True)\n",
    "    print(len(value_not_zero))\n",
    "    print(len(value_zero))\n",
    "    print(len(op_data))\n",
    "    return op_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T14:17:59.186317Z",
     "iopub.status.busy": "2022-01-02T14:17:59.185568Z",
     "iopub.status.idle": "2022-01-02T14:17:59.752065Z",
     "shell.execute_reply": "2022-01-02T14:17:59.751159Z",
     "shell.execute_reply.started": "2022-01-02T14:17:59.186278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1902194\n",
      "      id                                       comment_text     toxic  \\\n",
      "0  59848  This is so cool. It's like, 'would you want yo...  0.000000   \n",
      "1  59849  Thank you!! This would make my life a lot less...  0.000000   \n",
      "2  59852  This is such an urgent design problem; kudos t...  0.000000   \n",
      "3  59855  Is this something I'll be able to install on m...  0.000000   \n",
      "4  59856               haha you guys are a bunch of losers.  0.893617   \n",
      "\n",
      "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
      "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
      "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
      "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
      "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
      "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
      "\n",
      "   ...    rating  funny  wow  sad  likes  disagree  sexual_explicit  \\\n",
      "0  ...  rejected      0    0    0      0         0              0.0   \n",
      "1  ...  rejected      0    0    0      0         0              0.0   \n",
      "2  ...  rejected      0    0    0      0         0              0.0   \n",
      "3  ...  rejected      0    0    0      0         0              0.0   \n",
      "4  ...  rejected      0    0    0      1         0              0.0   \n",
      "\n",
      "   identity_annotator_count  toxicity_annotator_count     score  \n",
      "0                         0                         4  0.000000  \n",
      "1                         0                         4  0.000000  \n",
      "2                         0                         4  0.000000  \n",
      "3                         0                         4  0.000000  \n",
      "4                         4                        47  1.808511  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.902194e+06</td>\n",
       "      <td>1.902194e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.912771e+06</td>\n",
       "      <td>2.345440e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.497349e+06</td>\n",
       "      <td>4.600420e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.984800e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.273542e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.282205e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.862735e+06</td>\n",
       "      <td>3.333333e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.194639e+06</td>\n",
       "      <td>5.255702e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         score\n",
       "count  1.902194e+06  1.902194e+06\n",
       "mean   3.912771e+06  2.345440e-01\n",
       "std    2.497349e+06  4.600420e-01\n",
       "min    5.984800e+04  0.000000e+00\n",
       "25%    8.273542e+05  0.000000e+00\n",
       "50%    5.282205e+06  0.000000e+00\n",
       "75%    5.862735e+06  3.333333e-01\n",
       "max    7.194639e+06  5.255702e+00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data2))\n",
    "data2['score']=data2[['toxic', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack']].sum(axis=1)\n",
    "print(data2.head())\n",
    "pre_data2=data2[['comment_text','score']]\n",
    "pre_data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T14:18:48.084933Z",
     "iopub.status.busy": "2022-01-02T14:18:48.084147Z",
     "iopub.status.idle": "2022-01-02T14:18:48.447191Z",
     "shell.execute_reply": "2022-01-02T14:18:48.446436Z",
     "shell.execute_reply.started": "2022-01-02T14:18:48.084891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22468\n",
      "201081\n",
      "44936\n",
      "590294\n",
      "1311900\n",
      "1180588\n"
     ]
    }
   ],
   "source": [
    "pre_data1_op=data_preprocess(pre_data1)\n",
    "pre_data2_op=data_preprocess(pre_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T14:19:22.012362Z",
     "iopub.status.busy": "2022-01-02T14:19:22.011533Z",
     "iopub.status.idle": "2022-01-02T14:19:22.099059Z",
     "shell.execute_reply": "2022-01-02T14:19:22.098186Z",
     "shell.execute_reply.started": "2022-01-02T14:19:22.012328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225524\n"
     ]
    }
   ],
   "source": [
    "all_data=pd.concat([pre_data1_op, pre_data2_op], ignore_index=True)\n",
    "print(len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T14:25:21.031847Z",
     "iopub.status.busy": "2022-01-02T14:25:21.031247Z",
     "iopub.status.idle": "2022-01-02T14:25:21.096466Z",
     "shell.execute_reply": "2022-01-02T14:25:21.095727Z",
     "shell.execute_reply.started": "2022-01-02T14:25:21.031811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: ', device.type)\n",
    "\n",
    "\n",
    "SEED = 2022\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T14:26:11.817383Z",
     "iopub.status.busy": "2022-01-02T14:26:11.816689Z",
     "iopub.status.idle": "2022-01-02T14:26:11.822371Z",
     "shell.execute_reply": "2022-01-02T14:26:11.821709Z",
     "shell.execute_reply.started": "2022-01-02T14:26:11.817346Z"
    }
   },
   "outputs": [],
   "source": [
    "# BERT\n",
    "BERT = 'bert-base-uncased'\n",
    "# Distilbert\n",
    "DISTILBERT = 'distilbert-base-uncased'\n",
    "# Roberta\n",
    "ROBERTA = 'roberta-base'\n",
    "cfg ={}\n",
    "ARCH_PATH = ROBERTA\n",
    "cfg['train'] = {'n_folds': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T14:35:47.856702Z",
     "iopub.status.busy": "2022-01-02T14:35:47.856434Z",
     "iopub.status.idle": "2022-01-02T14:35:47.863864Z",
     "shell.execute_reply": "2022-01-02T14:35:47.862788Z",
     "shell.execute_reply.started": "2022-01-02T14:35:47.856671Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bin_stratified(df, n_bins=20, n_splits=5):\n",
    "    df['bin'] = pd.cut(df.score, n_bins, labels=[i for i in range(n_bins)])\n",
    "    \n",
    "    df['fold'] = np.nan\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=SEED, shuffle=True)\n",
    "    gen_skf = skf.split(df.comment_text, y=df.bin)\n",
    "\n",
    "    for fold, (idx_train, idx_val) in enumerate(gen_skf):\n",
    "        df.loc[idx_val, 'fold'] = fold\n",
    "    df['fold'] = df['fold'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T14:57:24.105119Z",
     "iopub.status.busy": "2022-01-02T14:57:24.104647Z",
     "iopub.status.idle": "2022-01-02T14:57:30.269854Z",
     "shell.execute_reply": "2022-01-02T14:57:30.269113Z",
     "shell.execute_reply.started": "2022-01-02T14:57:24.105084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40629ad9d0cd4238b01a7b312c47b713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fd389ab2834b54910f6242601a4d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659ae48c72db49ae89e3d7f8451674f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfde8298839642c0ac05d86a8fe4f828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg['tokenizer'] ={'name': ARCH_PATH, \n",
    "                   'max_length': 210}\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:03:45.845484Z",
     "iopub.status.busy": "2022-01-02T15:03:45.844800Z",
     "iopub.status.idle": "2022-01-02T15:03:45.851290Z",
     "shell.execute_reply": "2022-01-02T15:03:45.850503Z",
     "shell.execute_reply.started": "2022-01-02T15:03:45.845447Z"
    }
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    text = df.loc[SEED, 'comment_text']\n",
    "    print('Text Length ', len(text.split(' ')))\n",
    "    text_tokenized = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        add_special_tokens=True,\n",
    "                        padding='max_length',\n",
    "                        max_length=cfg['tokenizer']['max_length'], \n",
    "                        truncation=True\n",
    "                        )\n",
    "    \n",
    "    for key, value in text_tokenized.items():\n",
    "        print(key, type(value))\n",
    "        print(value)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:23:15.305515Z",
     "iopub.status.busy": "2022-01-02T15:23:15.304874Z",
     "iopub.status.idle": "2022-01-02T15:23:15.315245Z",
     "shell.execute_reply": "2022-01-02T15:23:15.314292Z",
     "shell.execute_reply.started": "2022-01-02T15:23:15.305472Z"
    }
   },
   "outputs": [],
   "source": [
    "class jigsawDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, index):\n",
    "        text = self.df.loc[index, 'comment_text']\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,                                 \n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids'] \n",
    "        mask = inputs['attention_mask'] \n",
    "        \n",
    "        if cfg['tokenizer']['name']=='bert-base-uncased':\n",
    "            token_type_ids = inputs['token_type_ids'] \n",
    "        else:\n",
    "            token_type_ids = 1.\n",
    "        \n",
    "        target = self.df.loc[index, ['score']]\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.LongTensor(ids),\n",
    "            'mask': torch.LongTensor(mask),\n",
    "             'token_type_ids': torch.tensor(token_type_ids)\n",
    "            },{\n",
    "            'target': torch.Tensor(target)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:23:16.002918Z",
     "iopub.status.busy": "2022-01-02T15:23:16.002321Z",
     "iopub.status.idle": "2022-01-02T15:23:16.008564Z",
     "shell.execute_reply": "2022-01-02T15:23:16.007636Z",
     "shell.execute_reply.started": "2022-01-02T15:23:16.002872Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg['dl_train'] = {\n",
    "    'batch_size': 8 if device.type=='cpu' else 32, \n",
    "    'shuffle': True, \n",
    "    'num_workers': os.cpu_count(), \n",
    "    'pin_memory': True\n",
    "}\n",
    "\n",
    "cfg['dl_val'] = {\n",
    "    'batch_size': 8 if device.type=='cpu' else 64, \n",
    "    'shuffle': False, \n",
    "    'num_workers': os.cpu_count(), \n",
    "    'pin_memory': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:23:16.815800Z",
     "iopub.status.busy": "2022-01-02T15:23:16.815045Z",
     "iopub.status.idle": "2022-01-02T15:23:16.820289Z",
     "shell.execute_reply": "2022-01-02T15:23:16.819406Z",
     "shell.execute_reply.started": "2022-01-02T15:23:16.815719Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg['model'] = {'name': ARCH_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:23:17.313644Z",
     "iopub.status.busy": "2022-01-02T15:23:17.313180Z",
     "iopub.status.idle": "2022-01-02T15:23:17.325094Z",
     "shell.execute_reply": "2022-01-02T15:23:17.324238Z",
     "shell.execute_reply.started": "2022-01-02T15:23:17.313608Z"
    }
   },
   "outputs": [],
   "source": [
    "class jigsawBERT(nn.Module):\n",
    "    \n",
    "    def __init__(self, name, dropout=True):\n",
    "        super(jigsawBERT, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(name)\n",
    "        self.name = name\n",
    "        \n",
    "        if name == BERT:\n",
    "            self.in_features = self.bert.pooler.dense.out_features\n",
    "        elif name == DISTILBERT:\n",
    "            self.in_features = self.bert.transformer.layer[5].output_layer_norm.normalized_shape[0]\n",
    "        elif name == ROBERTA:\n",
    "            self.in_features = self.bert.pooler.dense.out_features\n",
    "        else:\n",
    "            self.in_features = 768\n",
    "        \n",
    "        self.fc = nn.Linear(self.in_features, 1)\n",
    "        self.dense = nn.Linear(self.in_features, self.in_features)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.layer_norm = nn.LayerNorm(self.in_features)\n",
    "        \n",
    "        torch.nn.init.kaiming_normal_(self.dense.weight)\n",
    "        torch.nn.init.kaiming_normal_(self.fc.weight)\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        if self.name == BERT:\n",
    "            last_hidden_state, output = self.bert(ids,\n",
    "                                                  attention_mask=mask,\n",
    "                                                  token_type_ids=token_type_ids,\n",
    "                                                  return_dict=False)\n",
    "        elif self.name == DISTILBERT:\n",
    "            last_hidden_state = self.bert(ids, \n",
    "                                           attention_mask=mask, \n",
    "                                           return_dict=False)\n",
    "            first_token_tensor = last_hidden_state[0][:, 0]\n",
    "            output = self.dense(first_token_tensor)\n",
    "            output = self.activation(output)\n",
    "            \n",
    "        elif self.name == ROBERTA:\n",
    "            last_hidden_state, output = self.bert(ids,\n",
    "                                                  attention_mask=mask,\n",
    "                                                  return_dict=False)\n",
    "        \n",
    "        output = self.layer_norm(output)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:23:17.902354Z",
     "iopub.status.busy": "2022-01-02T15:23:17.901457Z",
     "iopub.status.idle": "2022-01-02T15:23:17.907684Z",
     "shell.execute_reply": "2022-01-02T15:23:17.906804Z",
     "shell.execute_reply.started": "2022-01-02T15:23:17.902304Z"
    }
   },
   "outputs": [],
   "source": [
    "def jigsawMetric(y_pred, y_gt):\n",
    "    assert y_pred.size() == y_gt.size()\n",
    "    metric = nn.MSELoss()\n",
    "    metric = torch.sqrt(metric(y_pred, y_gt))\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:23:19.391275Z",
     "iopub.status.busy": "2022-01-02T15:23:19.390620Z",
     "iopub.status.idle": "2022-01-02T15:23:19.401177Z",
     "shell.execute_reply": "2022-01-02T15:23:19.400406Z",
     "shell.execute_reply.started": "2022-01-02T15:23:19.391233Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "\n",
    "cfg['optim'] = {'lr': 8e-6, \n",
    "#                 'weight_decay': 0.01\n",
    "               }\n",
    "cfg['scheduler'] = {'num_warmup_steps': 3, \n",
    "                    'num_training_steps': 7, \n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:23:20.872953Z",
     "iopub.status.busy": "2022-01-02T15:23:20.872693Z",
     "iopub.status.idle": "2022-01-02T15:23:20.884477Z",
     "shell.execute_reply": "2022-01-02T15:23:20.883675Z",
     "shell.execute_reply.started": "2022-01-02T15:23:20.872924Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "cfg['train'] ={\n",
    "    'n_folds': 5,\n",
    "    'n_epochs': 100\n",
    "}\n",
    "\n",
    "class StoreLoss:\n",
    "    \n",
    "    def __init__(self, fold):\n",
    "        self.loss_train_mean = []\n",
    "        self.loss_train_std = []\n",
    "        self.loss_val_mean = []\n",
    "        self.loss_val_std = []\n",
    "        \n",
    "        self.fold = fold\n",
    "        \n",
    "    def get_loss(self, loss_train, loss_val):\n",
    "        self.loss_train_mean.append(loss_train[0])\n",
    "        self.loss_train_std.append(loss_train[1])\n",
    "        self.loss_val_mean.append(loss_val[0])\n",
    "        self.loss_val_std.append(loss_val[1])\n",
    "        \n",
    "    def plot_loss(self):\n",
    "        \n",
    "        def get_ax(ax, loss_train, loss_val, title='mean'):\n",
    "            ax.plot(loss_train, marker='o', label='train')\n",
    "            ax.plot(loss_val, marker='x', label='val')\n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.set_ylabel(f'RMSE ({title})')\n",
    "            ax.set_title(f'RMSE({title}) vs Epoch at fold {self.fold}')\n",
    "            ax.legend()\n",
    "            return ax\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "        \n",
    "        ax[0] = get_ax(ax[0], self.loss_train_mean, self.loss_val_mean, title='mean')\n",
    "        ax[1] = get_ax(ax[1], self.loss_train_std, self.loss_val_std, title='std')\n",
    "        \n",
    "        \n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:23:22.177112Z",
     "iopub.status.busy": "2022-01-02T15:23:22.176525Z",
     "iopub.status.idle": "2022-01-02T15:23:22.182064Z",
     "shell.execute_reply": "2022-01-02T15:23:22.181358Z",
     "shell.execute_reply.started": "2022-01-02T15:23:22.177072Z"
    }
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    store = StoreLoss(fold=0)\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        loss_train = np.random.rand(2)\n",
    "        loss_val = np.random.rand(2)\n",
    "        \n",
    "        store.get_loss(loss_train, loss_val)\n",
    "    \n",
    "    store.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:33:21.431670Z",
     "iopub.status.busy": "2022-01-02T15:33:21.431398Z",
     "iopub.status.idle": "2022-01-02T15:33:21.447216Z",
     "shell.execute_reply": "2022-01-02T15:33:21.446538Z",
     "shell.execute_reply.started": "2022-01-02T15:33:21.431641Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(model, dl, criterion, optim, scheduler):\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    loss_train = []\n",
    "    loss_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    progress_bar = tqdm(dl, desc='train')\n",
    "    \n",
    "    for i, data in enumerate(progress_bar):\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        inputs = {key: value.to(device) for key, value in data[0].items()}\n",
    "        targets = data[1]['target'].to(device)\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(**inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        loss_train.append(loss.item())\n",
    "        loss_total += loss.item()\n",
    "        \n",
    "        progress_bar.set_postfix({'RMSE(batch)': loss.item(), \n",
    "                                  'RMSE(ave)': loss_total / (i+1), \n",
    "                                  'lr': optim.param_groups[0]['lr']})\n",
    "        \n",
    "        scaler.step(optim)\n",
    "        scaler.update()\n",
    "    \n",
    "    return np.mean(loss_train), np.std(loss_train)\n",
    "\n",
    "def val_fn(model, dl):\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    loss_val = []\n",
    "    loss_total = 0\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    progress_bar = tqdm(dl, desc='val')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(progress_bar):\n",
    "            inputs = {key: value.to(device) for key, value in data[0].items()}\n",
    "            targets = data[1]['score'].to(device)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(**inputs)\n",
    "                loss = jigsawMetric(outputs, targets)\n",
    "            \n",
    "            loss_val.append(loss.item())\n",
    "            loss_total += loss.item()\n",
    "            \n",
    "            progress_bar.set_postfix({'RMSE(batch)': loss.item(), 'RMSE(ave)': loss_total / (i+1)})\n",
    "    \n",
    "    loss_val_2 = np.array(loss_val)**2 * cfg['dl_val']['batch_size'] / len(dl.dataset)\n",
    "    print('RMSE for validation set overall: ', np.sqrt(loss_val_2.sum()))\n",
    "    \n",
    "    return np.sqrt(loss_val_2.sum()), np.std(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:33:24.258945Z",
     "iopub.status.busy": "2022-01-02T15:33:24.258678Z",
     "iopub.status.idle": "2022-01-02T15:33:24.263769Z",
     "shell.execute_reply": "2022-01-02T15:33:24.262973Z",
     "shell.execute_reply.started": "2022-01-02T15:33:24.258915Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_one_epoch(model, train_dl, val_dl, criterion, optim, scheduler):\n",
    "    inputs_train = {\n",
    "        'model': model, \n",
    "        'dl': train_dl, \n",
    "        'criterion': criterion, \n",
    "        'optim': optim, \n",
    "        'scheduler': scheduler\n",
    "    }\n",
    "\n",
    "    inputs_val = {'model': model, \n",
    "                  'dl': val_dl}\n",
    "\n",
    "    loss_train = train_fn(**inputs_train)\n",
    "    loss_val = val_fn(**inputs_val)\n",
    "    \n",
    "    return loss_train, loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:33:25.558485Z",
     "iopub.status.busy": "2022-01-02T15:33:25.558240Z",
     "iopub.status.idle": "2022-01-02T15:33:25.564605Z",
     "shell.execute_reply": "2022-01-02T15:33:25.563653Z",
     "shell.execute_reply.started": "2022-01-02T15:33:25.558458Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dls_for_n_fold(df, fold, tokenizer):\n",
    "    train_df = df.loc[df.fold!=fold].reset_index(drop=True)\n",
    "    val_df = df.loc[df.fold==fold].reset_index(drop=True)\n",
    "    \n",
    "    train_ds = jigsawDataset(\n",
    "        train_df, \n",
    "        tokenizer=tokenizer, \n",
    "        max_len=cfg['tokenizer']['max_length']\n",
    "    )\n",
    "    \n",
    "    val_ds = jigsawDataset(\n",
    "        val_df, \n",
    "        tokenizer=tokenizer, \n",
    "        max_len=cfg['tokenizer']['max_length']\n",
    "    )\n",
    "    \n",
    "    train_dl = DataLoader(train_ds, **cfg['dl_train'])\n",
    "    val_dl = DataLoader(val_ds, **cfg['dl_val'])\n",
    "    \n",
    "    return train_dl, val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:33:27.271014Z",
     "iopub.status.busy": "2022-01-02T15:33:27.270264Z",
     "iopub.status.idle": "2022-01-02T15:33:27.280474Z",
     "shell.execute_reply": "2022-01-02T15:33:27.279441Z",
     "shell.execute_reply.started": "2022-01-02T15:33:27.270976Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \n",
    "    def __init__(self, patience=2, seq=False):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.stop = False\n",
    "        \n",
    "    def __call__(self, loss, model, optim, cfg, path):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = loss\n",
    "            self.save_checkpoint(model, optim, cfg, path)\n",
    "        elif loss < self.best_score:\n",
    "            print(f'Loss decreased {self.best_score} -> {loss}.')\n",
    "            self.best_score = loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model, optim, cfg, path)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter > self.patience: self.stop = True\n",
    "                \n",
    "    def save_checkpoint(self, model, optim, cfg, path):\n",
    "        save_list = {'model': model.state_dict(), \n",
    "                     'cfg': cfg}\n",
    "        SAVE_PATH = path\n",
    "        torch.save(save_list, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:33:27.685338Z",
     "iopub.status.busy": "2022-01-02T15:33:27.684775Z",
     "iopub.status.idle": "2022-01-02T15:33:27.695726Z",
     "shell.execute_reply": "2022-01-02T15:33:27.694967Z",
     "shell.execute_reply.started": "2022-01-02T15:33:27.685302Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    seed_everything(SEED)\n",
    "        \n",
    "    df = all_data\n",
    "    get_bin_stratified(df, n_splits=cfg['train']['n_folds'])\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])\n",
    "    \n",
    "    for fold in range(cfg['train']['n_folds']):\n",
    "        print('Fold:', fold)\n",
    "        store = StoreLoss(fold=fold)\n",
    "        es = EarlyStopping()\n",
    "\n",
    "        train_dl, val_dl = get_dls_for_n_fold(df, fold, tokenizer)\n",
    "\n",
    "        model = jigsawBERT(name=cfg['model']['name'])\n",
    "        criterion =jigsawMetric\n",
    "        optim = AdamW(model.parameters(), **cfg['optim'])\n",
    "        scheduler = get_cosine_schedule_with_warmup(optim, **cfg['scheduler'])\n",
    "        if optim.param_groups[0]['lr']==0:\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        inputs = {'model': model,\n",
    "                  'train_dl': train_dl,\n",
    "                  'val_dl': val_dl,\n",
    "                  'criterion': criterion,\n",
    "                  'optim': optim,\n",
    "                  'scheduler': scheduler}\n",
    "\n",
    "        for epoch in range(cfg['train']['n_epochs']):\n",
    "            loss_train, loss_val = run_one_epoch(**inputs)\n",
    "            \n",
    "            store.get_loss(loss_train, loss_val)\n",
    "            \n",
    "            es(loss_val[0], model, optim, cfg, path=f'jigsawBERT_fold{fold}.tar')\n",
    "            if es.stop:\n",
    "                print('Early Stop !')\n",
    "                break\n",
    "\n",
    "            scheduler.step()\n",
    "            \n",
    "        store.plot_loss()\n",
    "        \n",
    "        del model, optim\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T15:33:27.946371Z",
     "iopub.status.busy": "2022-01-02T15:33:27.946065Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a78636a60844edbb74bd867fac0693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "train:   2%|â–         | 475/30639 [05:19<5:36:36,  1.49it/s, RMSE(batch)=0.771, RMSE(ave)=0.875, lr=2.67e-6]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'jigsawBERT'\n",
    "\n",
    "def val_fn_cv(model, dl):\n",
    "    scaler = GradScaler()\n",
    "    preds = []\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    progress_bar = tqdm(dl, desc='cv')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(progress_bar):\n",
    "            inputs = {key: value.to(device) for key, value in data[0].items()}\n",
    "            targets = data[1]['target'].to(device)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(**inputs)\n",
    "            \n",
    "            preds.append(outputs.detach().cpu().numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def main_cv():\n",
    "    seed_everything(SEED)\n",
    "    \n",
    "    df = all_data\n",
    "    get_bin_stratified(df, n_splits=cfg['train']['n_folds'])\n",
    "    df['oof'] = np.nan\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])\n",
    "    \n",
    "    for fold in range(cfg['train']['n_folds']):\n",
    "        train_dl, val_dl = get_dls_for_n_fold(df, fold, tokenizer)\n",
    "\n",
    "        model = jigsawBERT(name=cfg['model']['name'])\n",
    "        PATH = os.path.join(MODEL_NAME + f'_fold{fold}.tar')\n",
    "        saved_contents = torch.load(PATH, map_location=device)\n",
    "        \n",
    "        model.load_state_dict(saved_contents['model'])\n",
    "        if fold==0:\n",
    "            cfg_for_train = saved_contents['cfg']\n",
    "            print('Configuration for training:')\n",
    "            print()\n",
    "            pprint(cfg_for_train)\n",
    "            print()\n",
    "        \n",
    "        print('Fold:', fold)\n",
    "        \n",
    "        inputs = {'model': model,\n",
    "                  'dl': val_dl}\n",
    "        \n",
    "        preds = val_fn_cv(**inputs)\n",
    "        df.loc[df.fold==fold, 'oof'] = preds\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = main_cv()\n",
    "df.to_csv('oof_df.csv', index=False)\n",
    "\n",
    "mse = mean_squared_error(df['score'], df['oof'])\n",
    "rmse = np.sqrt(mse)\n",
    "print('CV score: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame()\n",
    "temp_df['x'] = np.linspace(-3.5, 1.5, 10)\n",
    "temp_df['y'] = temp_df['x']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(data=df, x='score', y='oof', label='oof vs target')\n",
    "sns.lineplot(data=temp_df, x='x', y='y', color='orange')\n",
    "plt.title('OOF Prediction vs Target')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
