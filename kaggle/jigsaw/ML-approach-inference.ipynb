{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:34:08.495032Z",
     "iopub.status.busy": "2021-12-17T08:34:08.494712Z",
     "iopub.status.idle": "2021-12-17T08:34:09.465416Z",
     "shell.execute_reply": "2021-12-17T08:34:09.464424Z",
     "shell.execute_reply.started": "2021-12-17T08:34:08.494997Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import scipy.optimize as optimize\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "import time\n",
    "import re \n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import gc \n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:27:56.730997Z",
     "iopub.status.busy": "2021-12-17T08:27:56.730656Z",
     "iopub.status.idle": "2021-12-17T08:27:56.734780Z",
     "shell.execute_reply": "2021-12-17T08:27:56.734225Z",
     "shell.execute_reply.started": "2021-12-17T08:27:56.730963Z"
    }
   },
   "outputs": [],
   "source": [
    "#1 means kf 2 means sample\n",
    "Fold_type=2\n",
    "\n",
    "data_names=[\"jc_\"]\n",
    "model_choice=[\"ridge\"]\n",
    "factor=[1]\n",
    "\n",
    "use_new_val=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:27:58.208669Z",
     "iopub.status.busy": "2021-12-17T08:27:58.207878Z",
     "iopub.status.idle": "2021-12-17T08:27:58.213895Z",
     "shell.execute_reply": "2021-12-17T08:27:58.213064Z",
     "shell.execute_reply.started": "2021-12-17T08:27:58.208625Z"
    }
   },
   "outputs": [],
   "source": [
    "system_path=r\"C:\\Users\\Lenovo\\Desktop\\stupidcode\\data\\jigsaw\"\n",
    "#第一届 jigsaw比赛 数据（challenge） Toxic Comment Classification Challenge\n",
    "\n",
    "jc_path=os.path.join(system_path,\"jigsaw-toxic-comment-classification-challenge\")\n",
    "#ruddit 数据\n",
    "run_path=os.path.join(system_path,\"ruddit-jigsaw-dataset/Dataset\")\n",
    "#第二届 jigsaw比赛 对少数人群不歧视\n",
    "juc_path=os.path.join(system_path,\"jigsaw-unintended-bias-in-toxicity-classification\")\n",
    "\n",
    "#本次比赛数据 作为val\n",
    "jts_path=os.path.join(system_path,\"jigsaw-toxic-severity-rating\")\n",
    "\n",
    "# #数据抽样存储路径\n",
    "\n",
    "gbm_save_path=os.path.join(system_path,r\"save_model\\four_model ridge+gbm 0.806\")\n",
    "ridge_save_path=os.path.join(system_path,r\"save_model\\four_model ridge+gbm 0.806\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:28:00.471284Z",
     "iopub.status.busy": "2021-12-17T08:28:00.470292Z",
     "iopub.status.idle": "2021-12-17T08:28:01.114147Z",
     "shell.execute_reply": "2021-12-17T08:28:01.113359Z",
     "shell.execute_reply.started": "2021-12-17T08:28:00.471241Z"
    }
   },
   "outputs": [],
   "source": [
    "#验证集和测试集\n",
    "df_val = pd.read_csv(os.path.join(jts_path,\"validation_data.csv\"))\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(jts_path,\"comments_to_score.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train+Test:223549\n",
      "comments with toxic behaviour:22468\n"
     ]
    }
   ],
   "source": [
    "# 第一届比赛数据 以0/1为分值 \n",
    "features = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "jc_train_df = pd.read_csv(os.path.join(jc_path,\"train.csv\"))\n",
    "jc_test_df = pd.read_csv(os.path.join(jc_path,\"test.csv\"))\n",
    "temp_df = pd.read_csv(os.path.join(jc_path,\"test_labels.csv\"))\n",
    "\n",
    "jc_test_df = jc_test_df.merge ( temp_df, on =\"id\")\n",
    "#drop test data not used for scoring\n",
    "jc_test_df = jc_test_df.query (\"toxic != -1\")\n",
    "jc_df = jc_train_df.append ( jc_test_df ) \n",
    "\n",
    "print(f\"Train+Test:{jc_df.shape[0]}\")\n",
    "\n",
    "# 将代表有毒行为的筛选出来\n",
    "jc_df[\"toxic_subtype_sum\"]=jc_df[features].sum(axis=1)\n",
    "jc_df[\"toxic_behaviour\"]=jc_df[\"toxic_subtype_sum\"].map(lambda x: x > 0)\n",
    "\n",
    "tot_toxic_behaviour = jc_df[\"toxic_behaviour\"].sum()\n",
    "print(f'comments with toxic behaviour:{tot_toxic_behaviour}')\n",
    "\n",
    "jc_df = jc_df[['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].rename(columns={'comment_text': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30108, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6489, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 消除jc中重叠数据\n",
    "df_val_new = pd.read_csv(os.path.join(jts_path,\"validation_data.csv\"))\n",
    "print(df_val_new.shape)\n",
    "\n",
    "\n",
    "# Find cases already present in toxic data\n",
    "\n",
    "df_val_new = pd.merge(df_val_new, jc_df.loc[:,['text']], \n",
    "                  left_on = 'less_toxic', \n",
    "                  right_on = 'text', how='left')\n",
    "\n",
    "df_val_new = pd.merge(df_val_new, jc_df.loc[:,['text']], \n",
    "                  left_on = 'more_toxic', \n",
    "                  right_on = 'text', how='left')\n",
    "\n",
    "# Removing those cases\n",
    "df_val_new = df_val_new[(df_val_new.text_x.isna()) & (df_val_new.text_y.isna())][['worker', 'less_toxic', 'more_toxic']]\n",
    "df_val_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_new_val==True:\n",
    "    df_val=df_val_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:28:06.504345Z",
     "iopub.status.busy": "2021-12-17T08:28:06.504074Z",
     "iopub.status.idle": "2021-12-17T08:28:06.508644Z",
     "shell.execute_reply": "2021-12-17T08:28:06.507897Z",
     "shell.execute_reply.started": "2021-12-17T08:28:06.504317Z"
    }
   },
   "outputs": [],
   "source": [
    "Fold_type=2\n",
    "if Fold_type==1:\n",
    "    fold_num=5\n",
    "else:\n",
    "    fold_num=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:28:12.205646Z",
     "iopub.status.busy": "2021-12-17T08:28:12.205220Z",
     "iopub.status.idle": "2021-12-17T08:28:12.210647Z",
     "shell.execute_reply": "2021-12-17T08:28:12.209884Z",
     "shell.execute_reply.started": "2021-12-17T08:28:12.205615Z"
    }
   },
   "outputs": [],
   "source": [
    "if Fold_type==1:\n",
    "    pre_names=[ data_name+\"k_\" for data_name in data_names]\n",
    "elif Fold_type==2:\n",
    "    pre_names=[ data_name+\"s_\" for data_name in data_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:28:13.493082Z",
     "iopub.status.busy": "2021-12-17T08:28:13.492748Z",
     "iopub.status.idle": "2021-12-17T08:28:13.499407Z",
     "shell.execute_reply": "2021-12-17T08:28:13.498818Z",
     "shell.execute_reply.started": "2021-12-17T08:28:13.493048Z"
    }
   },
   "outputs": [],
   "source": [
    "#clean data\n",
    "def clean(data, col):\n",
    "    #数据清洗 \n",
    "    \n",
    "    # Clean some punctutations\n",
    "    data[col] = data[col].str.replace('\\n', ' \\n ')\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n",
    "    # Replace repeating characters more than 3 times to length of 3\n",
    "    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')    \n",
    "    # Add space around repeating characters\n",
    "    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ')    \n",
    "    # patterns with repeating characters \n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n",
    "    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:29:33.336673Z",
     "iopub.status.busy": "2021-12-17T08:29:33.336031Z",
     "iopub.status.idle": "2021-12-17T08:29:33.345249Z",
     "shell.execute_reply": "2021-12-17T08:29:33.344436Z",
     "shell.execute_reply.started": "2021-12-17T08:29:33.336629Z"
    }
   },
   "outputs": [],
   "source": [
    "def ridge_cv(model_pre,clean_prm=False):\n",
    "    val_preds_arr1 = np.zeros((df_val.shape[0], fold_num))\n",
    "    val_preds_arr2 = np.zeros((df_val.shape[0], fold_num))\n",
    "    test_preds_arr = np.zeros((df_test.shape[0], fold_num))\n",
    "    for fld in range(fold_num):\n",
    "        model_path=os.path.join(ridge_save_path,f\"{model_pre}{fld}.pkl\")\n",
    "        vec_model_path=os.path.join(ridge_save_path,f\"{model_pre}vec_{fld}.pkl\")\n",
    "        \n",
    "        vec = joblib.load(vec_model_path)\n",
    "        model=joblib.load(model_path)\n",
    "        \n",
    "        if clean_prm==False:\n",
    "            X_less_toxic = vec.transform(clean(df_val,'less_toxic')['less_toxic'])\n",
    "            X_more_toxic = vec.transform(clean(df_val,'more_toxic')['more_toxic'])\n",
    "            X_test = vec.transform(clean(df_test,'text')['text'])\n",
    "\n",
    "        else:\n",
    "            X_less_toxic = vec.transform(df_val['less_toxic'])\n",
    "            X_more_toxic = vec.transform(df_val['more_toxic'])\n",
    "            X_test=vec.transform(df_test['text'])\n",
    "            \n",
    "        val_preds_arr1[:,fld] = model.predict(X_less_toxic)\n",
    "        val_preds_arr2[:,fld] = model.predict(X_more_toxic)\n",
    "        test_preds_arr[:,fld] = model.predict(X_test)\n",
    "        \n",
    "        del model,vec\n",
    "    p1=val_preds_arr1.mean(axis=1)\n",
    "    p2=val_preds_arr2.mean(axis=1)\n",
    "    pv=test_preds_arr.mean(axis=1)\n",
    "    print(f'Ridge Validation Accuracy is { np.round((p1 < p2).mean() * 100,2)}')   \n",
    "    return p1,p2,pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:29:33.553867Z",
     "iopub.status.busy": "2021-12-17T08:29:33.553321Z",
     "iopub.status.idle": "2021-12-17T08:29:33.562981Z",
     "shell.execute_reply": "2021-12-17T08:29:33.562146Z",
     "shell.execute_reply.started": "2021-12-17T08:29:33.553821Z"
    }
   },
   "outputs": [],
   "source": [
    "def lightgbm_cv(model_pre,clean_prm=False):\n",
    "    val_preds_arr1 = np.zeros((df_val.shape[0], fold_num))\n",
    "    val_preds_arr2 = np.zeros((df_val.shape[0], fold_num))\n",
    "    test_preds_arr = np.zeros((df_test.shape[0], fold_num))\n",
    "    \n",
    "    for fld in range(fold_num):\n",
    "        \n",
    "        model_path=os.path.join(gbm_save_path,f\"{model_pre}{fld}.txt\")\n",
    "        vec_model_path=os.path.join(gbm_save_path,f\"{model_pre}vec_{fld}.pkl\")\n",
    "        # 模型加载\n",
    "        vec = joblib.load(vec_model_path)\n",
    "        gbm = lgb.Booster(model_file=model_path)\n",
    "        if clean_prm==False:\n",
    "            X_less_toxic = vec.transform(clean(df_val,'less_toxic')['less_toxic'])\n",
    "            X_more_toxic = vec.transform(clean(df_val,'more_toxic')['more_toxic'])\n",
    "            X_test = vec.transform(clean(df_test,'text')['text'])\n",
    "            \n",
    "        else:\n",
    "            X_less_toxic = vec.transform(df_val['less_toxic'])\n",
    "            X_more_toxic = vec.transform(df_val['more_toxic'])\n",
    "            X_test=vec.transform(df_test['text'])\n",
    "            \n",
    "        val_preds_arr1[:,fld] = gbm.predict(X_less_toxic,num_iteration=gbm.best_iteration)\n",
    "        val_preds_arr2[:,fld] = gbm.predict(X_more_toxic,num_iteration=gbm.best_iteration)\n",
    "        test_preds_arr[:,fld] = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "        del gbm,vec\n",
    "        \n",
    "    p1=val_preds_arr1.mean(axis=1)\n",
    "    p2=val_preds_arr2.mean(axis=1)\n",
    "    pv=test_preds_arr.mean(axis=1)\n",
    "    print(f'Gbm Validation Accuracy is { np.round((p1 < p2).mean() * 100,2)}')        \n",
    "    return p1,p2,pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T08:34:32.914503Z",
     "iopub.status.busy": "2021-12-17T08:34:32.914202Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [01:57<00:00, 117.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gbm Validation Accuracy is 67.62\n",
      "k Validation Accuracy is 67.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p1=defaultdict()\n",
    "p2=defaultdict()\n",
    "pv=defaultdict()\n",
    "\n",
    "func_dict={\"ridge\":ridge_cv,\"gbm\":lightgbm_cv}\n",
    "score=np.zeros(df_test.shape[0])\n",
    "\n",
    "p1_ensenmble = np.zeros((df_val.shape[0]))\n",
    "p2_ensenmble = np.zeros((df_val.shape[0]))\n",
    "\n",
    "for pre_name in tqdm(pre_names):\n",
    "    ###model_pre_ridge:jc_k_ridge_ pre_name:jc_k_ model:jc_k_ridge_{fold} vec:jc_k_ridge_vec_{fold}\n",
    "    #pre_name ju_k_ model_name jc_k_ridge_\n",
    "    clean_prm=False\n",
    "    p1[pre_name],p2[pre_name]=np.zeros((df_val.shape[0])),np.zeros((df_val.shape[0]))\n",
    "    pv[pre_name]=np.zeros((df_test.shape[0]))\n",
    "    if \"jcc\" in pre_name:\n",
    "        clean_prm=True\n",
    "    for index,model_name in enumerate(model_choice):\n",
    "        cv_func=func_dict.get(model_name)\n",
    "        model_pre=pre_name+model_name+\"_\"\n",
    "        p1[model_pre],p2[model_pre],pv[model_pre]=cv_func(model_pre,clean_prm)\n",
    "        \n",
    "        p1[pre_name]= p1[pre_name]+ p1[model_pre]*factor[index]\n",
    "        p2[pre_name]= p2[pre_name]+ p2[model_pre]*factor[index]\n",
    "        pv[pre_name]= pv[pre_name]+ pv[model_pre]*factor[index]\n",
    "\n",
    "    kmax=max(p1[pre_name].max(),p2[pre_name].max())\n",
    "    p1_ensenmble=p1_ensenmble+p1[pre_name]/kmax\n",
    "    p2_ensenmble=p2_ensenmble+p2[pre_name]/kmax\n",
    "    score=score+pv[pre_name]/kmax\n",
    "    \n",
    "print(f' Validation Accuracy is { np.round((p1_ensenmble < p2_ensenmble).mean() * 100,2)}') \n",
    "\n",
    "df_test['score'] = rankdata(score, method='ordinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
