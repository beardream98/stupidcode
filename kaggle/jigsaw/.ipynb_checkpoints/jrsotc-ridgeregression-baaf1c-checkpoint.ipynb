{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variation of https://www.kaggle.com/julian3833/jigsaw-incredibly-simple-naive-bayes-0-768 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T08:23:05.548230Z",
     "iopub.status.busy": "2021-12-10T08:23:05.547952Z",
     "iopub.status.idle": "2021-12-10T08:23:06.476402Z",
     "shell.execute_reply": "2021-12-10T08:23:06.475716Z",
     "shell.execute_reply.started": "2021-12-10T08:23:05.548203Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T08:23:06.477885Z",
     "iopub.status.busy": "2021-12-10T08:23:06.477670Z",
     "iopub.status.idle": "2021-12-10T08:23:07.233876Z",
     "shell.execute_reply": "2021-12-10T08:23:07.232983Z",
     "shell.execute_reply.started": "2021-12-10T08:23:06.477859Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import re \n",
    "import scipy\n",
    "from scipy import sparse\n",
    "\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import time\n",
    "import scipy.optimize as optimize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_colwidth=300\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train data\n",
    "\n",
    "Using data from [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)\n",
    "\n",
    "The target was multioutput, we turn it into linear,  using weighted toxic behaviors\n",
    "\n",
    "The types of toxicity are: 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T08:23:07.235672Z",
     "iopub.status.busy": "2021-12-10T08:23:07.235349Z",
     "iopub.status.idle": "2021-12-10T08:23:11.150025Z",
     "shell.execute_reply": "2021-12-10T08:23:11.149177Z",
     "shell.execute_reply.started": "2021-12-10T08:23:07.235622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jc_train_df:(159571, 8)\n",
      "jc_test_df:(153164, 8)\n",
      "jc_test_df:(63978, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "jc_path=r\"C:\\Users\\Lenovo\\Desktop\\stupidcode\\data\\jigsaw\\Jigsaw Rate Severity of T\"\n",
    "\n",
    "jc_train_df = pd.read_csv(os.path.join(jc_path,\"train.csv\"))\n",
    "print(f\"jc_train_df:{jc_train_df.shape}\")\n",
    "jc_test_df = pd.read_csv(os.path.join(jc_path,\"test.csv\"))\n",
    "\n",
    "temp_df = pd.read_csv(os.path.join(jc_path,\"test_labels.csv\"))\n",
    "\n",
    "jc_test_df = jc_test_df.merge ( temp_df, on =\"id\")\n",
    "print(f\"jc_test_df:{jc_test_df.shape}\")\n",
    "jc_test_df = jc_test_df.query (\"toxic != -1\")\n",
    "print(f\"jc_test_df:{jc_test_df.shape}\")\n",
    "df = jc_train_df.append(jc_test_df)\n",
    "\n",
    "\n",
    "df[\"toxic_flag\"] = df[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]].sum(axis=1)\n",
    "df = df.rename(columns={'comment_text': 'text'})\n",
    "\n",
    "\n",
    "\n",
    "#undersample non toxic comments  on Toxic Comment Classification Challenge\n",
    "min_len = (df['toxic_flag'] >= 1).sum() \n",
    "df_y0_undersample = df[df['toxic_flag'] == 0].sample(n=int(min_len*2.5),random_state=201)\n",
    "df = pd.concat([df[df['toxic_flag'] >= 1], df_y0_undersample])\n",
    "\n",
    "toxic = 0.71\n",
    "severe_toxic = 0.75\n",
    "obscene = 1.47\n",
    "threat = 0.0\n",
    "insult = 0.66\n",
    "identity_hate = 1.36 \n",
    "\n",
    "\n",
    "df['y'] = df[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]].max(axis=1)\n",
    "df['y'] = df[\"y\"]+df['toxic']*toxic\n",
    "df['y'] = df[\"y\"]+df['severe_toxic']*severe_toxic\n",
    "df['y'] = df[\"y\"]+df['obscene']*obscene\n",
    "df['y'] = df[\"y\"]+df['threat']*threat\n",
    "df['y'] = df[\"y\"]+df['insult']*insult\n",
    "df['y'] = df[\"y\"]+df['identity_hate']*identity_hate\n",
    "y = df['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T08:23:11.152725Z",
     "iopub.status.busy": "2021-12-10T08:23:11.152208Z",
     "iopub.status.idle": "2021-12-10T08:23:11.161200Z",
     "shell.execute_reply": "2021-12-10T08:23:11.159994Z",
     "shell.execute_reply.started": "2021-12-10T08:23:11.152685Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form for NLP. Operations include the following:-\n",
    "    1. Remove special charecters like &, #, etc\n",
    "    2. Removes extra spaces\n",
    "    3. Removes embedded URL links\n",
    "    4. Removes HTML tags\n",
    "    5. Removes emojis\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T08:23:11.162681Z",
     "iopub.status.busy": "2021-12-10T08:23:11.162358Z",
     "iopub.status.idle": "2021-12-10T08:23:11.181597Z",
     "shell.execute_reply": "2021-12-10T08:23:11.180420Z",
     "shell.execute_reply.started": "2021-12-10T08:23:11.162642Z"
    }
   },
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "# df['text'] = df['text'].progress_apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T08:23:11.183735Z",
     "iopub.status.busy": "2021-12-10T08:23:11.183237Z",
     "iopub.status.idle": "2021-12-10T08:23:59.213623Z",
     "shell.execute_reply": "2021-12-10T08:23:59.212744Z",
     "shell.execute_reply.started": "2021-12-10T08:23:11.183690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78638, 280403)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(analyzer='char_wb', max_df=0.5, min_df=3, ngram_range=(3, 5) )\n",
    "\n",
    "X = vec.fit_transform(df['text'])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T08:23:59.215733Z",
     "iopub.status.busy": "2021-12-10T08:23:59.215036Z",
     "iopub.status.idle": "2021-12-10T08:24:38.867798Z",
     "shell.execute_reply": "2021-12-10T08:24:38.866585Z",
     "shell.execute_reply.started": "2021-12-10T08:23:59.215688Z"
    }
   },
   "outputs": [],
   "source": [
    "### validate\n",
    "jts_path=r\"C:\\Users\\Lenovo\\Desktop\\stupidcode\\data\\jigsaw\\jigsaw-toxic-severity-rating\"\n",
    "\n",
    "df_val = pd.read_csv(os.path.join(jts_path,\"validation_data.csv\"))\n",
    "\n",
    "X_less_toxic = vec.transform(df_val['less_toxic'])\n",
    "X_more_toxic = vec.transform(df_val['more_toxic'])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T08:24:38.870033Z",
     "iopub.status.busy": "2021-12-10T08:24:38.869737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6881559718347283"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Ridge(alpha = 1.0)\n",
    "model.fit(X, df['y'])\n",
    "\n",
    "\n",
    "ridge_p1 = model.predict(X_less_toxic)\n",
    "ridge_p2 = model.predict(X_more_toxic)\n",
    "\n",
    "# Validation Accuracy\n",
    "(ridge_p1< ridge_p2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 16.624657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.674006908462867"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,df['y'],test_size = 0.1,random_state = 0)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train,y_train)\n",
    "lgb_eval = lgb.Dataset(X_test,y_test,reference=lgb_train)\n",
    "\n",
    "params = {'task':'train',\n",
    "    'boosting_type':'gbdt',\n",
    "    'objective':'regression',\n",
    "    'metric':{'l2','mae'},\n",
    "    'num_leaves':31,\n",
    "    'learning_rate':0.05,\n",
    "    'feature_fraction':0.9,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq':5,\n",
    "    'verbose':0}\n",
    "\n",
    "gbm = lgb.train(params,lgb_train,\n",
    "    num_boost_round=100,\n",
    "    valid_sets=lgb_eval,\n",
    "    early_stopping_rounds=5, \n",
    "    verbose_eval=False)  \n",
    "\n",
    "lgb_p1 = gbm.predict(X_less_toxic,num_iteration=gbm.best_iteration) \n",
    "lgb_p2 = gbm.predict(X_more_toxic,num_iteration=gbm.best_iteration) \n",
    "\n",
    "(lgb_p1< lgb_p2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6909127142287764"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_percentage=0.85\n",
    "f2_percentage=1-f1_percentage\n",
    "p1=f1_percentage*ridge_p1+f2_percentage*lgb_p1\n",
    "p2=f1_percentage*ridge_p2+f2_percentage*lgb_p2\n",
    "(p1< p2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T14:27:08.168359Z",
     "iopub.status.busy": "2021-12-09T14:27:08.168065Z",
     "iopub.status.idle": "2021-12-09T14:27:14.716368Z",
     "shell.execute_reply": "2021-12-09T14:27:14.715867Z",
     "shell.execute_reply.started": "2021-12-09T14:27:08.16832Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(os.path.join(jts_path,\"comments_to_score.csv\"))\n",
    "X_test = vec.transform(df_sub['text'])\n",
    "score1 = model.predict(X_test)\n",
    "score2=gbm.predict(X_test,num_iteration=gbm.best_iteration)\n",
    "\n",
    "score=0.5*score1+0.5*score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>\"\\n \\n\\nGjalexei, you asked about whether there is an \"\"anti-editorializing\"\" policy here.  There is, and it's called wikipedia:neutral point of view.  It discusses at some length  the case of what we should do when writing about a subject which most of us find repugnant.  Whilst you're not like...</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>Looks like be have an abuser , can you please look into this?  thanks.</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>I confess to having complete (and apparently blissful) ignorance of Jordan, but I've glanced at the article. Is this a woman or a soap opera!?.  I don't think there was much to change in terms of the description of the various diseases.  It is mentioned that she is famous for the size of her bre...</td>\n",
       "      <td>1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>\"\\n\\nFreud's ideas are certainly much discussed today, and I would be the first to agree that they must be grappled with and dealt with seriously, if only because of their currency.  So Freud deserves a long and thorough article in Wikipedia.  I believe that a balanced article would include A) e...</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>It is not just you. This is a laundry list of stupid allegations scooped up from god-knows-where. Probably two-thirds of it has little basis in fact.</td>\n",
       "      <td>4388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id  \\\n",
       "0      114890   \n",
       "1      732895   \n",
       "2     1139051   \n",
       "3     1434512   \n",
       "4     2084821   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                          text  \\\n",
       "0  \"\\n \\n\\nGjalexei, you asked about whether there is an \"\"anti-editorializing\"\" policy here.  There is, and it's called wikipedia:neutral point of view.  It discusses at some length  the case of what we should do when writing about a subject which most of us find repugnant.  Whilst you're not like...   \n",
       "1                                                                                                                                                                                                                                       Looks like be have an abuser , can you please look into this?  thanks.   \n",
       "2  I confess to having complete (and apparently blissful) ignorance of Jordan, but I've glanced at the article. Is this a woman or a soap opera!?.  I don't think there was much to change in terms of the description of the various diseases.  It is mentioned that she is famous for the size of her bre...   \n",
       "3  \"\\n\\nFreud's ideas are certainly much discussed today, and I would be the first to agree that they must be grappled with and dealt with seriously, if only because of their currency.  So Freud deserves a long and thorough article in Wikipedia.  I believe that a balanced article would include A) e...   \n",
       "4                                                                                                                                                        It is not just you. This is a laundry list of stupid allegations scooped up from god-knows-where. Probably two-thirds of it has little basis in fact.   \n",
       "\n",
       "   score  \n",
       "0    393  \n",
       "1    819  \n",
       "2   1096  \n",
       "3   1272  \n",
       "4   4388  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## to enforce unique values on score\n",
    "df_sub['score'] = rankdata(score, method='ordinal')\n",
    "df_sub[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
