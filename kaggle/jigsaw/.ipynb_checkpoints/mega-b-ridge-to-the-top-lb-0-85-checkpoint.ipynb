{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae2daf6",
   "metadata": {
    "papermill": {
     "duration": 0.042318,
     "end_time": "2021-11-18T17:28:49.265127",
     "exception": false,
     "start_time": "2021-11-18T17:28:49.222809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0.82+ score by ensemble of simple TF-Idf and Ridge regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661e4fd",
   "metadata": {
    "papermill": {
     "duration": 0.03865,
     "end_time": "2021-11-18T17:28:49.342472",
     "exception": false,
     "start_time": "2021-11-18T17:28:49.303822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Built on top of the amazing notebook here : \n",
    "https://www.kaggle.com/julian3833/jigsaw-incredibly-simple-naive-bayes-0-768\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cea245",
   "metadata": {
    "papermill": {
     "duration": 0.038131,
     "end_time": "2021-11-18T17:28:49.419151",
     "exception": false,
     "start_time": "2021-11-18T17:28:49.381020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08a93d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:28:49.511062Z",
     "iopub.status.busy": "2021-11-18T17:28:49.509838Z",
     "iopub.status.idle": "2021-11-18T17:28:50.846403Z",
     "shell.execute_reply": "2021-11-18T17:28:50.845461Z",
     "shell.execute_reply.started": "2021-11-18T17:05:22.443950Z"
    },
    "papermill": {
     "duration": 1.389085,
     "end_time": "2021-11-18T17:28:50.846646",
     "exception": false,
     "start_time": "2021-11-18T17:28:49.457561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import re \n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import gc \n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth=300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae35d7",
   "metadata": {
    "papermill": {
     "duration": 0.038864,
     "end_time": "2021-11-18T17:28:50.925566",
     "exception": false,
     "start_time": "2021-11-18T17:28:50.886702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training data \n",
    "\n",
    "## Convert the label to SUM of all toxic labels (This might help with maintaining toxicity order of comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ac04a96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:28:51.009786Z",
     "iopub.status.busy": "2021-11-18T17:28:51.008716Z",
     "iopub.status.idle": "2021-11-18T17:28:53.204544Z",
     "shell.execute_reply": "2021-11-18T17:28:53.203972Z",
     "shell.execute_reply.started": "2021-11-18T17:05:22.934145Z"
    },
    "papermill": {
     "duration": 2.240124,
     "end_time": "2021-11-18T17:28:53.204732",
     "exception": false,
     "start_time": "2021-11-18T17:28:50.964608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    }
   ],
   "source": [
    "jc_path=r\"C:\\Users\\Lenovo\\Desktop\\stupidcode\\data\\jigsaw\\Jigsaw Rate Severity of T\"\n",
    "df = pd.read_csv(os.path.join(jc_path,\"train.csv\"))\n",
    "print(df.shape)\n",
    "\n",
    "save_df_path=r\"C:\\Users\\Lenovo\\Desktop\\stupidcode\\data\\jigsaw\\mega_b_ridge_to_the_top_lb_0.85\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2d00d17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:28:53.306537Z",
     "iopub.status.busy": "2021-11-18T17:28:53.305784Z",
     "iopub.status.idle": "2021-11-18T17:28:53.355996Z",
     "shell.execute_reply": "2021-11-18T17:28:53.356515Z",
     "shell.execute_reply.started": "2021-11-18T17:05:24.067589Z"
    },
    "papermill": {
     "duration": 0.104695,
     "end_time": "2021-11-18T17:28:53.356728",
     "exception": false,
     "start_time": "2021-11-18T17:28:53.252033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78555</th>\n",
       "      <td>Sieg Heil! \\n\\nHeil Hitler you gay noob!! I'm gonna cut off your brain!</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136745</th>\n",
       "      <td>What does that have to do with this article? Take whatever preconceived notions you have about me and shove them up your pussy.</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21067</th>\n",
       "      <td>\"\\n\\n Wikipedia:Wikipedia Loves Art \\nFirst off, I apologize for the spam. You are receiving this message because you have indicated that you are in Southern California or interested in Southern California topics (either  via category or WikiProject).\\n\\nI would like to invite you to the Los Ang...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97957</th>\n",
       "      <td>There was no consensus not to support it either. That's how a consensus works  unless a consensus exists one way or another, there is no consensus on the issue, and it is inappropriate to use it as a reasoning in an edit. What you're doing is just wikilawyering here to enter edit warring rather ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143472</th>\n",
       "      <td>Girls.. Reverted edits. Please. email or fax me first as I tend to loosse all the information. Im beginning to get tired of remembering all my past entries. Thanks.(  )</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                               text  \\\n",
       "78555                                                                                                                                                                                                                                       Sieg Heil! \\n\\nHeil Hitler you gay noob!! I'm gonna cut off your brain!   \n",
       "136745                                                                                                                                                                              What does that have to do with this article? Take whatever preconceived notions you have about me and shove them up your pussy.   \n",
       "21067   \"\\n\\n Wikipedia:Wikipedia Loves Art \\nFirst off, I apologize for the spam. You are receiving this message because you have indicated that you are in Southern California or interested in Southern California topics (either  via category or WikiProject).\\n\\nI would like to invite you to the Los Ang...   \n",
       "97957   There was no consensus not to support it either. That's how a consensus works  unless a consensus exists one way or another, there is no consensus on the issue, and it is inappropriate to use it as a reasoning in an edit. What you're doing is just wikilawyering here to enter edit warring rather ...   \n",
       "143472                                                                                                                                     Girls.. Reverted edits. Please. email or fax me first as I tend to loosse all the information. Im beginning to get tired of remembering all my past entries. Thanks.(  )   \n",
       "\n",
       "               y  \n",
       "78555   0.714286  \n",
       "136745  0.428571  \n",
       "21067   0.000000  \n",
       "97957   0.000000  \n",
       "143472  0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Give more weight to severe toxic \n",
    "df['severe_toxic'] = df.severe_toxic * 2\n",
    "df['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) ).astype(int)\n",
    "#毒性值归一化\n",
    "df['y'] = df['y']/df['y'].max()\n",
    "\n",
    "df = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ae5e5",
   "metadata": {
    "papermill": {
     "duration": 0.047097,
     "end_time": "2021-11-18T17:28:53.648116",
     "exception": false,
     "start_time": "2021-11-18T17:28:53.601019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create 3 versions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6de9ebfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:28:53.745854Z",
     "iopub.status.busy": "2021-11-18T17:28:53.745130Z",
     "iopub.status.idle": "2021-11-18T17:28:55.688320Z",
     "shell.execute_reply": "2021-11-18T17:28:55.687672Z",
     "shell.execute_reply.started": "2021-11-18T17:05:24.123752Z"
    },
    "papermill": {
     "duration": 1.993565,
     "end_time": "2021-11-18T17:28:55.688475",
     "exception": false,
     "start_time": "2021-11-18T17:28:53.694910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "(32450, 2)\n",
      "0.000000    19470\n",
      "0.142857     5070\n",
      "0.428571     3251\n",
      "0.285714     2751\n",
      "0.714286      853\n",
      "0.571429      766\n",
      "0.857143      263\n",
      "1.000000       26\n",
      "Name: y, dtype: int64\n",
      "Fold: 1\n",
      "(32450, 2)\n",
      "0.000000    19470\n",
      "0.142857     5077\n",
      "0.428571     3257\n",
      "0.285714     2738\n",
      "0.714286      844\n",
      "0.571429      770\n",
      "0.857143      270\n",
      "1.000000       24\n",
      "Name: y, dtype: int64\n",
      "Fold: 2\n",
      "(32450, 2)\n",
      "0.000000    19470\n",
      "0.142857     5086\n",
      "0.428571     3246\n",
      "0.285714     2752\n",
      "0.714286      833\n",
      "0.571429      769\n",
      "0.857143      273\n",
      "1.000000       21\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#抽样 1：1.5 正负样本比例的 data\n",
    "n_folds = 3\n",
    "\n",
    "frac_1 = 0.8\n",
    "frac_1_factor = 1.5\n",
    "\n",
    "for fld in range(n_folds):\n",
    "    print(f'Fold: {fld}')\n",
    "    tmp_df = pd.concat([df[df.y>0].sample(frac=frac_1, random_state = 10*(fld+1)) , \n",
    "                        df[df.y==0].sample(n=int(len(df[df.y>0])*frac_1*frac_1_factor) , \n",
    "                                            random_state = 10*(fld+1))], axis=0).sample(frac=1, random_state = 10*(fld+1))\n",
    "\n",
    "    tmp_df.to_csv(os.path.join(save_df_path,f'df_fld{fld}.csv'), index=False)\n",
    "    print(tmp_df.shape)\n",
    "    print(tmp_df['y'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636ad27",
   "metadata": {
    "papermill": {
     "duration": 0.047737,
     "end_time": "2021-11-18T17:28:55.786236",
     "exception": false,
     "start_time": "2021-11-18T17:28:55.738499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create 3 versions of __clean__ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21164939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:28:55.892702Z",
     "iopub.status.busy": "2021-11-18T17:28:55.891949Z",
     "iopub.status.idle": "2021-11-18T17:28:55.894311Z",
     "shell.execute_reply": "2021-11-18T17:28:55.893728Z",
     "shell.execute_reply.started": "2021-11-18T17:05:25.447133Z"
    },
    "papermill": {
     "duration": 0.060447,
     "end_time": "2021-11-18T17:28:55.894466",
     "exception": false,
     "start_time": "2021-11-18T17:28:55.834019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heyy\\n\\nkkdsfj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi   how/are/you ???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey?????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noooo!!!!!!!!!   comeone !!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cooooooooool     brooooooooooo  coool brooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>naaaahhhhhhh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text\n",
       "0                               heyy\\n\\nkkdsfj\n",
       "1                         hi   how/are/you ???\n",
       "2                                     hey?????\n",
       "3                 noooo!!!!!!!!!   comeone !! \n",
       "4  cooooooooool     brooooooooooo  coool brooo\n",
       "5                                 naaaahhhhhhh"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heyy \\n \\n kkdsfj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi how / are/you ???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey ???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noo !!! comeone !!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coool broo coool broo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>naaahh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text\n",
       "0      heyy \\n \\n kkdsfj\n",
       "1   hi how / are/you ???\n",
       "2                hey ???\n",
       "3     noo !!! comeone !!\n",
       "4  coool broo coool broo\n",
       "5                 naaahh"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(data, col):\n",
    "    #数据清洗 \n",
    "    \n",
    "    # Clean some punctutations\n",
    "    data[col] = data[col].str.replace('\\n', ' \\n ')\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n",
    "    # Replace repeating characters more than 3 times to length of 3\n",
    "    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')    \n",
    "    # Add space around repeating characters\n",
    "    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ')    \n",
    "    # patterns with repeating characters \n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n",
    "    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n",
    "    \n",
    "    return data\n",
    "\n",
    "# Test clean function\n",
    "test_clean_df = pd.DataFrame({\"text\":\n",
    "                              [\"heyy\\n\\nkkdsfj\",\n",
    "                               \"hi   how/are/you ???\",\n",
    "                               \"hey?????\",\n",
    "                               \"noooo!!!!!!!!!   comeone !! \",\n",
    "                              \"cooooooooool     brooooooooooo  coool brooo\",\n",
    "                              \"naaaahhhhhhh\"]})\n",
    "display(test_clean_df)\n",
    "clean(test_clean_df,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dee463d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:28:56.121164Z",
     "iopub.status.busy": "2021-11-18T17:28:56.120417Z",
     "iopub.status.idle": "2021-11-18T17:29:48.371126Z",
     "shell.execute_reply": "2021-11-18T17:29:48.370468Z",
     "shell.execute_reply.started": "2021-11-18T17:05:26.651927Z"
    },
    "papermill": {
     "duration": 52.304692,
     "end_time": "2021-11-18T17:29:48.371312",
     "exception": false,
     "start_time": "2021-11-18T17:28:56.066620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = clean(df,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80873db0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:29:48.472195Z",
     "iopub.status.busy": "2021-11-18T17:29:48.471203Z",
     "iopub.status.idle": "2021-11-18T17:29:50.401852Z",
     "shell.execute_reply": "2021-11-18T17:29:50.401313Z",
     "shell.execute_reply.started": "2021-11-18T17:05:46.652731Z"
    },
    "papermill": {
     "duration": 1.982049,
     "end_time": "2021-11-18T17:29:50.402018",
     "exception": false,
     "start_time": "2021-11-18T17:29:48.419969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "(32450, 2)\n",
      "0.000000    19470\n",
      "0.142857     5070\n",
      "0.428571     3251\n",
      "0.285714     2751\n",
      "0.714286      853\n",
      "0.571429      766\n",
      "0.857143      263\n",
      "1.000000       26\n",
      "Name: y, dtype: int64\n",
      "Fold: 1\n",
      "(32450, 2)\n",
      "0.000000    19470\n",
      "0.142857     5077\n",
      "0.428571     3257\n",
      "0.285714     2738\n",
      "0.714286      844\n",
      "0.571429      770\n",
      "0.857143      270\n",
      "1.000000       24\n",
      "Name: y, dtype: int64\n",
      "Fold: 2\n",
      "(32450, 2)\n",
      "0.000000    19470\n",
      "0.142857     5086\n",
      "0.428571     3246\n",
      "0.285714     2752\n",
      "0.714286      833\n",
      "0.571429      769\n",
      "0.857143      273\n",
      "1.000000       21\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n_folds = 3\n",
    "\n",
    "frac_1 = 0.8\n",
    "frac_1_factor = 1.5\n",
    "\n",
    "for fld in range(n_folds):\n",
    "    print(f'Fold: {fld}')\n",
    "    tmp_df = pd.concat([df[df.y>0].sample(frac=frac_1, random_state = 10*(fld+1)) , \n",
    "                        df[df.y==0].sample(n=int(len(df[df.y>0])*frac_1*frac_1_factor) , \n",
    "                                            random_state = 10*(fld+1))], axis=0).sample(frac=1, random_state = 10*(fld+1))\n",
    "\n",
    "    tmp_df.to_csv(os.path.join(save_df_path,f'df_clean_fld{fld}.csv'), index=False)\n",
    "    print(tmp_df.shape)\n",
    "    print(tmp_df['y'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0c40637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:29:50.659186Z",
     "iopub.status.busy": "2021-11-18T17:29:50.532911Z",
     "iopub.status.idle": "2021-11-18T17:29:50.663102Z",
     "shell.execute_reply": "2021-11-18T17:29:50.662418Z",
     "shell.execute_reply.started": "2021-11-18T17:05:47.934263Z"
    },
    "papermill": {
     "duration": 0.210967,
     "end_time": "2021-11-18T17:29:50.663243",
     "exception": false,
     "start_time": "2021-11-18T17:29:50.452276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "470"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df,tmp_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba4f969",
   "metadata": {
    "papermill": {
     "duration": 0.049616,
     "end_time": "2021-11-18T17:29:50.763781",
     "exception": false,
     "start_time": "2021-11-18T17:29:50.714165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ruddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dc4cd45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:29:50.871865Z",
     "iopub.status.busy": "2021-11-18T17:29:50.871190Z",
     "iopub.status.idle": "2021-11-18T17:29:51.217454Z",
     "shell.execute_reply": "2021-11-18T17:29:51.216827Z",
     "shell.execute_reply.started": "2021-11-18T17:05:48.248121Z"
    },
    "papermill": {
     "duration": 0.403751,
     "end_time": "2021-11-18T17:29:51.217633",
     "exception": false,
     "start_time": "2021-11-18T17:29:50.813882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5838, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_path=r\"C:\\Users\\Lenovo\\Desktop\\stupidcode\\data\\jigsaw\\ruddit jigsaw dataset\\Dataset\"\n",
    "\n",
    "df_ =pd.read_csv(os.path.join(run_path,\"ruddit_with_text.csv\"))\n",
    "print(df_.shape)\n",
    "\n",
    "df_ = df_[['txt', 'offensiveness_score']].rename(columns={'txt': 'text',\n",
    "                                                                'offensiveness_score':'y'})\n",
    "\n",
    "df_['y'] = (df_['y'] - df_.y.min()) / (df_.y.max() - df_.y.min()) \n",
    "df_.y.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169c32c",
   "metadata": {
    "papermill": {
     "duration": 0.051197,
     "end_time": "2021-11-18T17:29:51.320374",
     "exception": false,
     "start_time": "2021-11-18T17:29:51.269177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create 3 versions of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a9fda18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:29:51.429280Z",
     "iopub.status.busy": "2021-11-18T17:29:51.428620Z",
     "iopub.status.idle": "2021-11-18T17:29:51.610113Z",
     "shell.execute_reply": "2021-11-18T17:29:51.610642Z",
     "shell.execute_reply.started": "2021-11-18T17:05:48.529817Z"
    },
    "papermill": {
     "duration": 0.239084,
     "end_time": "2021-11-18T17:29:51.610826",
     "exception": false,
     "start_time": "2021-11-18T17:29:51.371742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "(4670, 2)\n",
      "0.464668    136\n",
      "0.475910    122\n",
      "0.386510    104\n",
      "0.408994    101\n",
      "0.453426     99\n",
      "           ... \n",
      "0.806210      1\n",
      "0.439507      1\n",
      "0.954497      1\n",
      "0.054604      1\n",
      "1.000000      1\n",
      "Name: y, Length: 273, dtype: int64\n",
      "Fold: 1\n",
      "(4670, 2)\n",
      "0.464668    127\n",
      "0.475910    114\n",
      "0.386510    108\n",
      "0.408994    107\n",
      "0.364561    103\n",
      "           ... \n",
      "0.715203      1\n",
      "0.085653      1\n",
      "0.666488      1\n",
      "0.940043      1\n",
      "1.000000      1\n",
      "Name: y, Length: 274, dtype: int64\n",
      "Fold: 2\n",
      "(4670, 2)\n",
      "0.464668    133\n",
      "0.475910    122\n",
      "0.442719    110\n",
      "0.386510    108\n",
      "0.364561    102\n",
      "           ... \n",
      "0.862955      1\n",
      "0.941649      1\n",
      "0.309422      1\n",
      "0.068522      1\n",
      "1.000000      1\n",
      "Name: y, Length: 274, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n_folds = 3\n",
    "\n",
    "frac_1 = 0.8\n",
    "\n",
    "for fld in range(n_folds):\n",
    "    print(f'Fold: {fld}')\n",
    "    tmp_df = df_.sample(frac=frac_1, random_state = 10*(fld+1))\n",
    "    tmp_df.to_csv(os.path.join(save_df_path,f'df2_fld{fld}.csv'), index=False)\n",
    "    print(tmp_df.shape)\n",
    "    print(tmp_df['y'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68b14bd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:29:51.717959Z",
     "iopub.status.busy": "2021-11-18T17:29:51.717307Z",
     "iopub.status.idle": "2021-11-18T17:29:51.830451Z",
     "shell.execute_reply": "2021-11-18T17:29:51.829798Z",
     "shell.execute_reply.started": "2021-11-18T17:05:48.679248Z"
    },
    "papermill": {
     "duration": 0.16763,
     "end_time": "2021-11-18T17:29:51.830644",
     "exception": false,
     "start_time": "2021-11-18T17:29:51.663014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tmp_df, df_; \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936a069",
   "metadata": {
    "papermill": {
     "duration": 0.052669,
     "end_time": "2021-11-18T17:29:51.936172",
     "exception": false,
     "start_time": "2021-11-18T17:29:51.883503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Validation and Test data  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "839f62c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:29:52.044841Z",
     "iopub.status.busy": "2021-11-18T17:29:52.044003Z",
     "iopub.status.idle": "2021-11-18T17:29:52.530297Z",
     "shell.execute_reply": "2021-11-18T17:29:52.529562Z",
     "shell.execute_reply.started": "2021-11-18T17:05:48.889641Z"
    },
    "papermill": {
     "duration": 0.541825,
     "end_time": "2021-11-18T17:29:52.530440",
     "exception": false,
     "start_time": "2021-11-18T17:29:51.988615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validation data \n",
    "jts_path=r\"C:\\Users\\Lenovo\\Desktop\\stupidcode\\data\\jigsaw\\jigsaw-toxic-severity-rating\"\n",
    "\n",
    "df_val = pd.read_csv(os.path.join(jts_path,\"validation_data.csv\"))\n",
    "\n",
    "# Test data\n",
    "\n",
    "df_sub = pd.read_csv(os.path.join(jts_path,\"comments_to_score.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef028c",
   "metadata": {
    "papermill": {
     "duration": 0.052081,
     "end_time": "2021-11-18T17:29:52.842377",
     "exception": false,
     "start_time": "2021-11-18T17:29:52.790296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Sklearn Pipeline with \n",
    "## TFIDF - Take 'char_wb' as analyzer to capture subwords well\n",
    "## Ridge - Ridge is a simple regression algorithm that will reduce overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b1ac0",
   "metadata": {
    "papermill": {
     "duration": 0.052838,
     "end_time": "2021-11-18T17:29:55.481024",
     "exception": false,
     "start_time": "2021-11-18T17:29:55.428186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train pipeline\n",
    "\n",
    "- Load folds data\n",
    "- train pipeline\n",
    "- Predict on validation data\n",
    "- Predict on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1972941e",
   "metadata": {
    "papermill": {
     "duration": 0.053351,
     "end_time": "2021-11-18T17:29:55.587753",
     "exception": false,
     "start_time": "2021-11-18T17:29:55.534402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Toxic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7bbac41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:29:55.703346Z",
     "iopub.status.busy": "2021-11-18T17:29:55.702668Z",
     "iopub.status.idle": "2021-11-18T17:34:44.820040Z",
     "shell.execute_reply": "2021-11-18T17:34:44.820692Z",
     "shell.execute_reply.started": "2021-11-18T17:07:26.954339Z"
    },
    "papermill": {
     "duration": 289.179884,
     "end_time": "2021-11-18T17:34:44.821136",
     "exception": false,
     "start_time": "2021-11-18T17:29:55.641252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ridge_cv(folder_pre):\n",
    "    val_preds_arr1 = np.zeros((df_val.shape[0], n_folds))\n",
    "    val_preds_arr2 = np.zeros((df_val.shape[0], n_folds))\n",
    "    test_preds_arr = np.zeros((df_sub.shape[0], n_folds))\n",
    "\n",
    "    for fld in range(n_folds):\n",
    "        print(\"\\n\\n\")\n",
    "        print(f' ****************************** FOLD: {fld} ******************************')\n",
    "        df = pd.read_csv(os.path.join(save_df_path,f'{folder_pre}{fld}.csv'))\n",
    "        print(df.shape)\n",
    "\n",
    "        features = FeatureUnion([\n",
    "            (\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))),\n",
    "            #(\"vect4\", TfidfVectorizer(min_df= 5, max_df=0.5, analyzer = 'word', token_pattern=r'(?u)\\b\\w{8,}\\b')),\n",
    "\n",
    "        ])\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"features\", features),\n",
    "                #(\"clf\", RandomForestRegressor(n_estimators = 5, min_sample_leaf=3)),\n",
    "                (\"clf\", Ridge()),\n",
    "                #(\"clf\",LinearRegression())\n",
    "            ]\n",
    "        )\n",
    "        print(\"\\nTrain:\")\n",
    "        # Train the pipeline\n",
    "        pipeline.fit(df['text'], df['y'])\n",
    "\n",
    "        # What are the important features for toxicity\n",
    "\n",
    "        print('\\nTotal number of features:', len(pipeline['features'].get_feature_names()) )\n",
    "\n",
    "        feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), \n",
    "                                      np.round(pipeline['clf'].coef_,2) )), \n",
    "                             key = lambda x:x[1], \n",
    "                             reverse=True)\n",
    "\n",
    "        pprint(feature_wts[:30])\n",
    "\n",
    "        print(\"\\npredict validation data \")\n",
    "        val_preds_arr1[:,fld] = pipeline.predict(df_val['less_toxic'])\n",
    "        val_preds_arr2[:,fld] = pipeline.predict(df_val['more_toxic'])\n",
    "\n",
    "        print(\"\\npredict test data \")\n",
    "        test_preds_arr[:,fld] = pipeline.predict(df_sub['text'])\n",
    "        \n",
    "    return val_preds_arr1.mean(axis=1),val_preds_arr2.mean(axis=1),test_preds_arr.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113762d",
   "metadata": {
    "papermill": {
     "duration": 0.065357,
     "end_time": "2021-11-18T17:42:37.612788",
     "exception": false,
     "start_time": "2021-11-18T17:42:37.547431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Validate the pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5459ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:42:37.765711Z",
     "iopub.status.busy": "2021-11-18T17:42:37.764988Z",
     "iopub.status.idle": "2021-11-18T17:42:37.775538Z",
     "shell.execute_reply": "2021-11-18T17:42:37.775014Z",
     "shell.execute_reply.started": "2021-11-18T17:16:42.442637Z"
    },
    "papermill": {
     "duration": 0.091504,
     "end_time": "2021-11-18T17:42:37.775696",
     "exception": false,
     "start_time": "2021-11-18T17:42:37.684192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Toxic data \n",
      "\n",
      "\n",
      "\n",
      " ****************************** FOLD: 0 ******************************\n",
      "(32450, 2)\n",
      "\n",
      "Train:\n",
      "\n",
      "Total number of features: 158204\n",
      "[('vect3__uck', 0.55),\n",
      " ('vect3__fuc', 0.5),\n",
      " ('vect3__ ass', 0.39),\n",
      " ('vect3__fuck', 0.37),\n",
      " ('vect3__fag', 0.34),\n",
      " ('vect3__ f ', 0.33),\n",
      " ('vect3__ass', 0.31),\n",
      " ('vect3__shit', 0.31),\n",
      " ('vect3__ f*', 0.3),\n",
      " ('vect3__ fag', 0.3),\n",
      " ('vect3__gay', 0.3),\n",
      " ('vect3__nig', 0.3),\n",
      " ('vect3__ fu', 0.29),\n",
      " ('vect3__fuk', 0.29),\n",
      " ('vect3__dick', 0.28),\n",
      " ('vect3__nigg', 0.28),\n",
      " ('vect3__nl3', 0.28),\n",
      " ('vect3__hit', 0.27),\n",
      " ('vect3__ck ', 0.26),\n",
      " ('vect3__ fuk', 0.25),\n",
      " ('vect3__ gay', 0.25),\n",
      " ('vect3__ die', 0.24),\n",
      " ('vect3__ g ', 0.24),\n",
      " ('vect3__ nl', 0.24),\n",
      " ('vect3__dum', 0.24),\n",
      " ('vect3__gga', 0.24),\n",
      " ('vect3__kill ', 0.24),\n",
      " ('vect3__ je', 0.23),\n",
      " ('vect3__*ck', 0.23),\n",
      " ('vect3__cun', 0.23)]\n",
      "\n",
      "predict validation data \n",
      "\n",
      "predict test data \n",
      "\n",
      "\n",
      "\n",
      " ****************************** FOLD: 1 ******************************\n",
      "(32450, 2)\n",
      "\n",
      "Train:\n",
      "\n",
      "Total number of features: 158677\n",
      "[('vect3__uck', 0.55),\n",
      " ('vect3__fuc', 0.47),\n",
      " ('vect3__ ass', 0.38),\n",
      " ('vect3__fag', 0.36),\n",
      " ('vect3__fuck', 0.35),\n",
      " ('vect3__gay', 0.34),\n",
      " ('vect3__shit', 0.33),\n",
      " ('vect3__ f ', 0.32),\n",
      " ('vect3__ass', 0.32),\n",
      " ('vect3__fuk', 0.31),\n",
      " ('vect3__ fag', 0.3),\n",
      " ('vect3__ fu', 0.29),\n",
      " ('vect3__dick', 0.29),\n",
      " ('vect3__ gay', 0.28),\n",
      " ('vect3__hit', 0.27),\n",
      " ('vect3__l33', 0.27),\n",
      " ('vect3__nig', 0.27),\n",
      " ('vect3__ f*', 0.26),\n",
      " ('vect3__ fuk', 0.26),\n",
      " ('vect3__ nl', 0.26),\n",
      " ('vect3__ck ', 0.26),\n",
      " ('vect3__kkk', 0.26),\n",
      " ('vect3__nigg', 0.26),\n",
      " ('vect3__ die', 0.25),\n",
      " ('vect3__ moro', 0.24),\n",
      " ('vect3__tard', 0.24),\n",
      " ('vect3__ ass.', 0.23),\n",
      " ('vect3__ r ', 0.23),\n",
      " ('vect3__cun', 0.23),\n",
      " ('vect3__cunt', 0.23)]\n",
      "\n",
      "predict validation data \n",
      "\n",
      "predict test data \n",
      "\n",
      "\n",
      "\n",
      " ****************************** FOLD: 2 ******************************\n",
      "(32450, 2)\n",
      "\n",
      "Train:\n",
      "\n",
      "Total number of features: 158027\n",
      "[('vect3__uck', 0.51),\n",
      " ('vect3__fuc', 0.47),\n",
      " ('vect3__fuck', 0.39),\n",
      " ('vect3__ f ', 0.37),\n",
      " ('vect3__ ass', 0.35),\n",
      " ('vect3__gay', 0.33),\n",
      " ('vect3__ f*', 0.32),\n",
      " ('vect3__ass', 0.32),\n",
      " ('vect3__fag', 0.32),\n",
      " ('vect3__fuk', 0.32),\n",
      " ('vect3__shit', 0.31),\n",
      " ('vect3__ fu', 0.3),\n",
      " ('vect3__nig', 0.29),\n",
      " ('vect3__ gay', 0.28),\n",
      " ('vect3__ck ', 0.28),\n",
      " ('vect3__dick', 0.28),\n",
      " ('vect3__l33', 0.28),\n",
      " ('vect3__ fag', 0.27),\n",
      " ('vect3__ fuk', 0.27),\n",
      " ('vect3__ nl', 0.26),\n",
      " ('vect3__]]]', 0.26),\n",
      " ('vect3__hit', 0.26),\n",
      " ('vect3__nigg', 0.26),\n",
      " ('vect3__ g ', 0.25),\n",
      " ('vect3__ moro', 0.25),\n",
      " ('vect3__cun', 0.25),\n",
      " ('vect3__dum', 0.25),\n",
      " ('vect3__ die', 0.24),\n",
      " ('vect3__bitc', 0.24),\n",
      " ('vect3__homo', 0.24)]\n",
      "\n",
      "predict validation data \n",
      "\n",
      "predict test data \n",
      "Validation Accuracy is 68.56\n",
      " Ruddit data \n",
      "\n",
      "\n",
      "\n",
      " ****************************** FOLD: 0 ******************************\n",
      "(4670, 2)\n",
      "\n",
      "Train:\n",
      "\n",
      "Total number of features: 34287\n",
      "[('vect3__fuc', 0.61),\n",
      " ('vect3__fuck', 0.6),\n",
      " ('vect3__uck', 0.55),\n",
      " ('vect3__ fuc', 0.54),\n",
      " ('vect3__ fuck', 0.54),\n",
      " ('vect3__ fu', 0.44),\n",
      " ('vect3__shit', 0.42),\n",
      " ('vect3__hit', 0.39),\n",
      " ('vect3__ shit', 0.37),\n",
      " ('vect3__fuck ', 0.36),\n",
      " ('vect3__ck ', 0.35),\n",
      " ('vect3__uck ', 0.33),\n",
      " ('vect3__ shi', 0.29),\n",
      " ('vect3__shi', 0.29),\n",
      " ('vect3__ ass ', 0.28),\n",
      " ('vect3__sex', 0.28),\n",
      " ('vect3__ ass', 0.26),\n",
      " ('vect3__ dick', 0.26),\n",
      " ('vect3__ sex', 0.25),\n",
      " ('vect3__dick', 0.25),\n",
      " ('vect3__ dic', 0.24),\n",
      " ('vect3__ sh', 0.24),\n",
      " ('vect3__shit ', 0.24),\n",
      " ('vect3__ass', 0.22),\n",
      " ('vect3__ di', 0.2),\n",
      " ('vect3__hit ', 0.2),\n",
      " ('vect3__ kil', 0.19),\n",
      " ('vect3__ kill', 0.19),\n",
      " ('vect3__ex ', 0.19),\n",
      " ('vect3__kill', 0.19)]\n",
      "\n",
      "predict validation data \n",
      "\n",
      "predict test data \n",
      "\n",
      "\n",
      "\n",
      " ****************************** FOLD: 1 ******************************\n",
      "(4670, 2)\n",
      "\n",
      "Train:\n",
      "\n",
      "Total number of features: 34499\n",
      "[('vect3__fuc', 0.61),\n",
      " ('vect3__fuck', 0.61),\n",
      " ('vect3__uck', 0.56),\n",
      " ('vect3__ fuc', 0.54),\n",
      " ('vect3__ fuck', 0.54),\n",
      " ('vect3__ fu', 0.43),\n",
      " ('vect3__shit', 0.39),\n",
      " ('vect3__hit', 0.38),\n",
      " ('vect3__fuck ', 0.37),\n",
      " ('vect3__ shit', 0.36),\n",
      " ('vect3__ck ', 0.36),\n",
      " ('vect3__uck ', 0.35),\n",
      " ('vect3__ ass ', 0.3),\n",
      " ('vect3__ shi', 0.3),\n",
      " ('vect3__shi', 0.29),\n",
      " ('vect3__ dick', 0.28),\n",
      " ('vect3__ ass', 0.27),\n",
      " ('vect3__ sh', 0.27),\n",
      " ('vect3__dick', 0.27),\n",
      " ('vect3__ dic', 0.26),\n",
      " ('vect3__sex', 0.26),\n",
      " ('vect3__ sex', 0.24),\n",
      " ('vect3__ di', 0.21),\n",
      " ('vect3__ kil', 0.21),\n",
      " ('vect3__ kill', 0.21),\n",
      " ('vect3__shit ', 0.21),\n",
      " ('vect3__ass', 0.2),\n",
      " ('vect3__kill', 0.2),\n",
      " ('vect3__ du', 0.19),\n",
      " ('vect3__ dumb', 0.19)]\n",
      "\n",
      "predict validation data \n",
      "\n",
      "predict test data \n",
      "\n",
      "\n",
      "\n",
      " ****************************** FOLD: 2 ******************************\n",
      "(4670, 2)\n",
      "\n",
      "Train:\n",
      "\n",
      "Total number of features: 34214\n",
      "[('vect3__fuc', 0.6),\n",
      " ('vect3__fuck', 0.59),\n",
      " ('vect3__uck', 0.55),\n",
      " ('vect3__ fuc', 0.53),\n",
      " ('vect3__ fuck', 0.53),\n",
      " ('vect3__ fu', 0.43),\n",
      " ('vect3__shit', 0.4),\n",
      " ('vect3__ck ', 0.38),\n",
      " ('vect3__fuck ', 0.38),\n",
      " ('vect3__ shit', 0.36),\n",
      " ('vect3__hit', 0.36),\n",
      " ('vect3__uck ', 0.34),\n",
      " ('vect3__ ass ', 0.31),\n",
      " ('vect3__ ass', 0.3),\n",
      " ('vect3__ dick', 0.3),\n",
      " ('vect3__ shi', 0.29),\n",
      " ('vect3__dick', 0.29),\n",
      " ('vect3__ dic', 0.28),\n",
      " ('vect3__sex', 0.28),\n",
      " ('vect3__shi', 0.28),\n",
      " ('vect3__ sex', 0.25),\n",
      " ('vect3__shit ', 0.25),\n",
      " ('vect3__ sh', 0.24),\n",
      " ('vect3__ass', 0.23),\n",
      " ('vect3__ kill', 0.22),\n",
      " ('vect3__ kil', 0.21),\n",
      " ('vect3__dic', 0.21),\n",
      " ('vect3__ di', 0.2),\n",
      " ('vect3__ dum', 0.2),\n",
      " ('vect3__dum', 0.2)]\n",
      "\n",
      "predict validation data \n",
      "\n",
      "predict test data \n",
      "Validation Accuracy is 62.66\n",
      " Toxic CLEAN data \n",
      "\n",
      "\n",
      "\n",
      " ****************************** FOLD: 0 ******************************\n",
      "(32450, 2)\n",
      "\n",
      "Train:\n",
      "\n",
      "Total number of features: 144097\n",
      "[('vect3__uck', 0.52),\n",
      " ('vect3__ f ', 0.47),\n",
      " ('vect3__fuc', 0.46),\n",
      " ('vect3__ ass', 0.36),\n",
      " ('vect3__fuck', 0.36),\n",
      " ('vect3__ ck', 0.35),\n",
      " ('vect3__fag', 0.33),\n",
      " ('vect3__shit', 0.31),\n",
      " ('vect3__ fu', 0.3),\n",
      " ('vect3__ k ', 0.3),\n",
      " ('vect3__fuk', 0.3),\n",
      " ('vect3__ fag', 0.29),\n",
      " ('vect3__ re ', 0.28),\n",
      " ('vect3__nig', 0.28),\n",
      " ('vect3__ass', 0.27),\n",
      " ('vect3__gay', 0.27),\n",
      " ('vect3__hit', 0.27),\n",
      " ('vect3__nl3', 0.27),\n",
      " ('vect3__ fuk', 0.26),\n",
      " ('vect3__ck ', 0.26),\n",
      " ('vect3__dick', 0.26),\n",
      " ('vect3__gga', 0.26),\n",
      " ('vect3__nigg', 0.26),\n",
      " ('vect3__ gay', 0.25),\n",
      " ('vect3__suck', 0.25),\n",
      " ('vect3__ nl', 0.24),\n",
      " ('vect3__dum', 0.24),\n",
      " ('vect3__ ass ', 0.23),\n",
      " ('vect3__ g ', 0.23),\n",
      " ('vect3__ je', 0.23)]\n",
      "\n",
      "predict validation data \n",
      "\n",
      "predict test data \n",
      "\n",
      "\n",
      "\n",
      " ****************************** FOLD: 1 ******************************\n",
      "(32450, 2)\n",
      "\n",
      "Train:\n",
      "\n",
      "Total number of features: 144568\n",
      "[('vect3__uck', 0.52),\n",
      " ('vect3__fuc', 0.43),\n",
      " ('vect3__ f ', 0.42),\n",
      " ('vect3__fag', 0.36),\n",
      " ('vect3__ ass', 0.35),\n",
      " ('vect3__fuck', 0.34),\n",
      " ('vect3__shit', 0.33),\n",
      " ('vect3__ ck', 0.32),\n",
      " ('vect3__ re ', 0.32),\n",
      " ('vect3__fuk', 0.32),\n",
      " ('vect3__gay', 0.31),\n",
      " ('vect3__ fu', 0.29),\n",
      " ('vect3__ass', 0.29),\n",
      " ('vect3__ fag', 0.28),\n",
      " ('vect3__ck ', 0.28),\n",
      " ('vect3__ fuk', 0.27),\n",
      " ('vect3__ gay', 0.27),\n",
      " ('vect3__dick', 0.27),\n",
      " ('vect3__hit', 0.27),\n",
      " ('vect3__l33', 0.26),\n",
      " ('vect3__nig', 0.25),\n",
      " ('vect3__suck', 0.25),\n",
      " ('vect3__ moro', 0.24),\n",
      " ('vect3__ nl', 0.24),\n",
      " ('vect3__///', 0.24),\n",
      " ('vect3__gga', 0.24),\n",
      " ('vect3__nigg', 0.24),\n",
      " ('vect3__ ass.', 0.23),\n",
      " ('vect3__ die', 0.23),\n",
      " ('vect3__ k ', 0.23)]\n",
      "\n",
      "predict validation data \n",
      "\n",
      "predict test data \n",
      "\n",
      "\n",
      "\n",
      " ****************************** FOLD: 2 ******************************\n",
      "(32450, 2)\n",
      "\n",
      "Train:\n",
      "\n",
      "Total number of features: 143698\n",
      "[('vect3__ f ', 0.48),\n",
      " ('vect3__uck', 0.48),\n",
      " ('vect3__fuc', 0.44),\n",
      " ('vect3__fuck', 0.38),\n",
      " ('vect3__ ck', 0.34),\n",
      " ('vect3__fuk', 0.33),\n",
      " ('vect3__ ass', 0.32),\n",
      " ('vect3__ck ', 0.31),\n",
      " ('vect3__fag', 0.31),\n",
      " ('vect3__ k ', 0.3),\n",
      " ('vect3__ass', 0.3),\n",
      " ('vect3__shit', 0.3),\n",
      " ('vect3__gay', 0.29),\n",
      " ('vect3__ fu', 0.28),\n",
      " ('vect3__ re ', 0.28),\n",
      " ('vect3__l33', 0.28),\n",
      " ('vect3__ fuk', 0.27),\n",
      " ('vect3__ gay', 0.27),\n",
      " ('vect3__dick', 0.27),\n",
      " ('vect3__nig', 0.27),\n",
      " ('vect3__]]]', 0.26),\n",
      " ('vect3__hit', 0.26),\n",
      " ('vect3__ moro', 0.25),\n",
      " ('vect3__ nl', 0.25),\n",
      " ('vect3__ fag', 0.24),\n",
      " ('vect3__cun', 0.24),\n",
      " ('vect3__dum', 0.24),\n",
      " ('vect3__nigg', 0.24),\n",
      " ('vect3__suck', 0.24),\n",
      " ('vect3__ g ', 0.23)]\n",
      "\n",
      "predict validation data \n",
      "\n",
      "predict test data \n",
      "Validation Accuracy is 68.29\n"
     ]
    }
   ],
   "source": [
    "print(\" Toxic data \")\n",
    "\n",
    "p1,p2,pv1=ridge_cv(\"df_fld\")\n",
    "\n",
    "print(f'Validation Accuracy is { np.round((p1 < p2).mean() * 100,2)}')\n",
    "\n",
    "print(\" Ruddit data \")\n",
    "p3,p4,pv2=ridge_cv(\"df2_fld\")\n",
    "\n",
    "print(f'Validation Accuracy is { np.round((p3 < p4).mean() * 100,2)}')\n",
    "\n",
    "print(\" Toxic CLEAN data \")\n",
    "p5,p6,pv3=ridge_cv(\"df_clean_fld\")\n",
    "\n",
    "\n",
    "print(f'Validation Accuracy is { np.round((p5 < p6).mean() * 100,2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "399e58b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:42:37.922213Z",
     "iopub.status.busy": "2021-11-18T17:42:37.921241Z",
     "iopub.status.idle": "2021-11-18T17:42:38.186742Z",
     "shell.execute_reply": "2021-11-18T17:42:38.185913Z",
     "shell.execute_reply.started": "2021-11-18T17:24:28.791965Z"
    },
    "papermill": {
     "duration": 0.337683,
     "end_time": "2021-11-18T17:42:38.186938",
     "exception": false,
     "start_time": "2021-11-18T17:42:37.849255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find right weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.64, 0.21, 0.15, 69.07),\n",
       " (0.68, 0.19, 0.12999999999999995, 69.07),\n",
       " (0.64, 0.2, 0.15999999999999998, 69.06),\n",
       " (0.65, 0.21, 0.13999999999999999, 69.06),\n",
       " (0.66, 0.21, 0.12999999999999998, 69.06)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Find right weight\")\n",
    "\n",
    "wts_acc = []\n",
    "for i in range(30,70,1):\n",
    "    for j in range(0,20,1):\n",
    "        w1 = i/100\n",
    "        w2 = (100 - i - j)/100\n",
    "        w3 = (1 - w1 - w2 )\n",
    "        p1_wt = w1*p1 + w2*p3 + w3*p5\n",
    "        p2_wt = w1*p2 + w2*p4 + w3*p6\n",
    "        wts_acc.append( (w1,w2,w3, \n",
    "                         np.round((p1_wt < p2_wt).mean() * 100,2))\n",
    "                      )\n",
    "sorted(wts_acc, key=lambda x:x[3], reverse=True)[:5]\n",
    "\n",
    "w1,w2,_ = sorted(wts_acc, key=lambda x:x[3], reverse=True)[0]\n",
    "#print(best_wts)\n",
    "\n",
    "p1_wt = w1*p1 + w2*p3 + w3*p5\n",
    "p2_wt = w1*p2 + w2*p4 + w3*p6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c81f2b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find right weight\n",
      "[(0.63, 0.37, 68.5), (0.62, 0.38, 68.49), (0.49, 0.51, 68.48), (0.6, 0.4, 68.48), (0.64, 0.36, 68.48)]\n"
     ]
    }
   ],
   "source": [
    "##############delete clean\n",
    "print(\"Find right weight\")\n",
    "\n",
    "wts_acc = []\n",
    "for i in range(30,70,1):\n",
    "    \n",
    "    w1 = i/100\n",
    "    w2 = 1 - w1\n",
    "\n",
    "    p1_wt = w1*p1 + w2*p5 \n",
    "    p2_wt = w1*p2 + w2*p6 \n",
    "    wts_acc.append( (w1,w2, \n",
    "                     np.round((p1_wt < p2_wt).mean() * 100,2))\n",
    "                  )\n",
    "print(sorted(wts_acc, key=lambda x:x[2], reverse=True)[:5])\n",
    "\n",
    "w1,w2,_ = sorted(wts_acc, key=lambda x:x[2], reverse=True)[0]\n",
    "#print(best_wts)\n",
    "\n",
    "p1_wt = w1*p1 + w2*p5 \n",
    "p2_wt = w1*p2 + w2*p6 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c364fc2",
   "metadata": {
    "papermill": {
     "duration": 0.068774,
     "end_time": "2021-11-18T17:42:39.284968",
     "exception": false,
     "start_time": "2021-11-18T17:42:39.216194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a334267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T17:42:39.428123Z",
     "iopub.status.busy": "2021-11-18T17:42:39.427166Z",
     "iopub.status.idle": "2021-11-18T17:42:39.433610Z",
     "shell.execute_reply": "2021-11-18T17:42:39.433106Z",
     "shell.execute_reply.started": "2021-11-18T17:27:08.378310Z"
    },
    "papermill": {
     "duration": 0.078524,
     "end_time": "2021-11-18T17:42:39.433750",
     "exception": false,
     "start_time": "2021-11-18T17:42:39.355226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict using pipeline\n",
    "\n",
    "df_sub['score'] = w1*pv1 + w2*pv2 + w3*pv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520c79af",
   "metadata": {
    "papermill": {
     "duration": 0.070599,
     "end_time": "2021-11-18T17:42:40.801042",
     "exception": false,
     "start_time": "2021-11-18T17:42:40.730443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sub[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "df_sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 842.659088,
   "end_time": "2021-11-18T17:42:41.686298",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-18T17:28:39.027210",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
