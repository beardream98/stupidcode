{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:32.626552Z",
     "iopub.status.busy": "2022-01-16T07:57:32.626251Z",
     "iopub.status.idle": "2022-01-16T07:57:39.865181Z",
     "shell.execute_reply": "2022-01-16T07:57:39.864196Z",
     "shell.execute_reply.started": "2022-01-16T07:57:32.626522Z"
    },
    "papermill": {
     "duration": 9.26997,
     "end_time": "2021-12-23T03:28:36.18541",
     "exception": false,
     "start_time": "2021-12-23T03:28:26.91544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import string\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, logging\n",
    "from transformers import AlbertConfig, AlbertTokenizer, AlbertModel\n",
    "from transformers import RobertaConfig,RobertaTokenizer, RobertaModel\n",
    "from transformers import BertConfig, BertTokenizer, BertModel\n",
    "from transformers import XLNetConfig, XLNetTokenizer, XLNetModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, SequentialSampler, RandomSampler, DataLoader\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "from torch.cuda.amp import  GradScaler\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gc; gc.enable()\n",
    "from IPython.display import clear_output\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:42.472062Z",
     "iopub.status.busy": "2022-01-16T07:57:42.471725Z",
     "iopub.status.idle": "2022-01-16T07:57:42.4812Z",
     "shell.execute_reply": "2022-01-16T07:57:42.480166Z",
     "shell.execute_reply.started": "2022-01-16T07:57:42.472031Z"
    },
    "papermill": {
     "duration": 0.043418,
     "end_time": "2021-12-23T03:28:50.176898",
     "exception": false,
     "start_time": "2021-12-23T03:28:50.13348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#产生一个哈希值\n",
    "# def id_generator(size=12, chars=string.ascii_lowercase + string.digits):\n",
    "#     return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n",
    "\n",
    "# HASH_NAME = id_generator(size=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032281,
     "end_time": "2021-12-23T03:28:50.24189",
     "exception": false,
     "start_time": "2021-12-23T03:28:50.209609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:42.973734Z",
     "iopub.status.busy": "2022-01-16T07:57:42.97339Z",
     "iopub.status.idle": "2022-01-16T07:57:43.035419Z",
     "shell.execute_reply": "2022-01-16T07:57:43.034294Z",
     "shell.execute_reply.started": "2022-01-16T07:57:42.973706Z"
    },
    "papermill": {
     "duration": 0.102339,
     "end_time": "2021-12-23T03:28:50.376474",
     "exception": false,
     "start_time": "2021-12-23T03:28:50.274135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "CONFIG={\n",
    "    \"TRAIN_BATCH_SIZE\":24,\n",
    "    \"MAX_LENGTH\":128,\n",
    "    \"DEV_BATCH_SIZE\": 64,\n",
    "    \"LR\":2e-5,\n",
    "    \"EPS\":1e-8,\n",
    "    \"weight_decay\":1e-6,\n",
    "    \n",
    "    \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 500,\n",
    "    \"T_0\":500,\n",
    "    \"margin\":0.5,\n",
    "    \"fold_num\":5,\n",
    "    \"seed\":2021,\n",
    "    \"num_class\":1,\n",
    "    \n",
    "    \"EPOCHS\":4,\n",
    "    \"evaluate_step\":None,\n",
    "    \"swa_start\":4,\n",
    "    \"model_init_lr\":0.9e-4,\n",
    "    \"multiplier\":0.9,\n",
    "    \"classifier_lr\":1e-4 ,\n",
    "    \"swa_lr\": 1e-5\n",
    "}\n",
    "input_dir=\"./input/jigsaw-toxic-severity-rating\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更换模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:43.408116Z",
     "iopub.status.busy": "2022-01-16T07:57:43.407603Z",
     "iopub.status.idle": "2022-01-16T07:57:43.415474Z",
     "shell.execute_reply": "2022-01-16T07:57:43.414448Z",
     "shell.execute_reply.started": "2022-01-16T07:57:43.408067Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden_size=\"hidden_size\"\n",
    "num_hidden_layers=\"num_hidden_layers\"\n",
    "OUT_DIR=\"./output/jigsaw_server_xlnet/xlnet_folder\"\n",
    "#for xlnet\n",
    "# hidden_size=\"d_model\"\n",
    "# num_hidden_layers=\"n_layer\"\n",
    "\n",
    "# MODEL_DIR=\"../model/roberta-base\"\n",
    "# MODEL_DIR=\"../model/roberta-large\"\n",
    "\n",
    "# MODEL_DIR=\"../model/albert-large-v2\"\n",
    "\n",
    "MODEL_DIR=\"../model/xlnet_large_cased\"\n",
    "\n",
    "Model_type=\"Xlnet\"\n",
    "tokenizer_func_dict={\"Albert\":AlbertTokenizer,\"auto\":AutoTokenizer,\"Roberta\":RobertaTokenizer,\"Xlnet\":XLNetTokenizer}\n",
    "config_func_dict={\"Albert\":AlbertConfig,\"auto\":AutoConfig,\"Roberta\":RobertaConfig,\"Xlnet\":XLNetConfig}\n",
    "model_func_dict={\"Albert\":AlbertModel,\"auto\":AutoModel,\"Roberta\":RobertaModel,\"Xlnet\":XLNetModel}\n",
    "if Model_type==\"Xlnet\":\n",
    "    hidden_size=\"d_model\"\n",
    "    num_hidden_layers=\"n_layer\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##检查事项\n",
    "* 提交之前 注意 run_db 是否打开 是否创建了正确的hash值\n",
    "* test是否关闭\n",
    "* 如果 换模型 model_dir 是否正确 model struct是否正确\n",
    "* gpu 是否需要打开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:43.765907Z",
     "iopub.status.busy": "2022-01-16T07:57:43.765628Z",
     "iopub.status.idle": "2022-01-16T07:57:43.771476Z",
     "shell.execute_reply": "2022-01-16T07:57:43.770583Z",
     "shell.execute_reply.started": "2022-01-16T07:57:43.765856Z"
    },
    "papermill": {
     "duration": 0.042294,
     "end_time": "2021-12-23T03:28:50.9876",
     "exception": false,
     "start_time": "2021-12-23T03:28:50.945306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_TEST=False\n",
    "run_db=True\n",
    "model_struct=\"OriginModel\"\n",
    "\n",
    "HASH_NAME=\"xlnet large 4e 2e-5 \"\n",
    "\n",
    "swa_use=False\n",
    "data_aug=False\n",
    "translate_aug=False\n",
    "FP16=True\n",
    "\n",
    "#OriginModel MeanPoolingModel LastLayerCLSModel MaxPoolingModel\n",
    "#SecondToLastLayerCLSModel ConcatenateLastFourModel WeightedLayerPoolingModel WeightedLayerPoolingModel\n",
    "#AttentionPoolingModel\n",
    "translate_text=[\"text_fr\",\"text_de\",\"text_es\"]\n",
    "\n",
    "CONFIG['group'] = f'{HASH_NAME}-Baseline'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033229,
     "end_time": "2021-12-23T03:28:51.11638",
     "exception": false,
     "start_time": "2021-12-23T03:28:51.083151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:44.125767Z",
     "iopub.status.busy": "2022-01-16T07:57:44.125327Z",
     "iopub.status.idle": "2022-01-16T07:57:46.967717Z",
     "shell.execute_reply": "2022-01-16T07:57:46.966567Z",
     "shell.execute_reply.started": "2022-01-16T07:57:44.125732Z"
    },
    "papermill": {
     "duration": 2.957967,
     "end_time": "2021-12-23T03:28:54.108287",
     "exception": false,
     "start_time": "2021-12-23T03:28:51.15032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madreambear\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/py/.netrc\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "try:\n",
    "#     from kaggle_secrets import UserSecretsClient\n",
    "#     user_secrets = UserSecretsClient()\n",
    "#     api_key = user_secrets.get_secret(\"wandb_api\")\n",
    "    api_key=\"ebe051612bfb733306f4e4b5df4b043050ebea6e\"\n",
    "    wandb.login(key=api_key)\n",
    "    anony = None\n",
    "except:\n",
    "    anony = \"must\"\n",
    "    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032929,
     "end_time": "2021-12-23T03:28:54.175247",
     "exception": false,
     "start_time": "2021-12-23T03:28:54.142318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:46.97027Z",
     "iopub.status.busy": "2022-01-16T07:57:46.970022Z",
     "iopub.status.idle": "2022-01-16T07:57:47.502666Z",
     "shell.execute_reply": "2022-01-16T07:57:47.501715Z",
     "shell.execute_reply.started": "2022-01-16T07:57:46.970237Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df=pd.read_csv(os.path.join(input_dir,\"validation_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033961,
     "end_time": "2021-12-23T03:28:54.242352",
     "exception": false,
     "start_time": "2021-12-23T03:28:54.208391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.504763Z",
     "iopub.status.busy": "2022-01-16T07:57:47.504441Z",
     "iopub.status.idle": "2022-01-16T07:57:47.516262Z",
     "shell.execute_reply": "2022-01-16T07:57:47.515228Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.504721Z"
    },
    "papermill": {
     "duration": 0.045101,
     "end_time": "2021-12-23T03:28:54.32118",
     "exception": false,
     "start_time": "2021-12-23T03:28:54.276079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def generate_comments(data):\n",
    "    more_toxic_text=data[\"more_toxic\"].values\n",
    "    less_toxic_text=data[\"less_toxic\"].values    \n",
    "    comments=np.concatenate((more_toxic_text,less_toxic_text))\n",
    "    comments=np.unique(comments)\n",
    "    comments=pd.DataFrame({\"text\":comments})\n",
    "    text_encoder=LabelEncoder()\n",
    "    text_encoder.fit(comments)\n",
    "    comments[\"encode_text\"]=text_encoder.transform(comments[\"text\"])\n",
    "    comments[\"toxic_value\"]=0\n",
    "    comments[\"access_time\"]=0\n",
    "    data[\"encode_less\"]=text_encoder.transform(data[\"less_toxic\"])\n",
    "    data[\"encode_more\"]=text_encoder.transform(data[\"more_toxic\"])\n",
    "    \n",
    "    return data,comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.520768Z",
     "iopub.status.busy": "2022-01-16T07:57:47.520312Z",
     "iopub.status.idle": "2022-01-16T07:57:47.541118Z",
     "shell.execute_reply": "2022-01-16T07:57:47.540111Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.520732Z"
    },
    "papermill": {
     "duration": 0.056054,
     "end_time": "2021-12-23T03:28:54.410318",
     "exception": false,
     "start_time": "2021-12-23T03:28:54.354264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bsearch(start,more2less_dict):\n",
    "    queue = deque([start])\n",
    "    visit_list=[]\n",
    "    while len(queue)!=0:\n",
    "        visit_id=queue.popleft()\n",
    "        if visit_id in visit_list:\n",
    "            continue\n",
    "        visit_list.append(visit_id)\n",
    "        queue+=deque(more2less_dict[visit_id])\n",
    "    visit_list.remove(start)\n",
    "    return [ x for x in visit_list if x not in more2less_dict[start] ]\n",
    "\n",
    "def search_lessText(more2less_dict):\n",
    "    aug_dict= defaultdict(list)\n",
    "    for start in list(more2less_dict.keys()):\n",
    "        \n",
    "        aug_list=bsearch(start,more2less_dict)\n",
    "        aug_dict[start]=aug_list\n",
    "    return aug_dict\n",
    "\n",
    "def data_aug1(data_df,comments):\n",
    "    data_df[\"label_min\"]=data_df.apply(lambda row:row[\"encode_less\"] \n",
    "                                   if row[\"encode_less\"]<row[\"encode_more\"] else row[\"encode_more\"],axis=1)\n",
    "    data_df[\"label_max\"]=data_df.apply(lambda row:row[\"encode_more\"] \n",
    "                                       if row[\"encode_less\"]<row[\"encode_more\"] else row[\"encode_less\"],axis=1)\n",
    "\n",
    "    data_df[\"win_min\"]=data_df.apply(lambda row:1 if row[\"encode_more\"]<row[\"encode_less\"] else 0 ,axis=1)\n",
    "    data_df[\"win_max\"]=data_df.apply(lambda row:0 if row[\"encode_more\"]<row[\"encode_less\"] else 1 ,axis=1)\n",
    "\n",
    "    data_df_agg=data_df.groupby([\"label_min\",\"label_max\"]).agg({\"win_min\":\"sum\",\"win_max\":\"sum\"}).reset_index()\n",
    "    data_df_agg[\"encode_less\"]=data_df_agg.apply(lambda row:row[\"label_min\"] \n",
    "                                                 if row[\"win_min\"]<row[\"win_max\"] else row[\"label_max\"],axis=1)\n",
    "    data_df_agg[\"encode_more\"]=data_df_agg.apply(lambda row:row[\"label_min\"] \n",
    "                                                 if row[\"win_min\"]>row[\"win_max\"] else row[\"label_max\"],axis=1)\n",
    "    \n",
    "    more2less_dict= defaultdict(list)\n",
    "    data_df_agg.apply(lambda row:more2less_dict[row[\"encode_more\"]].append(row[\"encode_less\"]),axis=1)\n",
    "    \n",
    "    aug_dict=search_lessText(more2less_dict)\n",
    "    aug_dict={key:value for key,value in aug_dict.items() if len(value)!=0}\n",
    "    aug_df=pd.DataFrame(columns=(tuple(data_df.columns)))\n",
    "    \n",
    "    id2text_dict=comments.to_dict()[\"text\"]\n",
    "    \n",
    "    for key,value in aug_dict.items():\n",
    "        encode_more=key\n",
    "        encode_less_list=value\n",
    "\n",
    "        more_toxic=id2text_dict[encode_more]\n",
    "        for encode_less in encode_less_list:\n",
    "            less_toxic=id2text_dict[encode_less]\n",
    "            row=pd.DataFrame({\"worker\":[999],\"less_toxic\":[less_toxic],\"more_toxic\":[more_toxic],\"encode_less\":[encode_less],\n",
    "                                       \"encode_more\":[encode_more]})\n",
    "            aug_df=aug_df.append(row,ignore_index=True)\n",
    "    work_list=np.array([999]*len(aug_df),dtype=np.int64)\n",
    "    aug_df[\"worker\"]=work_list\n",
    "    return aug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.543755Z",
     "iopub.status.busy": "2022-01-16T07:57:47.542974Z",
     "iopub.status.idle": "2022-01-16T07:57:47.72383Z",
     "shell.execute_reply": "2022-01-16T07:57:47.722869Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.543708Z"
    },
    "papermill": {
     "duration": 0.755321,
     "end_time": "2021-12-23T03:28:55.200325",
     "exception": false,
     "start_time": "2021-12-23T03:28:54.445004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df,comments=generate_comments(data_df)\n",
    "if translate_aug==True:\n",
    "    comment_translation=pd.read_csv(\"../input/translate-toxic/comment_translation.csv\")\n",
    "    comment_translation=comment_translation.merge(comments,on=\"text\",how=\"left\")\n",
    "if data_aug==True:\n",
    "    aug_df=data_aug1(data_df,comments)\n",
    "    data_df=pd.concat([data_df,aug_df],axis=0)\n",
    "    data_df=data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.725771Z",
     "iopub.status.busy": "2022-01-16T07:57:47.72524Z",
     "iopub.status.idle": "2022-01-16T07:57:47.732166Z",
     "shell.execute_reply": "2022-01-16T07:57:47.730762Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.725718Z"
    },
    "papermill": {
     "duration": 0.04379,
     "end_time": "2021-12-23T03:28:55.280908",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.237118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DATASET_TEST==True:\n",
    "    data_df=data_df[0:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033677,
     "end_time": "2021-12-23T03:28:55.348276",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.314599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.734914Z",
     "iopub.status.busy": "2022-01-16T07:57:47.734442Z",
     "iopub.status.idle": "2022-01-16T07:57:47.752704Z",
     "shell.execute_reply": "2022-01-16T07:57:47.751733Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.734875Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "class UnionFind():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.parents = [-1] * n\n",
    "\n",
    "    def find(self, x):\n",
    "        if self.parents[x] < 0:\n",
    "            return x\n",
    "        else:\n",
    "            self.parents[x] = self.find(self.parents[x])\n",
    "            return self.parents[x]\n",
    "\n",
    "    def union(self, x, y):\n",
    "        x = self.find(x)\n",
    "        y = self.find(y)\n",
    "        if x == y:\n",
    "            return\n",
    "        if self.parents[x] > self.parents[y]:\n",
    "            x, y = y, x\n",
    "        self.parents[x] += self.parents[y]\n",
    "        self.parents[y] = x\n",
    "\n",
    "\n",
    "def get_group_unionfind(train: pd.DataFrame):\n",
    "    less_unique_text = train['less_toxic'].unique()\n",
    "    more_unique_text = train['more_toxic'].unique()\n",
    "    unique_text = np.hstack([less_unique_text, more_unique_text])\n",
    "    unique_text = np.unique(unique_text).tolist()    \n",
    "    text2num = {text: i for i, text in enumerate(unique_text)}\n",
    "    num2text = {num: text for text, num in text2num.items()}\n",
    "    train['num_less_toxic'] = train['less_toxic'].map(text2num)\n",
    "    train['num_more_toxic'] = train['more_toxic'].map(text2num)\n",
    "\n",
    "    uf = UnionFind(len(unique_text))\n",
    "    for seq1, seq2 in train[['num_less_toxic', 'num_more_toxic']].to_numpy():\n",
    "        uf.union(seq1, seq2)\n",
    "\n",
    "    text2group = {num2text[i]: uf.find(i) for i in range(len(unique_text))}\n",
    "    train['group'] = train['less_toxic'].map(text2group)\n",
    "    train = train.drop(columns=['num_less_toxic', 'num_more_toxic'])\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.754627Z",
     "iopub.status.busy": "2022-01-16T07:57:47.754217Z",
     "iopub.status.idle": "2022-01-16T07:57:47.824999Z",
     "shell.execute_reply": "2022-01-16T07:57:47.824059Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.754583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>encode_less</th>\n",
       "      <th>encode_more</th>\n",
       "      <th>group</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>2405</td>\n",
       "      <td>12151</td>\n",
       "      <td>2405</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "      <td>7215</td>\n",
       "      <td>653</td>\n",
       "      <td>697</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "      <td>2632</td>\n",
       "      <td>7222</td>\n",
       "      <td>2632</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "      <td>7973</td>\n",
       "      <td>12968</td>\n",
       "      <td>7973</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "      <td>3524</td>\n",
       "      <td>3266</td>\n",
       "      <td>3524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  encode_less  \\\n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...         2405   \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...         7215   \n",
       "2  \"Atom you don't believe actual photos of mastu...         2632   \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...         7973   \n",
       "4           hey \\n\\nway to support nazis, you racist         3524   \n",
       "\n",
       "   encode_more  group  kfold  \n",
       "0        12151   2405      2  \n",
       "1          653    697      2  \n",
       "2         7222   2632      2  \n",
       "3        12968   7973      2  \n",
       "4         3266   3524      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = get_group_unionfind(data_df)\n",
    "group_kfold = GroupKFold(n_splits=CONFIG[\"fold_num\"])\n",
    "for fold, (trn_idx, val_idx) in enumerate(group_kfold.split(data_df, data_df, data_df['group'])): \n",
    "    data_df.loc[val_idx , \"kfold\"] = fold\n",
    "\n",
    "data_df[\"kfold\"] = data_df[\"kfold\"].astype(int)\n",
    "data_df.to_csv('train_noleak.csv', index=False)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.836482Z",
     "iopub.status.busy": "2022-01-16T07:57:47.835909Z",
     "iopub.status.idle": "2022-01-16T07:57:47.853335Z",
     "shell.execute_reply": "2022-01-16T07:57:47.852206Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.836439Z"
    },
    "papermill": {
     "duration": 0.050813,
     "end_time": "2021-12-23T03:28:55.572476",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.521663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self,data,tokenizer,max_len=CONFIG[\"MAX_LENGTH\"]):\n",
    "        self.data=data\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_len=max_len\n",
    "        self.more_toxic=data[\"more_toxic\"].values\n",
    "        self.less_toxic=data[\"less_toxic\"].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, item):\n",
    "        more_toxic=self.more_toxic[item]\n",
    "        less_toxic=self.less_toxic[item]\n",
    "\n",
    "        features1=self.convert_examples_to_features(more_toxic)\n",
    "        features2=self.convert_examples_to_features(less_toxic)\n",
    "        features1={\"input_ids\":features1[\"input_ids\"],\"attention_mask\":features1[\"attention_mask\"]}\n",
    "        features2={\"input_ids\":features2[\"input_ids\"],\"attention_mask\":features2[\"attention_mask\"]}\n",
    "        target=1\n",
    "        return {\"more_toxic\":{key:torch.tensor(value,dtype=torch.long) for key,value in features1.items()},\n",
    "                \"less_toxic\":{key:torch.tensor(value,dtype=torch.long) for key,value in features2.items()},\n",
    "                \"target\":torch.tensor(target,dtype=torch.long)}\n",
    "    def convert_examples_to_features(self, example):\n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            example,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            is_split_into_words=False,\n",
    "            )\n",
    "        return encoded\n",
    "def make_dataloader(data,batch_size,model_dir=MODEL_DIR,max_len=CONFIG[\"MAX_LENGTH\"]):\n",
    "    tokenizer=tokenizer_func_dict.get(Model_type).from_pretrained(model_dir)\n",
    "    dataset=DatasetRetriever(data,tokenizer,max_len)\n",
    "    sampler=RandomSampler(dataset)\n",
    "    \n",
    "    dataloader=DataLoader(dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          sampler=sampler\n",
    "                         )\n",
    "    return dataloader\n",
    "\n",
    "class DatasetRetriever_cv(Dataset):\n",
    "    def __init__(self,data,tokenizer,max_len=CONFIG[\"MAX_LENGTH\"]):\n",
    "        self.data=data\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_len=max_len\n",
    "        self.text=self.data[\"text\"].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, item):\n",
    "        text=self.text[item]\n",
    "        features1=self.convert_examples_to_features(text)\n",
    "        ##roberta 没有tokentype ids 为了统一这里也不进行输入 反正训练也用不着\n",
    "        features1={\"input_ids\":features1[\"input_ids\"],\"attention_mask\":features1[\"attention_mask\"]}\n",
    "        return {\"text\":{key:torch.tensor(value,dtype=torch.long) for key,value in features1.items()}}\n",
    "    def convert_examples_to_features(self, example):\n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            example,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            is_split_into_words=False,\n",
    "            )\n",
    "        return encoded\n",
    "def make_dataloader_cv(data,batch_size,model_dir=MODEL_DIR,max_len=CONFIG[\"MAX_LENGTH\"]):\n",
    "    tokenizer=AutoTokenizer.from_pretrained(model_dir)\n",
    "    dataset=DatasetRetriever_cv(data,tokenizer,max_len)\n",
    "    sampler=SequentialSampler(dataset)\n",
    "    \n",
    "    dataloader=DataLoader(dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          sampler=sampler\n",
    "                         )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.855626Z",
     "iopub.status.busy": "2022-01-16T07:57:47.855089Z",
     "iopub.status.idle": "2022-01-16T07:57:47.870613Z",
     "shell.execute_reply": "2022-01-16T07:57:47.869681Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.855581Z"
    },
    "papermill": {
     "duration": 0.049317,
     "end_time": "2021-12-23T03:28:55.656104",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.606787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_loaders(df,fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    if translate_aug==True:\n",
    "        df_train_encode=df_train.drop([\"less_toxic\",\"more_toxic\"],axis=1)\n",
    "        for language_text in translate_text:\n",
    "            temp_train=df_train_encode\n",
    "            \n",
    "            temp_train=temp_train.merge(comment_translation[[\"encode_text\",language_text]],left_on=\"encode_less\",right_on=\"encode_text\",how=\"left\")\n",
    "            temp_train=temp_train.rename(columns={language_text:\"less_toxic\"})\n",
    "            temp_train.drop([\"encode_text\"],axis=1,inplace=True)\n",
    "            \n",
    "            temp_train=temp_train.merge(comment_translation[[\"encode_text\",language_text]],left_on=\"encode_more\",right_on=\"encode_text\",how=\"left\")\n",
    "            temp_train=temp_train.rename(columns={language_text:\"more_toxic\"})\n",
    "            temp_train.drop([\"encode_text\"],axis=1,inplace=True)\n",
    "            df_train=pd.concat([df_train,temp_train])\n",
    "    train_loader=make_dataloader(df_train,CONFIG[\"TRAIN_BATCH_SIZE\"],MODEL_DIR,CONFIG[\"MAX_LENGTH\"])\n",
    "    \n",
    "    valid_loader=make_dataloader(df_valid,CONFIG[\"DEV_BATCH_SIZE\"],MODEL_DIR,CONFIG[\"MAX_LENGTH\"])\n",
    "\n",
    " \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 模型输出结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.872799Z",
     "iopub.status.busy": "2022-01-16T07:57:47.872462Z",
     "iopub.status.idle": "2022-01-16T07:57:47.88607Z",
     "shell.execute_reply": "2022-01-16T07:57:47.88518Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.872757Z"
    },
    "papermill": {
     "duration": 0.045237,
     "end_time": "2021-12-23T03:28:55.735323",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.690086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OriginModel(nn.Module):\n",
    "    def __init__(self,model_name):\n",
    "        super(OriginModel,self).__init__()\n",
    "        self.config=config_func_dict.get(Model_type).from_pretrained(model_name)\n",
    "        self.config.update({\"hidden_dropout_prob\": 0.0,\"attention_probs_dropout_prob\":0.0\n",
    "            })   \n",
    "        self.model=model_func_dict.get(Model_type).from_pretrained(model_name,config=self.config)\n",
    "        self.drop=nn.Dropout(p=0)\n",
    "        \n",
    "        self.linear=nn.Linear(self.config.to_dict()[hidden_size],CONFIG[\"num_class\"])\n",
    "           \n",
    "        self.dense = nn.Linear(self.config.to_dict()[hidden_size], self.config.to_dict()[hidden_size])\n",
    "        self.activation = nn.Tanh()\n",
    "    def forward(self,input_ids,attention_mask):\n",
    "        out=self.model(input_ids=input_ids,attention_mask=attention_mask,output_hidden_states=False)\n",
    "        last_hidden_state = out[0]\n",
    "        cls_embeddings = last_hidden_state[:,0]\n",
    "        pooled_output = self.dense(cls_embeddings)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        \n",
    "        out=self.drop(pooled_output)\n",
    "        \n",
    "        outputs=self.linear(out)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:48.206871Z",
     "iopub.status.busy": "2022-01-16T07:57:48.206472Z",
     "iopub.status.idle": "2022-01-16T07:57:48.213127Z",
     "shell.execute_reply": "2022-01-16T07:57:48.212167Z",
     "shell.execute_reply.started": "2022-01-16T07:57:48.206838Z"
    }
   },
   "outputs": [],
   "source": [
    "func_dict={\"OriginModel\":OriginModel}\n",
    "JigsawModel=func_dict.get(model_struct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:48.591379Z",
     "iopub.status.busy": "2022-01-16T07:57:48.591085Z",
     "iopub.status.idle": "2022-01-16T07:57:48.597176Z",
     "shell.execute_reply": "2022-01-16T07:57:48.595981Z",
     "shell.execute_reply.started": "2022-01-16T07:57:48.591334Z"
    },
    "papermill": {
     "duration": 0.041048,
     "end_time": "2021-12-23T03:28:55.810694",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.769646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def criterion(outputs1, outputs2, targets):\n",
    "    return nn.MarginRankingLoss(margin=CONFIG[\"margin\"])(outputs1, outputs2, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:49.062994Z",
     "iopub.status.busy": "2022-01-16T07:57:49.0627Z",
     "iopub.status.idle": "2022-01-16T07:57:49.071384Z",
     "shell.execute_reply": "2022-01-16T07:57:49.070353Z",
     "shell.execute_reply.started": "2022-01-16T07:57:49.062951Z"
    },
    "papermill": {
     "duration": 0.045658,
     "end_time": "2021-12-23T03:28:55.889878",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.84422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_parameters(model,model_init_lr,multiplier, classifier_lr):\n",
    "    #权重分层，越靠近下游学习率越高\n",
    "    parameters=[]\n",
    "    lr=model_init_lr\n",
    "    # 迭代器包含 层名字和参数 parameters()函数只包含参数\n",
    "    #定义的层字典，参数的key必须叫params，否则在optimizer 父类中冲突\n",
    "    for layer in range(model.config.to_dict()[num_hidden_layers]-1,-1,-1):\n",
    "        layer_parameters={\n",
    "            \"params\":[p for n,p in model.named_parameters() if f\"encoder.layer.{layer}.\" in n],\n",
    "            \"lr\":lr\n",
    "        }\n",
    "        lr*=multiplier\n",
    "        parameters.append(layer_parameters)\n",
    "    \n",
    "    \n",
    "    classify_parameters={\n",
    "        #自己定义了什么分类层在此更改名字\n",
    "        \"params\":[p for n,p in model.named_parameters() if \"linear\"  in n],\n",
    "        \"lr\":classifier_lr\n",
    "    }\n",
    "        \n",
    "    parameters.append(classify_parameters)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:49.335729Z",
     "iopub.status.busy": "2022-01-16T07:57:49.335353Z",
     "iopub.status.idle": "2022-01-16T07:57:49.342559Z",
     "shell.execute_reply": "2022-01-16T07:57:49.34159Z",
     "shell.execute_reply.started": "2022-01-16T07:57:49.335698Z"
    },
    "papermill": {
     "duration": 0.042839,
     "end_time": "2021-12-23T03:28:55.96709",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.924251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cv(model,test_dataloader):\n",
    "    model.eval()\n",
    "    Preds=[]\n",
    "    for index,batch in enumerate(test_dataloader):\n",
    "\n",
    "        text_inputs=batch[\"text\"]\n",
    "        \n",
    "        text_inputs={key: value.to(DEVICE) for key,value in text_inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            out_more=model(**text_inputs)\n",
    "            Preds.append(out_more.view(-1).cpu().detach().numpy())\n",
    "    \n",
    "    Preds = np.concatenate(Preds) \n",
    "    gc.collect()\n",
    "    \n",
    "    return Preds\n",
    "def evaluate_comments(model,df,fold):\n",
    "    \n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    comments_fold_id=np.concatenate((df_valid[\"encode_more\"].values,df_valid[\"encode_less\"].values))\n",
    "    comments_fold_id=np.unique(comments_fold_id)\n",
    "    select_fold_list=comments.apply(lambda row : True if row[\"encode_text\"] in comments_fold_id else False ,axis=1)\n",
    "    comments_fold=comments[select_fold_list]\n",
    "    valid_loader=make_dataloader_cv(comments_fold,CONFIG[\"DEV_BATCH_SIZE\"],MODEL_DIR,CONFIG[\"MAX_LENGTH\"])   \n",
    "    \n",
    "    preds=evaluate_cv(model,valid_loader)\n",
    "    preds=np.array(preds)\n",
    "    comments_fold[\"toxic_value\"]=preds\n",
    "    comments_fold.index=comments_fold[\"encode_text\"]\n",
    "    index_score_dict=comments_fold.to_dict()[\"toxic_value\"]\n",
    "    df_valid[\"less_value\"]=df_valid[\"encode_less\"].map(lambda x:index_score_dict[x])\n",
    "    df_valid[\"more_value\"]=df_valid[\"encode_more\"].map(lambda x:index_score_dict[x])\n",
    "    df_valid[\"pair_True\"]=df_valid.apply(lambda row:True if row[\"more_value\"]>row[\"less_value\"] else False,axis=1)\n",
    "    cv=df_valid[\"pair_True\"].mean()\n",
    "    return -1*cv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:49.746346Z",
     "iopub.status.busy": "2022-01-16T07:57:49.743998Z",
     "iopub.status.idle": "2022-01-16T07:57:49.773445Z",
     "shell.execute_reply": "2022-01-16T07:57:49.772463Z",
     "shell.execute_reply.started": "2022-01-16T07:57:49.74631Z"
    },
    "papermill": {
     "duration": 0.062661,
     "end_time": "2021-12-23T03:28:56.063675",
     "exception": false,
     "start_time": "2021-12-23T03:28:56.001014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model,dev_dataloader):\n",
    "    model.eval()\n",
    "    dev_loss=0\n",
    "    for index,batch in enumerate(dev_dataloader):\n",
    "        \n",
    "        more_toxic_inputs=batch[\"more_toxic\"]\n",
    "        less_toxic_inputs=batch[\"less_toxic\"]\n",
    "        target=batch[\"target\"].to(DEVICE)\n",
    "\n",
    "        more_toxic_inputs={key: value.to(DEVICE) for key,value in more_toxic_inputs.items()}\n",
    "        less_toxic_inputs={key: value.to(DEVICE) for key,value in less_toxic_inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            out_more=model(**more_toxic_inputs)\n",
    "            out_less=model(**less_toxic_inputs)\n",
    "\n",
    "            loss=criterion(out_more, out_less, target)\n",
    "        \n",
    "            dev_loss+=loss.item()\n",
    "        \n",
    "    return dev_loss/len(dev_dataloader)\n",
    "def train(model,train_dataloader,dev_dataloader,evaluate_step=None,swa_start=None,fold=0):\n",
    "\n",
    "    if run_db==True:\n",
    "        wandb.watch(model,log_freq=100)\n",
    "#     optimizer=AdamW(get_parameters(model, model_init_lr=CONFIG[\"model_init_lr\"], multiplier=CONFIG[\"multiplier\"], \n",
    "#                                    classifier_lr=CONFIG[\"classifier_lr\"]),\n",
    "#                     lr = CONFIG['LR'], eps = CONFIG['EPS'],weight_decay=CONFIG['weight_decay'])\n",
    "    optimizer = AdamW(model.parameters(),lr= CONFIG['LR'], eps = CONFIG['EPS'],weight_decay=CONFIG['weight_decay'])\n",
    "    if evaluate_step==None:\n",
    "        evaluate_step=len(train_dataloader)\n",
    "    if swa_use==True:\n",
    "        swa_model=AveragedModel(model).to(DEVICE)\n",
    "        swa_scheduler = SWALR(optimizer, swa_lr=CONFIG[\"swa_lr\"])\n",
    "    \"\"\"\n",
    "    get_linear_schedule_with_warmup:学习率先从0开始warm_up到设定学习率，再逐渐减到0\n",
    "    num_warmup_steps：完成预热的步数\n",
    "    num_training_steps：训练批次*epochs 训练的step数\n",
    "    \"\"\"\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    if scheduler==None:\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, \n",
    "                                                num_training_steps=len(train_dataloader) * CONFIG[\"EPOCHS\"])\n",
    "    best_val_loss=100\n",
    "    best_model_param=None\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    start=time.time()\n",
    "    for epoch in range(CONFIG[\"EPOCHS\"]):\n",
    "        print(f\"\\n Epoch{epoch} train start \\n\")\n",
    "        train_loss=0\n",
    "        model.train()\n",
    "        #total 更新进度 \n",
    "        bar=tqdm(enumerate(train_dataloader),total=len(train_dataloader))\n",
    "        for index,batch in bar:\n",
    "            model.zero_grad()\n",
    "            more_toxic_inputs=batch[\"more_toxic\"]\n",
    "            less_toxic_inputs=batch[\"less_toxic\"]\n",
    "            target=batch[\"target\"].to(DEVICE)\n",
    "\n",
    "            more_toxic_inputs={key: value.to(DEVICE) for key,value in more_toxic_inputs.items()}\n",
    "            less_toxic_inputs={key: value.to(DEVICE) for key,value in less_toxic_inputs.items()}\n",
    "            if FP16==True:\n",
    "                with autocast():\n",
    "                    out_more=model(**more_toxic_inputs)\n",
    "                    out_less=model(**less_toxic_inputs)\n",
    "                    loss=criterion(out_more, out_less, target)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                out_more=model(**more_toxic_inputs)\n",
    "                out_less=model(**less_toxic_inputs)\n",
    "                loss=criterion(out_more, out_less, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if swa_use==True and epoch>=swa_start-1:\n",
    "\n",
    "                swa_model.update_parameters(model)\n",
    "                swa_scheduler.step()\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "            train_loss+=loss.item()\n",
    "            if (index+1)%evaluate_step==0 or (index+1)==len(train_dataloader):\n",
    "                if swa_use==True and epoch>=swa_start-1:\n",
    "                    val_loss=evaluate(swa_model,dev_dataloader)\n",
    "#                     val_loss=evaluate_comments(swa_model,data_df,fold)\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    val_loss=evaluate(model,dev_dataloader)\n",
    "#                     val_loss=evaluate_comments(model,data_df,fold)\n",
    "                    \n",
    "                if run_db==True:\n",
    "                    wandb.log({\"Train LOSS\":loss})\n",
    "                    wandb.log({\"Valid LOSS\":val_loss})\n",
    "\n",
    "                if val_loss<best_val_loss:\n",
    "                    best_val_loss=val_loss\n",
    "                    if swa_use==True and epoch>=swa_start-1:\n",
    "                        best_model_param=swa_model.module.state_dict()\n",
    "                    else:\n",
    "                        best_model_param=model.state_dict()\n",
    "                    print(f\"best_model saved ,val_loss:{best_val_loss}\")\n",
    "        avg_train_loss=train_loss/len(train_dataloader)\n",
    "        print(f\"EPOCH:{epoch+1},train_loss:{avg_train_loss},val_loss:{val_loss}\")\n",
    "\n",
    "    end=time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    if run_db==True:\n",
    "        run.summary[\"time (hour)\"]=time_elapsed /3600\n",
    "    return best_val_loss,best_model_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:50.179872Z",
     "iopub.status.busy": "2022-01-16T07:57:50.178891Z",
     "iopub.status.idle": "2022-01-16T07:58:22.323861Z",
     "shell.execute_reply": "2022-01-16T07:58:22.322514Z",
     "shell.execute_reply.started": "2022-01-16T07:57:50.179835Z"
    },
    "papermill": {
     "duration": 24312.182609,
     "end_time": "2021-12-23T10:14:08.280605",
     "exception": false,
     "start_time": "2021-12-23T03:28:56.097996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold0 train start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adreambear/Jigsaw/runs/3bmgyfcx\" target=\"_blank\">xlnet large 4e 2e-5 -fold-0</a></strong> to <a href=\"https://wandb.ai/adreambear/Jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch0 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6a9403b788496cb04d631a245d10d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.4386181247861762\n",
      "EPOCH:1,train_loss:0.43861937660916867,val_loss:0.4386181247861762\n",
      "\n",
      " Epoch1 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d5e16313a343a1917ccab593f492d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3606046359789999\n",
      "EPOCH:2,train_loss:0.3898630053309568,val_loss:0.3606046359789999\n",
      "\n",
      " Epoch2 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a1f565b5c5442cb4c7398d20f1f21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3531674347425762\n",
      "EPOCH:3,train_loss:0.35499219830144213,val_loss:0.3531674347425762\n",
      "\n",
      " Epoch3 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a3a4bcee324375af9383ac1ed4d96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:4,train_loss:0.3318354416401144,val_loss:0.35357868169483386\n",
      "Training complete in 0h 42m 48s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 239326... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>█▆▅▁</td></tr><tr><td>Valid LOSS</td><td>█▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>0.25872</td></tr><tr><td>Valid LOSS</td><td>0.35358</td></tr><tr><td>time (hour)</td><td>0.71328</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">xlnet large 4e 2e-5 -fold-0</strong>: <a href=\"https://wandb.ai/adreambear/Jigsaw/runs/3bmgyfcx\" target=\"_blank\">https://wandb.ai/adreambear/Jigsaw/runs/3bmgyfcx</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_000847-3bmgyfcx/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold1 train start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adreambear/Jigsaw/runs/jkmux1e6\" target=\"_blank\">xlnet large 4e 2e-5 -fold-1</a></strong> to <a href=\"https://wandb.ai/adreambear/Jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch0 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af41bdd2203944c6a4c39d1a5f3365fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.39476802725540966\n",
      "EPOCH:1,train_loss:0.4780086569517732,val_loss:0.39476802725540966\n",
      "\n",
      " Epoch1 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be033a04d47478ca54b7a5ee19bb509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.35175478521146275\n",
      "EPOCH:2,train_loss:0.3841876260030911,val_loss:0.35175478521146275\n",
      "\n",
      " Epoch2 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6521785942b7407f8fd722566f6281aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3424067250992123\n",
      "EPOCH:3,train_loss:0.3535123909879253,val_loss:0.3424067250992123\n",
      "\n",
      " Epoch3 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fb0de39f9b4572b89091556399d58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3362940163988816\n",
      "EPOCH:4,train_loss:0.3321858772792783,val_loss:0.3362940163988816\n",
      "Training complete in 0h 42m 59s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 292235... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>▆█▁▄</td></tr><tr><td>Valid LOSS</td><td>█▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>0.38196</td></tr><tr><td>Valid LOSS</td><td>0.33629</td></tr><tr><td>time (hour)</td><td>0.71636</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">xlnet large 4e 2e-5 -fold-1</strong>: <a href=\"https://wandb.ai/adreambear/Jigsaw/runs/jkmux1e6\" target=\"_blank\">https://wandb.ai/adreambear/Jigsaw/runs/jkmux1e6</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_005153-jkmux1e6/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold2 train start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adreambear/Jigsaw/runs/2343xifw\" target=\"_blank\">xlnet large 4e 2e-5 -fold-2</a></strong> to <a href=\"https://wandb.ai/adreambear/Jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch0 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b4992b11184b0eb8132339d659b0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.37377344871822155\n",
      "EPOCH:1,train_loss:0.38598349004746435,val_loss:0.37377344871822155\n",
      "\n",
      " Epoch1 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa4dff787674a32aeac7717e9fdb9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.35783462963606183\n",
      "EPOCH:2,train_loss:0.34299915730656383,val_loss:0.35783462963606183\n",
      "\n",
      " Epoch2 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d283cfa48b87497ab97664f7c0a508d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:3,train_loss:0.327866164225328,val_loss:0.40516200724400975\n",
      "\n",
      " Epoch3 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a189b26fa3d647cbb502534cf9dc5967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:4,train_loss:0.33628087431429865,val_loss:0.36995241704740023\n",
      "Training complete in 0h 42m 60s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 345671... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>▂█▄▁</td></tr><tr><td>Valid LOSS</td><td>▃▁█▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>0.21938</td></tr><tr><td>Valid LOSS</td><td>0.36995</td></tr><tr><td>time (hour)</td><td>0.71658</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">xlnet large 4e 2e-5 -fold-2</strong>: <a href=\"https://wandb.ai/adreambear/Jigsaw/runs/2343xifw\" target=\"_blank\">https://wandb.ai/adreambear/Jigsaw/runs/2343xifw</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_013508-2343xifw/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold3 train start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adreambear/Jigsaw/runs/1x2zxepr\" target=\"_blank\">xlnet large 4e 2e-5 -fold-3</a></strong> to <a href=\"https://wandb.ai/adreambear/Jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch0 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33984f21c2f84b7983e8ea8ba57a339c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3719382245289652\n",
      "EPOCH:1,train_loss:0.3761701493475779,val_loss:0.3719382245289652\n",
      "\n",
      " Epoch1 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b2ed7bcce44377bdb20375d426fe3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.360879941990501\n",
      "EPOCH:2,train_loss:0.33572141070705486,val_loss:0.360879941990501\n",
      "\n",
      " Epoch2 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034fbe7d3f014163823e46d9a156c364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3551621383742282\n",
      "EPOCH:3,train_loss:0.3167074012061752,val_loss:0.3551621383742282\n",
      "\n",
      " Epoch3 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb95621f1d64cfeb82dc900958f4926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.34921967183288777\n",
      "EPOCH:4,train_loss:0.30083640606932904,val_loss:0.34921967183288777\n",
      "Training complete in 0h 42m 41s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 398562... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>▃▆▁█</td></tr><tr><td>Valid LOSS</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>0.45638</td></tr><tr><td>Valid LOSS</td><td>0.34922</td></tr><tr><td>time (hour)</td><td>0.7115</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">xlnet large 4e 2e-5 -fold-3</strong>: <a href=\"https://wandb.ai/adreambear/Jigsaw/runs/1x2zxepr\" target=\"_blank\">https://wandb.ai/adreambear/Jigsaw/runs/1x2zxepr</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_021826-1x2zxepr/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold4 train start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adreambear/Jigsaw/runs/1fz7m0zr\" target=\"_blank\">xlnet large 4e 2e-5 -fold-4</a></strong> to <a href=\"https://wandb.ai/adreambear/Jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch0 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3bbf92478e49b7b8687f1e7a6e9be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3790173351764679\n",
      "EPOCH:1,train_loss:0.3820937054743805,val_loss:0.3790173351764679\n",
      "\n",
      " Epoch1 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d1feb64d4b4e6898be85e4d1546670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3591332959501367\n",
      "EPOCH:2,train_loss:0.33534309029044856,val_loss:0.3591332959501367\n",
      "\n",
      " Epoch2 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573f204eae8b47cfa529e1a2772939ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold in range(CONFIG[\"fold_num\"]):\n",
    "    print(f\"\\n Fold{fold} train start\")\n",
    "    if run_db==True:\n",
    "        run = wandb.init(project='Jigsaw', \n",
    "                     config=CONFIG,\n",
    "                     job_type='Train',\n",
    "                     group=CONFIG['group'],\n",
    "                     tags=['roberta-base', f'{HASH_NAME}', 'margin-loss'],\n",
    "                     name=f'{HASH_NAME}-fold-{fold}',\n",
    "                     anonymous='must')\n",
    "    train_loader,dev_loader=prepare_loaders(data_df,fold)    \n",
    "    model=JigsawModel(MODEL_DIR)\n",
    "    model.to(DEVICE)\n",
    "    dev_loss,best_model_param=train(model,train_loader,dev_loader,evaluate_step=CONFIG[\"evaluate_step\"],swa_start=CONFIG[\"swa_start\"],fold=fold)\n",
    "    model_path=f\"./output/jigsaw_server_xlnet/bestmodel-{fold}.pth\"\n",
    "    torch.save(best_model_param,model_path)\n",
    "    if run_db==True:\n",
    "        run.finish()\n",
    "    \n",
    "    del model,train_loader,dev_loader        \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046284,
     "end_time": "2021-12-23T10:14:08.373253",
     "exception": false,
     "start_time": "2021-12-23T10:14:08.326969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "papermill": {
     "duration": 0.070172,
     "end_time": "2021-12-23T10:14:08.490594",
     "exception": false,
     "start_time": "2021-12-23T10:14:08.420422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model_paths,data_df,comments):\n",
    "    \n",
    "    for fold in range(CONFIG[\"fold_num\"]):\n",
    "        print(f\"fold{fold} dev start\")\n",
    "\n",
    "        data_fold=data_df[data_df.kfold == fold]\n",
    "#         data_fold.drop([\"label_min\",\"label_max\",\"win_min\",\"win_max\"],axis=1,inplace=True)\n",
    "    \n",
    "        comments_fold_id=np.concatenate((data_fold[\"encode_more\"].values,data_fold[\"encode_less\"].values))\n",
    "        comments_fold_id=np.unique(comments_fold_id)\n",
    "        select_fold_list=comments.apply(lambda row : True if row[\"encode_text\"] in comments_fold_id else False ,axis=1)\n",
    "        comments_fold=comments[select_fold_list]\n",
    "        comments_fold[\"access_time\"]=comments_fold[\"access_time\"]+1\n",
    "        \n",
    "        \n",
    "        test_loader=make_dataloader_cv(comments_fold,CONFIG[\"DEV_BATCH_SIZE\"],MODEL_DIR,CONFIG[\"MAX_LENGTH\"])\n",
    "        model=JigsawModel(MODEL_DIR)\n",
    "        model.to(DEVICE)\n",
    "        path=model_paths[fold]\n",
    "        \n",
    "        model.load_state_dict(torch.load(path))\n",
    "        preds = evaluate_cv(model, test_loader)\n",
    "        comments_fold[\"toxic_value\"]=comments_fold[\"toxic_value\"]+preds\n",
    "        \n",
    "        data_df.loc[data_fold.index]=data_fold\n",
    "        comments.loc[comments_fold.index]=comments_fold\n",
    "\n",
    "        del model,test_loader        \n",
    "    \n",
    "    return data_df,comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "papermill": {
     "duration": 194.831052,
     "end_time": "2021-12-23T10:17:23.369397",
     "exception": false,
     "start_time": "2021-12-23T10:14:08.538345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adreambear/Jigsaw/runs/2gk2w4v0\" target=\"_blank\">xlnet large 4e 2e-5 -fold-4</a></strong> to <a href=\"https://wandb.ai/adreambear/Jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold0 dev start\n",
      "fold1 dev start\n",
      "fold2 dev start\n",
      "fold3 dev start\n",
      "fold4 dev start\n",
      "0.69210840972499\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 504353... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cv</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cv</td><td>0.69211</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">xlnet large 4e 2e-5 -fold-4</strong>: <a href=\"https://wandb.ai/adreambear/Jigsaw/runs/2gk2w4v0\" target=\"_blank\">https://wandb.ai/adreambear/Jigsaw/runs/2gk2w4v0</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_034437-2gk2w4v0/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if run_db==True:\n",
    "    run = wandb.init(project='Jigsaw', \n",
    "             config=CONFIG,\n",
    "             job_type='cv',\n",
    "             group=CONFIG['group'],\n",
    "             tags=['roberta-base', f'{HASH_NAME}', 'margin-loss'],\n",
    "             name='cv',\n",
    "             anonymous='must')\n",
    "MODEL_PATHS=[os.path.join(OUT_DIR,f\"bestmodel-{num}.pth\") for num in range(CONFIG[\"fold_num\"])]\n",
    "\n",
    "data_df,comments= inference(MODEL_PATHS, data_df,comments)\n",
    "\n",
    "comments[\"toxic_value\"]=comments[\"toxic_value\"]/comments[\"access_time\"]\n",
    "comments.index=comments[\"encode_text\"]\n",
    "index_score_dict=comments.to_dict()[\"toxic_value\"]\n",
    "data_df[\"less_value\"]=data_df[\"encode_less\"].map(lambda x:index_score_dict[x])\n",
    "data_df[\"more_value\"]=data_df[\"encode_more\"].map(lambda x:index_score_dict[x])\n",
    "data_df[\"pair_True\"]=data_df.apply(lambda row:True if row[\"more_value\"]>row[\"less_value\"] else False,axis=1)\n",
    "cv=data_df[\"pair_True\"].mean()\n",
    "data_df.to_csv(\"./output/jigsawserver/data_df_cv.csv\")\n",
    "print(cv)\n",
    "if run_db==True:\n",
    "    wandb.log({\"cv\":data_df[\"pair_True\"].mean()})\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipypath=os.path.join(OUT_DIR,\".ipynb_checkpoints\")\n",
    "if os.path.exists(ipypath):\n",
    "    os.removedirs(ipypath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "papermill": {
     "duration": 2.195751,
     "end_time": "2021-12-23T10:17:25.614408",
     "exception": false,
     "start_time": "2021-12-23T10:17:23.418657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# jc_df=pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "\n",
    "# min_len = (jc_df['toxic'] == 1).sum()\n",
    "# df_y0_undersample = jc_df[jc_df['toxic'] == 0].sample(n=min_len, random_state=201)\n",
    "# comments_fold = pd.concat([jc_df[jc_df['toxic'] == 1], df_y0_undersample])\n",
    "\n",
    "# comments_fold.rename(columns={\"comment_text\":\"text\"},inplace=True)\n",
    "# comments_fold[\"toxic_value\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "papermill": {
     "duration": 666.119257,
     "end_time": "2021-12-23T10:28:31.783306",
     "exception": false,
     "start_time": "2021-12-23T10:17:25.664049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for fold in range(CONFIG[\"fold_num\"]):\n",
    "#     print(f\"fold{fold} dev start\")\n",
    "#     test_loader=make_dataloader_cv(comments_fold,CONFIG[\"DEV_BATCH_SIZE\"],MODEL_DIR,CONFIG[\"MAX_LENGTH\"])\n",
    "#     model=JigsawModel(MODEL_DIR)\n",
    "#     model.to(DEVICE)\n",
    "#     path=MODEL_PATHS[fold]\n",
    "\n",
    "#     model.load_state_dict(torch.load(path))\n",
    "#     preds = evaluate_cv(model, test_loader)\n",
    "#     comments_fold[\"toxic_value\"]=comments_fold[\"toxic_value\"]+preds\n",
    "#     del model,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T05:02:13.332672Z",
     "iopub.status.busy": "2022-01-03T05:02:13.332181Z",
     "iopub.status.idle": "2022-01-03T05:02:13.339008Z",
     "shell.execute_reply": "2022-01-03T05:02:13.33828Z",
     "shell.execute_reply.started": "2022-01-03T05:02:13.332597Z"
    },
    "papermill": {
     "duration": 1.114385,
     "end_time": "2021-12-23T10:28:32.946363",
     "exception": false,
     "start_time": "2021-12-23T10:28:31.831978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# toxicSeperateValue=comments_fold[\"toxic_value\"].min()+(comments_fold[\"toxic_value\"].max()-comments_fold[\"toxic_value\"].min())/2\n",
    "# comments_fold[\"toxic_predict\"]=comments_fold.apply(lambda row : 1 if row[\"toxic_value\"]>=toxicSeperateValue else 0,axis=1)\n",
    "# comments_fold[\"predict_acc\"]=comments_fold.apply(lambda row : True if row[\"toxic_predict\"]==row[\"toxic\"] else False,axis=1)\n",
    "# cv=comments_fold[\"predict_acc\"].mean()\n",
    "# print(\"cv in first competition data:\",cv)\n",
    "# if run_db==True:\n",
    "#     wandb.log({\"cv in first competition \":cv})\n",
    "#     run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
