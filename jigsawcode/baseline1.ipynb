{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:32.626552Z",
     "iopub.status.busy": "2022-01-16T07:57:32.626251Z",
     "iopub.status.idle": "2022-01-16T07:57:39.865181Z",
     "shell.execute_reply": "2022-01-16T07:57:39.864196Z",
     "shell.execute_reply.started": "2022-01-16T07:57:32.626522Z"
    },
    "papermill": {
     "duration": 9.26997,
     "end_time": "2021-12-23T03:28:36.18541",
     "exception": false,
     "start_time": "2021-12-23T03:28:26.91544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import string\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, logging\n",
    "from transformers import AlbertConfig, AlbertTokenizer, AlbertModel\n",
    "from transformers import RobertaConfig,RobertaTokenizer, RobertaModel\n",
    "from transformers import BertConfig, BertTokenizer, BertModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, SequentialSampler, RandomSampler, DataLoader\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "from torch.cuda.amp import  GradScaler\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gc; gc.enable()\n",
    "from IPython.display import clear_output\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:42.472062Z",
     "iopub.status.busy": "2022-01-16T07:57:42.471725Z",
     "iopub.status.idle": "2022-01-16T07:57:42.4812Z",
     "shell.execute_reply": "2022-01-16T07:57:42.480166Z",
     "shell.execute_reply.started": "2022-01-16T07:57:42.472031Z"
    },
    "papermill": {
     "duration": 0.043418,
     "end_time": "2021-12-23T03:28:50.176898",
     "exception": false,
     "start_time": "2021-12-23T03:28:50.13348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#产生一个哈希值\n",
    "# def id_generator(size=12, chars=string.ascii_lowercase + string.digits):\n",
    "#     return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n",
    "\n",
    "# HASH_NAME = id_generator(size=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032281,
     "end_time": "2021-12-23T03:28:50.24189",
     "exception": false,
     "start_time": "2021-12-23T03:28:50.209609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:42.973734Z",
     "iopub.status.busy": "2022-01-16T07:57:42.97339Z",
     "iopub.status.idle": "2022-01-16T07:57:43.035419Z",
     "shell.execute_reply": "2022-01-16T07:57:43.034294Z",
     "shell.execute_reply.started": "2022-01-16T07:57:42.973706Z"
    },
    "papermill": {
     "duration": 0.102339,
     "end_time": "2021-12-23T03:28:50.376474",
     "exception": false,
     "start_time": "2021-12-23T03:28:50.274135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "CONFIG={\n",
    "    \"TRAIN_BATCH_SIZE\":48,\n",
    "    \"MAX_LENGTH\":128,\n",
    "    \"DEV_BATCH_SIZE\": 64,\n",
    "    \"LR\":2e-5,\n",
    "    \"EPS\":1e-8,\n",
    "    \"weight_decay\":1e-6,\n",
    "    \n",
    "    \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 500,\n",
    "    \"T_0\":500,\n",
    "    \"margin\":0.45,\n",
    "    \"fold_num\":5,\n",
    "    \"seed\":2021,\n",
    "    \"num_class\":1,\n",
    "    \n",
    "    \"EPOCHS\":4,\n",
    "    \"evaluate_step\":None,\n",
    "    \"swa_start\":4,\n",
    "    \"model_init_lr\":0.9e-4,\n",
    "    \"multiplier\":0.9,\n",
    "    \"classifier_lr\":1e-4 ,\n",
    "    \"swa_lr\": 1e-5\n",
    "}\n",
    "input_dir=\"./input/jigsaw-toxic-severity-rating\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更换模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:43.408116Z",
     "iopub.status.busy": "2022-01-16T07:57:43.407603Z",
     "iopub.status.idle": "2022-01-16T07:57:43.415474Z",
     "shell.execute_reply": "2022-01-16T07:57:43.414448Z",
     "shell.execute_reply.started": "2022-01-16T07:57:43.408067Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden_size=\"hidden_size\"\n",
    "num_hidden_layers=\"num_hidden_layers\"\n",
    "OUT_DIR=\"./output/jigsaw_server_albert/albert_folder\"\n",
    "#for xlnet\n",
    "# hidden_size=\"d_model\"\n",
    "# num_hidden_layers=\"n_layer\"\n",
    "\n",
    "# MODEL_DIR=\"../model/roberta-base\"\n",
    "# MODEL_DIR=\"../model/roberta-large\"\n",
    "\n",
    "MODEL_DIR=\"../model/albert-large-v2\"\n",
    "# MODEL_DIR=\"../model/xlnet-base-cased\"\n",
    "\n",
    "Model_type=\"Albert\"\n",
    "tokenizer_func_dict={\"Albert\":AlbertTokenizer,\"auto\":AutoTokenizer,\"Roberta\":RobertaTokenizer}\n",
    "config_func_dict={\"Albert\":AlbertConfig,\"auto\":AutoConfig,\"Roberta\":RobertaConfig}\n",
    "model_func_dict={\"Albert\":AlbertModel,\"auto\":AutoModel,\"Roberta\":RobertaModel}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##检查事项\n",
    "* 提交之前 注意 run_db 是否打开 是否创建了正确的hash值\n",
    "* test是否关闭\n",
    "* 如果 换模型 model_dir 是否正确 model struct是否正确\n",
    "* gpu 是否需要打开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:43.765907Z",
     "iopub.status.busy": "2022-01-16T07:57:43.765628Z",
     "iopub.status.idle": "2022-01-16T07:57:43.771476Z",
     "shell.execute_reply": "2022-01-16T07:57:43.770583Z",
     "shell.execute_reply.started": "2022-01-16T07:57:43.765856Z"
    },
    "papermill": {
     "duration": 0.042294,
     "end_time": "2021-12-23T03:28:50.9876",
     "exception": false,
     "start_time": "2021-12-23T03:28:50.945306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_TEST=False\n",
    "run_db=True\n",
    "model_struct=\"OriginModel\"\n",
    "\n",
    "HASH_NAME=\"albert  margin=0.45\"\n",
    "\n",
    "swa_use=False\n",
    "data_aug=False\n",
    "translate_aug=False\n",
    "FP16=True\n",
    "\n",
    "#OriginModel MeanPoolingModel LastLayerCLSModel MaxPoolingModel\n",
    "#SecondToLastLayerCLSModel ConcatenateLastFourModel WeightedLayerPoolingModel WeightedLayerPoolingModel\n",
    "#AttentionPoolingModel\n",
    "translate_text=[\"text_fr\",\"text_de\",\"text_es\"]\n",
    "\n",
    "CONFIG['group'] = f'{HASH_NAME}-Baseline'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033229,
     "end_time": "2021-12-23T03:28:51.11638",
     "exception": false,
     "start_time": "2021-12-23T03:28:51.083151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:44.125767Z",
     "iopub.status.busy": "2022-01-16T07:57:44.125327Z",
     "iopub.status.idle": "2022-01-16T07:57:46.967717Z",
     "shell.execute_reply": "2022-01-16T07:57:46.966567Z",
     "shell.execute_reply.started": "2022-01-16T07:57:44.125732Z"
    },
    "papermill": {
     "duration": 2.957967,
     "end_time": "2021-12-23T03:28:54.108287",
     "exception": false,
     "start_time": "2021-12-23T03:28:51.15032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/py/.netrc\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "try:\n",
    "#     from kaggle_secrets import UserSecretsClient\n",
    "#     user_secrets = UserSecretsClient()\n",
    "#     api_key = user_secrets.get_secret(\"wandb_api\")\n",
    "    api_key=\"ebe051612bfb733306f4e4b5df4b043050ebea6e\"\n",
    "    wandb.login(key=api_key)\n",
    "    anony = None\n",
    "except:\n",
    "    anony = \"must\"\n",
    "    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032929,
     "end_time": "2021-12-23T03:28:54.175247",
     "exception": false,
     "start_time": "2021-12-23T03:28:54.142318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:46.97027Z",
     "iopub.status.busy": "2022-01-16T07:57:46.970022Z",
     "iopub.status.idle": "2022-01-16T07:57:47.502666Z",
     "shell.execute_reply": "2022-01-16T07:57:47.501715Z",
     "shell.execute_reply.started": "2022-01-16T07:57:46.970237Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df=pd.read_csv(os.path.join(input_dir,\"validation_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033961,
     "end_time": "2021-12-23T03:28:54.242352",
     "exception": false,
     "start_time": "2021-12-23T03:28:54.208391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.504763Z",
     "iopub.status.busy": "2022-01-16T07:57:47.504441Z",
     "iopub.status.idle": "2022-01-16T07:57:47.516262Z",
     "shell.execute_reply": "2022-01-16T07:57:47.515228Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.504721Z"
    },
    "papermill": {
     "duration": 0.045101,
     "end_time": "2021-12-23T03:28:54.32118",
     "exception": false,
     "start_time": "2021-12-23T03:28:54.276079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def generate_comments(data):\n",
    "    more_toxic_text=data[\"more_toxic\"].values\n",
    "    less_toxic_text=data[\"less_toxic\"].values    \n",
    "    comments=np.concatenate((more_toxic_text,less_toxic_text))\n",
    "    comments=np.unique(comments)\n",
    "    comments=pd.DataFrame({\"text\":comments})\n",
    "    text_encoder=LabelEncoder()\n",
    "    text_encoder.fit(comments)\n",
    "    comments[\"encode_text\"]=text_encoder.transform(comments[\"text\"])\n",
    "    comments[\"toxic_value\"]=0\n",
    "    comments[\"access_time\"]=0\n",
    "    data[\"encode_less\"]=text_encoder.transform(data[\"less_toxic\"])\n",
    "    data[\"encode_more\"]=text_encoder.transform(data[\"more_toxic\"])\n",
    "    \n",
    "    return data,comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.520768Z",
     "iopub.status.busy": "2022-01-16T07:57:47.520312Z",
     "iopub.status.idle": "2022-01-16T07:57:47.541118Z",
     "shell.execute_reply": "2022-01-16T07:57:47.540111Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.520732Z"
    },
    "papermill": {
     "duration": 0.056054,
     "end_time": "2021-12-23T03:28:54.410318",
     "exception": false,
     "start_time": "2021-12-23T03:28:54.354264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bsearch(start,more2less_dict):\n",
    "    queue = deque([start])\n",
    "    visit_list=[]\n",
    "    while len(queue)!=0:\n",
    "        visit_id=queue.popleft()\n",
    "        if visit_id in visit_list:\n",
    "            continue\n",
    "        visit_list.append(visit_id)\n",
    "        queue+=deque(more2less_dict[visit_id])\n",
    "    visit_list.remove(start)\n",
    "    return [ x for x in visit_list if x not in more2less_dict[start] ]\n",
    "\n",
    "def search_lessText(more2less_dict):\n",
    "    aug_dict= defaultdict(list)\n",
    "    for start in list(more2less_dict.keys()):\n",
    "        \n",
    "        aug_list=bsearch(start,more2less_dict)\n",
    "        aug_dict[start]=aug_list\n",
    "    return aug_dict\n",
    "\n",
    "def data_aug1(data_df,comments):\n",
    "    data_df[\"label_min\"]=data_df.apply(lambda row:row[\"encode_less\"] \n",
    "                                   if row[\"encode_less\"]<row[\"encode_more\"] else row[\"encode_more\"],axis=1)\n",
    "    data_df[\"label_max\"]=data_df.apply(lambda row:row[\"encode_more\"] \n",
    "                                       if row[\"encode_less\"]<row[\"encode_more\"] else row[\"encode_less\"],axis=1)\n",
    "\n",
    "    data_df[\"win_min\"]=data_df.apply(lambda row:1 if row[\"encode_more\"]<row[\"encode_less\"] else 0 ,axis=1)\n",
    "    data_df[\"win_max\"]=data_df.apply(lambda row:0 if row[\"encode_more\"]<row[\"encode_less\"] else 1 ,axis=1)\n",
    "\n",
    "    data_df_agg=data_df.groupby([\"label_min\",\"label_max\"]).agg({\"win_min\":\"sum\",\"win_max\":\"sum\"}).reset_index()\n",
    "    data_df_agg[\"encode_less\"]=data_df_agg.apply(lambda row:row[\"label_min\"] \n",
    "                                                 if row[\"win_min\"]<row[\"win_max\"] else row[\"label_max\"],axis=1)\n",
    "    data_df_agg[\"encode_more\"]=data_df_agg.apply(lambda row:row[\"label_min\"] \n",
    "                                                 if row[\"win_min\"]>row[\"win_max\"] else row[\"label_max\"],axis=1)\n",
    "    \n",
    "    more2less_dict= defaultdict(list)\n",
    "    data_df_agg.apply(lambda row:more2less_dict[row[\"encode_more\"]].append(row[\"encode_less\"]),axis=1)\n",
    "    \n",
    "    aug_dict=search_lessText(more2less_dict)\n",
    "    aug_dict={key:value for key,value in aug_dict.items() if len(value)!=0}\n",
    "    aug_df=pd.DataFrame(columns=(tuple(data_df.columns)))\n",
    "    \n",
    "    id2text_dict=comments.to_dict()[\"text\"]\n",
    "    \n",
    "    for key,value in aug_dict.items():\n",
    "        encode_more=key\n",
    "        encode_less_list=value\n",
    "\n",
    "        more_toxic=id2text_dict[encode_more]\n",
    "        for encode_less in encode_less_list:\n",
    "            less_toxic=id2text_dict[encode_less]\n",
    "            row=pd.DataFrame({\"worker\":[999],\"less_toxic\":[less_toxic],\"more_toxic\":[more_toxic],\"encode_less\":[encode_less],\n",
    "                                       \"encode_more\":[encode_more]})\n",
    "            aug_df=aug_df.append(row,ignore_index=True)\n",
    "    work_list=np.array([999]*len(aug_df),dtype=np.int64)\n",
    "    aug_df[\"worker\"]=work_list\n",
    "    return aug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.543755Z",
     "iopub.status.busy": "2022-01-16T07:57:47.542974Z",
     "iopub.status.idle": "2022-01-16T07:57:47.72383Z",
     "shell.execute_reply": "2022-01-16T07:57:47.722869Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.543708Z"
    },
    "papermill": {
     "duration": 0.755321,
     "end_time": "2021-12-23T03:28:55.200325",
     "exception": false,
     "start_time": "2021-12-23T03:28:54.445004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df,comments=generate_comments(data_df)\n",
    "if translate_aug==True:\n",
    "    comment_translation=pd.read_csv(\"../input/translate-toxic/comment_translation.csv\")\n",
    "    comment_translation=comment_translation.merge(comments,on=\"text\",how=\"left\")\n",
    "if data_aug==True:\n",
    "    aug_df=data_aug1(data_df,comments)\n",
    "    data_df=pd.concat([data_df,aug_df],axis=0)\n",
    "    data_df=data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.725771Z",
     "iopub.status.busy": "2022-01-16T07:57:47.72524Z",
     "iopub.status.idle": "2022-01-16T07:57:47.732166Z",
     "shell.execute_reply": "2022-01-16T07:57:47.730762Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.725718Z"
    },
    "papermill": {
     "duration": 0.04379,
     "end_time": "2021-12-23T03:28:55.280908",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.237118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DATASET_TEST==True:\n",
    "    data_df=data_df[0:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033677,
     "end_time": "2021-12-23T03:28:55.348276",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.314599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.734914Z",
     "iopub.status.busy": "2022-01-16T07:57:47.734442Z",
     "iopub.status.idle": "2022-01-16T07:57:47.752704Z",
     "shell.execute_reply": "2022-01-16T07:57:47.751733Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.734875Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "class UnionFind():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.parents = [-1] * n\n",
    "\n",
    "    def find(self, x):\n",
    "        if self.parents[x] < 0:\n",
    "            return x\n",
    "        else:\n",
    "            self.parents[x] = self.find(self.parents[x])\n",
    "            return self.parents[x]\n",
    "\n",
    "    def union(self, x, y):\n",
    "        x = self.find(x)\n",
    "        y = self.find(y)\n",
    "        if x == y:\n",
    "            return\n",
    "        if self.parents[x] > self.parents[y]:\n",
    "            x, y = y, x\n",
    "        self.parents[x] += self.parents[y]\n",
    "        self.parents[y] = x\n",
    "\n",
    "\n",
    "def get_group_unionfind(train: pd.DataFrame):\n",
    "    less_unique_text = train['less_toxic'].unique()\n",
    "    more_unique_text = train['more_toxic'].unique()\n",
    "    unique_text = np.hstack([less_unique_text, more_unique_text])\n",
    "    unique_text = np.unique(unique_text).tolist()    \n",
    "    text2num = {text: i for i, text in enumerate(unique_text)}\n",
    "    num2text = {num: text for text, num in text2num.items()}\n",
    "    train['num_less_toxic'] = train['less_toxic'].map(text2num)\n",
    "    train['num_more_toxic'] = train['more_toxic'].map(text2num)\n",
    "\n",
    "    uf = UnionFind(len(unique_text))\n",
    "    for seq1, seq2 in train[['num_less_toxic', 'num_more_toxic']].to_numpy():\n",
    "        uf.union(seq1, seq2)\n",
    "\n",
    "    text2group = {num2text[i]: uf.find(i) for i in range(len(unique_text))}\n",
    "    train['group'] = train['less_toxic'].map(text2group)\n",
    "    train = train.drop(columns=['num_less_toxic', 'num_more_toxic'])\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.754627Z",
     "iopub.status.busy": "2022-01-16T07:57:47.754217Z",
     "iopub.status.idle": "2022-01-16T07:57:47.824999Z",
     "shell.execute_reply": "2022-01-16T07:57:47.824059Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.754583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>encode_less</th>\n",
       "      <th>encode_more</th>\n",
       "      <th>group</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>2405</td>\n",
       "      <td>12151</td>\n",
       "      <td>2405</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "      <td>7215</td>\n",
       "      <td>653</td>\n",
       "      <td>697</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "      <td>2632</td>\n",
       "      <td>7222</td>\n",
       "      <td>2632</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "      <td>7973</td>\n",
       "      <td>12968</td>\n",
       "      <td>7973</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "      <td>3524</td>\n",
       "      <td>3266</td>\n",
       "      <td>3524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  encode_less  \\\n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...         2405   \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...         7215   \n",
       "2  \"Atom you don't believe actual photos of mastu...         2632   \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...         7973   \n",
       "4           hey \\n\\nway to support nazis, you racist         3524   \n",
       "\n",
       "   encode_more  group  kfold  \n",
       "0        12151   2405      2  \n",
       "1          653    697      2  \n",
       "2         7222   2632      2  \n",
       "3        12968   7973      2  \n",
       "4         3266   3524      0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = get_group_unionfind(data_df)\n",
    "group_kfold = GroupKFold(n_splits=CONFIG[\"fold_num\"])\n",
    "for fold, (trn_idx, val_idx) in enumerate(group_kfold.split(data_df, data_df, data_df['group'])): \n",
    "    data_df.loc[val_idx , \"kfold\"] = fold\n",
    "\n",
    "data_df[\"kfold\"] = data_df[\"kfold\"].astype(int)\n",
    "data_df.to_csv('train_noleak.csv', index=False)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.836482Z",
     "iopub.status.busy": "2022-01-16T07:57:47.835909Z",
     "iopub.status.idle": "2022-01-16T07:57:47.853335Z",
     "shell.execute_reply": "2022-01-16T07:57:47.852206Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.836439Z"
    },
    "papermill": {
     "duration": 0.050813,
     "end_time": "2021-12-23T03:28:55.572476",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.521663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self,data,tokenizer,max_len=CONFIG[\"MAX_LENGTH\"]):\n",
    "        self.data=data\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_len=max_len\n",
    "        self.more_toxic=data[\"more_toxic\"].values\n",
    "        self.less_toxic=data[\"less_toxic\"].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, item):\n",
    "        more_toxic=self.more_toxic[item]\n",
    "        less_toxic=self.less_toxic[item]\n",
    "\n",
    "        features1=self.convert_examples_to_features(more_toxic)\n",
    "        features2=self.convert_examples_to_features(less_toxic)\n",
    "        features1={\"input_ids\":features1[\"input_ids\"],\"attention_mask\":features1[\"attention_mask\"]}\n",
    "        features2={\"input_ids\":features2[\"input_ids\"],\"attention_mask\":features2[\"attention_mask\"]}\n",
    "        target=1\n",
    "        return {\"more_toxic\":{key:torch.tensor(value,dtype=torch.long) for key,value in features1.items()},\n",
    "                \"less_toxic\":{key:torch.tensor(value,dtype=torch.long) for key,value in features2.items()},\n",
    "                \"target\":torch.tensor(target,dtype=torch.long)}\n",
    "    def convert_examples_to_features(self, example):\n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            example,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            is_split_into_words=False,\n",
    "            )\n",
    "        return encoded\n",
    "def make_dataloader(data,batch_size,model_dir=MODEL_DIR,max_len=CONFIG[\"MAX_LENGTH\"]):\n",
    "    tokenizer=tokenizer_func_dict.get(Model_type).from_pretrained(model_dir)\n",
    "    dataset=DatasetRetriever(data,tokenizer,max_len)\n",
    "    sampler=RandomSampler(dataset)\n",
    "    \n",
    "    dataloader=DataLoader(dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          sampler=sampler\n",
    "                         )\n",
    "    return dataloader\n",
    "\n",
    "class DatasetRetriever_cv(Dataset):\n",
    "    def __init__(self,data,tokenizer,max_len=CONFIG[\"MAX_LENGTH\"]):\n",
    "        self.data=data\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_len=max_len\n",
    "        self.text=self.data[\"text\"].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, item):\n",
    "        text=self.text[item]\n",
    "        features1=self.convert_examples_to_features(text)\n",
    "        ##roberta 没有tokentype ids 为了统一这里也不进行输入 反正训练也用不着\n",
    "        features1={\"input_ids\":features1[\"input_ids\"],\"attention_mask\":features1[\"attention_mask\"]}\n",
    "        return {\"text\":{key:torch.tensor(value,dtype=torch.long) for key,value in features1.items()}}\n",
    "    def convert_examples_to_features(self, example):\n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            example,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            is_split_into_words=False,\n",
    "            )\n",
    "        return encoded\n",
    "def make_dataloader_cv(data,batch_size,model_dir=MODEL_DIR,max_len=CONFIG[\"MAX_LENGTH\"]):\n",
    "    tokenizer=AutoTokenizer.from_pretrained(model_dir)\n",
    "    dataset=DatasetRetriever_cv(data,tokenizer,max_len)\n",
    "    sampler=SequentialSampler(dataset)\n",
    "    \n",
    "    dataloader=DataLoader(dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          sampler=sampler\n",
    "                         )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.855626Z",
     "iopub.status.busy": "2022-01-16T07:57:47.855089Z",
     "iopub.status.idle": "2022-01-16T07:57:47.870613Z",
     "shell.execute_reply": "2022-01-16T07:57:47.869681Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.855581Z"
    },
    "papermill": {
     "duration": 0.049317,
     "end_time": "2021-12-23T03:28:55.656104",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.606787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_loaders(df,fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    if translate_aug==True:\n",
    "        df_train_encode=df_train.drop([\"less_toxic\",\"more_toxic\"],axis=1)\n",
    "        for language_text in translate_text:\n",
    "            temp_train=df_train_encode\n",
    "            \n",
    "            temp_train=temp_train.merge(comment_translation[[\"encode_text\",language_text]],left_on=\"encode_less\",right_on=\"encode_text\",how=\"left\")\n",
    "            temp_train=temp_train.rename(columns={language_text:\"less_toxic\"})\n",
    "            temp_train.drop([\"encode_text\"],axis=1,inplace=True)\n",
    "            \n",
    "            temp_train=temp_train.merge(comment_translation[[\"encode_text\",language_text]],left_on=\"encode_more\",right_on=\"encode_text\",how=\"left\")\n",
    "            temp_train=temp_train.rename(columns={language_text:\"more_toxic\"})\n",
    "            temp_train.drop([\"encode_text\"],axis=1,inplace=True)\n",
    "            df_train=pd.concat([df_train,temp_train])\n",
    "    train_loader=make_dataloader(df_train,CONFIG[\"TRAIN_BATCH_SIZE\"],MODEL_DIR,CONFIG[\"MAX_LENGTH\"])\n",
    "    \n",
    "    valid_loader=make_dataloader(df_valid,CONFIG[\"DEV_BATCH_SIZE\"],MODEL_DIR,CONFIG[\"MAX_LENGTH\"])\n",
    "\n",
    " \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 模型输出结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:47.872799Z",
     "iopub.status.busy": "2022-01-16T07:57:47.872462Z",
     "iopub.status.idle": "2022-01-16T07:57:47.88607Z",
     "shell.execute_reply": "2022-01-16T07:57:47.88518Z",
     "shell.execute_reply.started": "2022-01-16T07:57:47.872757Z"
    },
    "papermill": {
     "duration": 0.045237,
     "end_time": "2021-12-23T03:28:55.735323",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.690086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OriginModel(nn.Module):\n",
    "    def __init__(self,model_name):\n",
    "        super(OriginModel,self).__init__()\n",
    "        self.config=config_func_dict.get(Model_type).from_pretrained(model_name)\n",
    "        self.config.update({\"hidden_dropout_prob\": 0.0,\"attention_probs_dropout_prob\":0.0\n",
    "            })   \n",
    "        self.model=model_func_dict.get(Model_type).from_pretrained(model_name,config=self.config)\n",
    "        self.drop=nn.Dropout(p=0)\n",
    "        \n",
    "        self.linear=nn.Linear(self.config.to_dict()[hidden_size],CONFIG[\"num_class\"])\n",
    "           \n",
    "        self.dense = nn.Linear(self.config.to_dict()[hidden_size], self.config.to_dict()[hidden_size])\n",
    "        self.activation = nn.Tanh()\n",
    "    def forward(self,input_ids,attention_mask):\n",
    "        out=self.model(input_ids=input_ids,attention_mask=attention_mask,output_hidden_states=False)\n",
    "        last_hidden_state = out[0]\n",
    "        cls_embeddings = last_hidden_state[:,0]\n",
    "        pooled_output = self.dense(cls_embeddings)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        \n",
    "        out=self.drop(pooled_output)\n",
    "        \n",
    "        outputs=self.linear(out)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:48.206871Z",
     "iopub.status.busy": "2022-01-16T07:57:48.206472Z",
     "iopub.status.idle": "2022-01-16T07:57:48.213127Z",
     "shell.execute_reply": "2022-01-16T07:57:48.212167Z",
     "shell.execute_reply.started": "2022-01-16T07:57:48.206838Z"
    }
   },
   "outputs": [],
   "source": [
    "func_dict={\"OriginModel\":OriginModel}\n",
    "JigsawModel=func_dict.get(model_struct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:48.591379Z",
     "iopub.status.busy": "2022-01-16T07:57:48.591085Z",
     "iopub.status.idle": "2022-01-16T07:57:48.597176Z",
     "shell.execute_reply": "2022-01-16T07:57:48.595981Z",
     "shell.execute_reply.started": "2022-01-16T07:57:48.591334Z"
    },
    "papermill": {
     "duration": 0.041048,
     "end_time": "2021-12-23T03:28:55.810694",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.769646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def criterion(outputs1, outputs2, targets):\n",
    "    return nn.MarginRankingLoss(margin=CONFIG[\"margin\"])(outputs1, outputs2, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:49.062994Z",
     "iopub.status.busy": "2022-01-16T07:57:49.0627Z",
     "iopub.status.idle": "2022-01-16T07:57:49.071384Z",
     "shell.execute_reply": "2022-01-16T07:57:49.070353Z",
     "shell.execute_reply.started": "2022-01-16T07:57:49.062951Z"
    },
    "papermill": {
     "duration": 0.045658,
     "end_time": "2021-12-23T03:28:55.889878",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.84422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_parameters(model,model_init_lr,multiplier, classifier_lr):\n",
    "    #权重分层，越靠近下游学习率越高\n",
    "    parameters=[]\n",
    "    lr=model_init_lr\n",
    "    # 迭代器包含 层名字和参数 parameters()函数只包含参数\n",
    "    #定义的层字典，参数的key必须叫params，否则在optimizer 父类中冲突\n",
    "    for layer in range(model.config.to_dict()[num_hidden_layers]-1,-1,-1):\n",
    "        layer_parameters={\n",
    "            \"params\":[p for n,p in model.named_parameters() if f\"encoder.layer.{layer}.\" in n],\n",
    "            \"lr\":lr\n",
    "        }\n",
    "        lr*=multiplier\n",
    "        parameters.append(layer_parameters)\n",
    "    \n",
    "    \n",
    "    classify_parameters={\n",
    "        #自己定义了什么分类层在此更改名字\n",
    "        \"params\":[p for n,p in model.named_parameters() if \"linear\"  in n],\n",
    "        \"lr\":classifier_lr\n",
    "    }\n",
    "        \n",
    "    parameters.append(classify_parameters)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:49.335729Z",
     "iopub.status.busy": "2022-01-16T07:57:49.335353Z",
     "iopub.status.idle": "2022-01-16T07:57:49.342559Z",
     "shell.execute_reply": "2022-01-16T07:57:49.34159Z",
     "shell.execute_reply.started": "2022-01-16T07:57:49.335698Z"
    },
    "papermill": {
     "duration": 0.042839,
     "end_time": "2021-12-23T03:28:55.96709",
     "exception": false,
     "start_time": "2021-12-23T03:28:55.924251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cv(model,test_dataloader):\n",
    "    model.eval()\n",
    "    Preds=[]\n",
    "    for index,batch in enumerate(test_dataloader):\n",
    "\n",
    "        text_inputs=batch[\"text\"]\n",
    "        \n",
    "        text_inputs={key: value.to(DEVICE) for key,value in text_inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            out_more=model(**text_inputs)\n",
    "            Preds.append(out_more.view(-1).cpu().detach().numpy())\n",
    "    \n",
    "    Preds = np.concatenate(Preds) \n",
    "    gc.collect()\n",
    "    \n",
    "    return Preds\n",
    "def evaluate_comments(model,df,fold):\n",
    "    \n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    comments_fold_id=np.concatenate((df_valid[\"encode_more\"].values,df_valid[\"encode_less\"].values))\n",
    "    comments_fold_id=np.unique(comments_fold_id)\n",
    "    select_fold_list=comments.apply(lambda row : True if row[\"encode_text\"] in comments_fold_id else False ,axis=1)\n",
    "    comments_fold=comments[select_fold_list]\n",
    "    valid_loader=make_dataloader_cv(comments_fold,CONFIG[\"DEV_BATCH_SIZE\"],MODEL_DIR,CONFIG[\"MAX_LENGTH\"])   \n",
    "    \n",
    "    preds=evaluate_cv(model,valid_loader)\n",
    "    preds=np.array(preds)\n",
    "    comments_fold[\"toxic_value\"]=preds\n",
    "    comments_fold.index=comments_fold[\"encode_text\"]\n",
    "    index_score_dict=comments_fold.to_dict()[\"toxic_value\"]\n",
    "    df_valid[\"less_value\"]=df_valid[\"encode_less\"].map(lambda x:index_score_dict[x])\n",
    "    df_valid[\"more_value\"]=df_valid[\"encode_more\"].map(lambda x:index_score_dict[x])\n",
    "    df_valid[\"pair_True\"]=df_valid.apply(lambda row:True if row[\"more_value\"]>row[\"less_value\"] else False,axis=1)\n",
    "    cv=df_valid[\"pair_True\"].mean()\n",
    "    return -1*cv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:49.746346Z",
     "iopub.status.busy": "2022-01-16T07:57:49.743998Z",
     "iopub.status.idle": "2022-01-16T07:57:49.773445Z",
     "shell.execute_reply": "2022-01-16T07:57:49.772463Z",
     "shell.execute_reply.started": "2022-01-16T07:57:49.74631Z"
    },
    "papermill": {
     "duration": 0.062661,
     "end_time": "2021-12-23T03:28:56.063675",
     "exception": false,
     "start_time": "2021-12-23T03:28:56.001014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model,dev_dataloader):\n",
    "    model.eval()\n",
    "    dev_loss=0\n",
    "    for index,batch in enumerate(dev_dataloader):\n",
    "        \n",
    "        more_toxic_inputs=batch[\"more_toxic\"]\n",
    "        less_toxic_inputs=batch[\"less_toxic\"]\n",
    "        target=batch[\"target\"].to(DEVICE)\n",
    "\n",
    "        more_toxic_inputs={key: value.to(DEVICE) for key,value in more_toxic_inputs.items()}\n",
    "        less_toxic_inputs={key: value.to(DEVICE) for key,value in less_toxic_inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            out_more=model(**more_toxic_inputs)\n",
    "            out_less=model(**less_toxic_inputs)\n",
    "\n",
    "            loss=criterion(out_more, out_less, target)\n",
    "        \n",
    "            dev_loss+=loss.item()\n",
    "        \n",
    "    return dev_loss/len(dev_dataloader)\n",
    "def train(model,train_dataloader,dev_dataloader,evaluate_step=None,swa_start=None,fold=0):\n",
    "\n",
    "    if run_db==True:\n",
    "        wandb.watch(model,log_freq=100)\n",
    "#     optimizer=AdamW(get_parameters(model, model_init_lr=CONFIG[\"model_init_lr\"], multiplier=CONFIG[\"multiplier\"], \n",
    "#                                    classifier_lr=CONFIG[\"classifier_lr\"]),\n",
    "#                     lr = CONFIG['LR'], eps = CONFIG['EPS'],weight_decay=CONFIG['weight_decay'])\n",
    "    optimizer = AdamW(model.parameters(),lr= CONFIG['LR'], eps = CONFIG['EPS'],weight_decay=CONFIG['weight_decay'])\n",
    "    if evaluate_step==None:\n",
    "        evaluate_step=len(train_dataloader)\n",
    "    if swa_use==True:\n",
    "        swa_model=AveragedModel(model).to(DEVICE)\n",
    "        swa_scheduler = SWALR(optimizer, swa_lr=CONFIG[\"swa_lr\"])\n",
    "    \"\"\"\n",
    "    get_linear_schedule_with_warmup:学习率先从0开始warm_up到设定学习率，再逐渐减到0\n",
    "    num_warmup_steps：完成预热的步数\n",
    "    num_training_steps：训练批次*epochs 训练的step数\n",
    "    \"\"\"\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    if scheduler==None:\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, \n",
    "                                                num_training_steps=len(train_dataloader) * CONFIG[\"EPOCHS\"])\n",
    "    best_val_loss=100\n",
    "    best_model_param=None\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    start=time.time()\n",
    "    for epoch in range(CONFIG[\"EPOCHS\"]):\n",
    "        print(f\"\\n Epoch{epoch} train start \\n\")\n",
    "        train_loss=0\n",
    "        model.train()\n",
    "        #total 更新进度 \n",
    "        bar=tqdm(enumerate(train_dataloader),total=len(train_dataloader))\n",
    "        for index,batch in bar:\n",
    "            model.zero_grad()\n",
    "            more_toxic_inputs=batch[\"more_toxic\"]\n",
    "            less_toxic_inputs=batch[\"less_toxic\"]\n",
    "            target=batch[\"target\"].to(DEVICE)\n",
    "\n",
    "            more_toxic_inputs={key: value.to(DEVICE) for key,value in more_toxic_inputs.items()}\n",
    "            less_toxic_inputs={key: value.to(DEVICE) for key,value in less_toxic_inputs.items()}\n",
    "            if FP16==True:\n",
    "                with autocast():\n",
    "                    out_more=model(**more_toxic_inputs)\n",
    "                    out_less=model(**less_toxic_inputs)\n",
    "                    loss=criterion(out_more, out_less, target)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                out_more=model(**more_toxic_inputs)\n",
    "                out_less=model(**less_toxic_inputs)\n",
    "                loss=criterion(out_more, out_less, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if swa_use==True and epoch>=swa_start-1:\n",
    "\n",
    "                swa_model.update_parameters(model)\n",
    "                swa_scheduler.step()\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "            train_loss+=loss.item()\n",
    "            if (index+1)%evaluate_step==0 or (index+1)==len(train_dataloader):\n",
    "                if swa_use==True and epoch>=swa_start-1:\n",
    "                    val_loss=evaluate(swa_model,dev_dataloader)\n",
    "#                     val_loss=evaluate_comments(swa_model,data_df,fold)\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    val_loss=evaluate(model,dev_dataloader)\n",
    "#                     val_loss=evaluate_comments(model,data_df,fold)\n",
    "                    \n",
    "                if run_db==True:\n",
    "                    wandb.log({\"Train LOSS\":loss})\n",
    "                    wandb.log({\"Valid LOSS\":val_loss})\n",
    "\n",
    "                if val_loss<best_val_loss:\n",
    "                    best_val_loss=val_loss\n",
    "                    if swa_use==True and epoch>=swa_start-1:\n",
    "                        best_model_param=swa_model.module.state_dict()\n",
    "                    else:\n",
    "                        best_model_param=model.state_dict()\n",
    "                    print(f\"best_model saved ,val_loss:{best_val_loss}\")\n",
    "        avg_train_loss=train_loss/len(train_dataloader)\n",
    "        print(f\"EPOCH:{epoch+1},train_loss:{avg_train_loss},val_loss:{val_loss}\")\n",
    "\n",
    "    end=time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    if run_db==True:\n",
    "        run.summary[\"time (hour)\"]=time_elapsed /3600\n",
    "    return best_val_loss,best_model_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T07:57:50.179872Z",
     "iopub.status.busy": "2022-01-16T07:57:50.178891Z",
     "iopub.status.idle": "2022-01-16T07:58:22.323861Z",
     "shell.execute_reply": "2022-01-16T07:58:22.322514Z",
     "shell.execute_reply.started": "2022-01-16T07:57:50.179835Z"
    },
    "papermill": {
     "duration": 24312.182609,
     "end_time": "2021-12-23T10:14:08.280605",
     "exception": false,
     "start_time": "2021-12-23T03:28:56.097996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold0 train start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adreambear/Jigsaw/runs/1ns8sur1\" target=\"_blank\">albert  margin=0.45-fold-0</a></strong> to <a href=\"https://wandb.ai/adreambear/Jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch0 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933a478e22084ca0beef3e46262edbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3100709993588297\n",
      "EPOCH:1,train_loss:0.32408953081089187,val_loss:0.3100709993588297\n",
      "\n",
      " Epoch1 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31a77079fc0422284880f05810f62bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:2,train_loss:0.3297381360989168,val_loss:0.44975944506494625\n",
      "\n",
      " Epoch2 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35771da4d9814ca78d063cc7820c1052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:3,train_loss:0.33516147569474947,val_loss:0.32381702112524136\n",
      "\n",
      " Epoch3 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4203a74e9f20430d995e478ef4917b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:4,train_loss:0.31094562983607865,val_loss:0.3179875085228368\n",
      "Training complete in 0h 27m 7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 539778... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>▁█▄▂</td></tr><tr><td>Valid LOSS</td><td>▁█▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>0.32418</td></tr><tr><td>Valid LOSS</td><td>0.31799</td></tr><tr><td>time (hour)</td><td>0.45189</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">albert  margin=0.45-fold-0</strong>: <a href=\"https://wandb.ai/adreambear/Jigsaw/runs/1ns8sur1\" target=\"_blank\">https://wandb.ai/adreambear/Jigsaw/runs/1ns8sur1</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220127_000846-1ns8sur1/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold1 train start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adreambear/Jigsaw/runs/3e0tej9r\" target=\"_blank\">albert  margin=0.45-fold-1</a></strong> to <a href=\"https://wandb.ai/adreambear/Jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch0 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734f9a93c5e241b586d7a445917525ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.30711959082829327\n",
      "EPOCH:1,train_loss:0.32814309651039514,val_loss:0.30711959082829327\n",
      "\n",
      " Epoch1 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d87634e091e4831899c7b8a649612b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:2,train_loss:0.3009010499335855,val_loss:0.3257108885990946\n",
      "\n",
      " Epoch2 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686812f5dd85450b9f5ca4d8b8bfe959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:3,train_loss:0.3536465850721792,val_loss:0.32254256794327185\n",
      "\n",
      " Epoch3 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7ff7fac94e417f814d31d1739f9f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:4,train_loss:0.31571471272593,val_loss:0.3169236719608307\n",
      "Training complete in 0h 27m 26s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 539892... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>▅▇█▁</td></tr><tr><td>Valid LOSS</td><td>▁█▇▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>0.2441</td></tr><tr><td>Valid LOSS</td><td>0.31692</td></tr><tr><td>time (hour)</td><td>0.45718</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">albert  margin=0.45-fold-1</strong>: <a href=\"https://wandb.ai/adreambear/Jigsaw/runs/3e0tej9r\" target=\"_blank\">https://wandb.ai/adreambear/Jigsaw/runs/3e0tej9r</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220127_003606-3e0tej9r/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold2 train start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adreambear/Jigsaw/runs/33tsweuk\" target=\"_blank\">albert  margin=0.45-fold-2</a></strong> to <a href=\"https://wandb.ai/adreambear/Jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch0 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac8ff42cc494c87896976a83ea72cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3134022074310403\n",
      "EPOCH:1,train_loss:0.32501104539371584,val_loss:0.3134022074310403\n",
      "\n",
      " Epoch1 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8ff428e1dd4eca8a1225955749d490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:2,train_loss:0.30371212407174814,val_loss:0.45022765084316857\n",
      "\n",
      " Epoch2 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffb2fc35118417e9c8f31f25661fbdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:3,train_loss:0.4505133356349877,val_loss:0.4500026577397397\n",
      "\n",
      " Epoch3 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade4665f22d34cb38bdf139a3e524272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:4,train_loss:0.44999920294816753,val_loss:0.44999900805322746\n",
      "Training complete in 0h 27m 14s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 540056... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>▁█▆▆</td></tr><tr><td>Valid LOSS</td><td>▁███</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>0.44999</td></tr><tr><td>Valid LOSS</td><td>0.45</td></tr><tr><td>time (hour)</td><td>0.45381</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">albert  margin=0.45-fold-2</strong>: <a href=\"https://wandb.ai/adreambear/Jigsaw/runs/33tsweuk\" target=\"_blank\">https://wandb.ai/adreambear/Jigsaw/runs/33tsweuk</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220127_010342-33tsweuk/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold3 train start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adreambear/Jigsaw/runs/2mstjjyd\" target=\"_blank\">albert  margin=0.45-fold-3</a></strong> to <a href=\"https://wandb.ai/adreambear/Jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch0 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d184c4775b34a74a282731d1f735a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.33996284462903675\n",
      "EPOCH:1,train_loss:0.3564360869595729,val_loss:0.33996284462903675\n",
      "\n",
      " Epoch1 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f3c61806c047ea8cf0ada9c181b955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3275292412230843\n",
      "EPOCH:2,train_loss:0.32473164737462046,val_loss:0.3275292412230843\n",
      "\n",
      " Epoch2 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bea2708f334106a693a9ac8c5103ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3242498048041996\n",
      "EPOCH:3,train_loss:0.3016152434733759,val_loss:0.3242498048041996\n",
      "\n",
      " Epoch3 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec4f8e6a76047c09484ef9d284c3053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:4,train_loss:0.2848412596965691,val_loss:0.325944459908887\n",
      "Training complete in 0h 27m 16s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 540164... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>█▇▅▁</td></tr><tr><td>Valid LOSS</td><td>█▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>0.2018</td></tr><tr><td>Valid LOSS</td><td>0.32594</td></tr><tr><td>time (hour)</td><td>0.45438</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">albert  margin=0.45-fold-3</strong>: <a href=\"https://wandb.ai/adreambear/Jigsaw/runs/2mstjjyd\" target=\"_blank\">https://wandb.ai/adreambear/Jigsaw/runs/2mstjjyd</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220127_013110-2mstjjyd/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold4 train start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adreambear/Jigsaw/runs/r8hedg7t\" target=\"_blank\">albert  margin=0.45-fold-4</a></strong> to <a href=\"https://wandb.ai/adreambear/Jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch0 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608ffb849f5242d5acc522ebade041da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3632579627789949\n",
      "EPOCH:1,train_loss:0.3678912064171882,val_loss:0.3632579627789949\n",
      "\n",
      " Epoch1 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06216aefb7c74a88908a305b269b987b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.35080386055143253\n",
      "EPOCH:2,train_loss:0.3433732163027463,val_loss:0.35080386055143253\n",
      "\n",
      " Epoch2 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d33be9976fb49d191a216475b8c345a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.3229456498434669\n",
      "EPOCH:3,train_loss:0.3162900400589187,val_loss:0.3229456498434669\n",
      "\n",
      " Epoch3 train start \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acfc079bf6a4c7b88a7cc6f6f9de917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model saved ,val_loss:0.319041445380763\n",
      "EPOCH:4,train_loss:0.29949449976364456,val_loss:0.319041445380763\n",
      "Training complete in 0h 27m 25s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 540263... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>█▅█▁</td></tr><tr><td>Valid LOSS</td><td>█▆▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train LOSS</td><td>0.21764</td></tr><tr><td>Valid LOSS</td><td>0.31904</td></tr><tr><td>time (hour)</td><td>0.45693</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">albert  margin=0.45-fold-4</strong>: <a href=\"https://wandb.ai/adreambear/Jigsaw/runs/r8hedg7t\" target=\"_blank\">https://wandb.ai/adreambear/Jigsaw/runs/r8hedg7t</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220127_015836-r8hedg7t/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(CONFIG[\"fold_num\"]):\n",
    "    print(f\"\\n Fold{fold} train start\")\n",
    "    if run_db==True:\n",
    "        run = wandb.init(project='Jigsaw', \n",
    "                     config=CONFIG,\n",
    "                     job_type='Train',\n",
    "                     group=CONFIG['group'],\n",
    "                     tags=['roberta-base', f'{HASH_NAME}', 'margin-loss'],\n",
    "                     name=f'{HASH_NAME}-fold-{fold}',\n",
    "                     anonymous='must')\n",
    "    train_loader,dev_loader=prepare_loaders(data_df,fold)    \n",
    "    model=JigsawModel(MODEL_DIR)\n",
    "    model.to(DEVICE)\n",
    "    dev_loss,best_model_param=train(model,train_loader,dev_loader,evaluate_step=CONFIG[\"evaluate_step\"],swa_start=CONFIG[\"swa_start\"],fold=fold)\n",
    "    model_path=f\"./output/jigsaw_server_albert/bestmodel-{fold}.pth\"\n",
    "    torch.save(best_model_param,model_path)\n",
    "    if run_db==True:\n",
    "        run.finish()\n",
    "    \n",
    "    del model,train_loader,dev_loader        \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046284,
     "end_time": "2021-12-23T10:14:08.373253",
     "exception": false,
     "start_time": "2021-12-23T10:14:08.326969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "papermill": {
     "duration": 0.070172,
     "end_time": "2021-12-23T10:14:08.490594",
     "exception": false,
     "start_time": "2021-12-23T10:14:08.420422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model_paths,data_df,comments):\n",
    "    \n",
    "    for fold in range(CONFIG[\"fold_num\"]):\n",
    "        print(f\"fold{fold} dev start\")\n",
    "\n",
    "        data_fold=data_df[data_df.kfold == fold]\n",
    "#         data_fold.drop([\"label_min\",\"label_max\",\"win_min\",\"win_max\"],axis=1,inplace=True)\n",
    "    \n",
    "        comments_fold_id=np.concatenate((data_fold[\"encode_more\"].values,data_fold[\"encode_less\"].values))\n",
    "        comments_fold_id=np.unique(comments_fold_id)\n",
    "        select_fold_list=comments.apply(lambda row : True if row[\"encode_text\"] in comments_fold_id else False ,axis=1)\n",
    "        comments_fold=comments[select_fold_list]\n",
    "        comments_fold[\"access_time\"]=comments_fold[\"access_time\"]+1\n",
    "        \n",
    "        \n",
    "        test_loader=make_dataloader_cv(comments_fold,CONFIG[\"DEV_BATCH_SIZE\"],MODEL_DIR,CONFIG[\"MAX_LENGTH\"])\n",
    "        model=JigsawModel(MODEL_DIR)\n",
    "        model.to(DEVICE)\n",
    "        path=model_paths[fold]\n",
    "        \n",
    "        model.load_state_dict(torch.load(path))\n",
    "        preds = evaluate_cv(model, test_loader)\n",
    "        comments_fold[\"toxic_value\"]=comments_fold[\"toxic_value\"]+preds\n",
    "        \n",
    "        data_df.loc[data_fold.index]=data_fold\n",
    "        comments.loc[comments_fold.index]=comments_fold\n",
    "\n",
    "        del model,test_loader        \n",
    "    \n",
    "    return data_df,comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "papermill": {
     "duration": 194.831052,
     "end_time": "2021-12-23T10:17:23.369397",
     "exception": false,
     "start_time": "2021-12-23T10:14:08.538345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adreambear/Jigsaw/runs/210ncmzd\" target=\"_blank\">cv</a></strong> to <a href=\"https://wandb.ai/adreambear/Jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold0 dev start\n",
      "fold1 dev start\n",
      "fold2 dev start\n",
      "fold3 dev start\n",
      "fold4 dev start\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: './output/jigsaw_server_albert/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_539728/85718605.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pair_True\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"more_value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"less_value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pair_True\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./output/jigsawserver/data_df_cv.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3464\u001b[0m         )\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3466\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: './output/jigsaw_server_albert/'"
     ]
    }
   ],
   "source": [
    "if run_db==True:\n",
    "    run = wandb.init(project='Jigsaw', \n",
    "             config=CONFIG,\n",
    "             job_type='cv',\n",
    "             group=CONFIG['group'],\n",
    "             tags=['roberta-base', f'{HASH_NAME}', 'margin-loss'],\n",
    "             name=f'cv',\n",
    "             anonymous='must')\n",
    "\n",
    "MODEL_PATHS=[os.path.join(OUT_DIR,f\"bestmodel-{num}.pth\") for num in range(CONFIG[\"fold_num\"])]\n",
    "\n",
    "data_df,comments= inference(MODEL_PATHS, data_df,comments)\n",
    "\n",
    "comments[\"toxic_value\"]=comments[\"toxic_value\"]/comments[\"access_time\"]\n",
    "comments.index=comments[\"encode_text\"]\n",
    "index_score_dict=comments.to_dict()[\"toxic_value\"]\n",
    "data_df[\"less_value\"]=data_df[\"encode_less\"].map(lambda x:index_score_dict[x])\n",
    "data_df[\"more_value\"]=data_df[\"encode_more\"].map(lambda x:index_score_dict[x])\n",
    "data_df[\"pair_True\"]=data_df.apply(lambda row:True if row[\"more_value\"]>row[\"less_value\"] else False,axis=1)\n",
    "cv=data_df[\"pair_True\"].mean()\n",
    "data_df.to_csv(os.path.join(OUT_DIR,\"data_df_cv.csv\"))\n",
    "# data_df.to_csv(\"./output/jigsawserver/data_df_cv.csv\")\n",
    "print(cv)\n",
    "if run_db==True:\n",
    "    wandb.log({\"cv\":data_df[\"pair_True\"].mean()})\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6463730569948186\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 540377... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cv</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cv</td><td>0.64637</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">cv</strong>: <a href=\"https://wandb.ai/adreambear/Jigsaw/runs/210ncmzd\" target=\"_blank\">https://wandb.ai/adreambear/Jigsaw/runs/210ncmzd</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220127_022613-210ncmzd/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df.to_csv(os.path.join(OUT_DIR,\"data_df_cv.csv\"))\n",
    "# data_df.to_csv(\"./output/jigsawserver/data_df_cv.csv\")\n",
    "print(cv)\n",
    "if run_db==True:\n",
    "    wandb.log({\"cv\":data_df[\"pair_True\"].mean()})\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "ipypath=os.path.join(OUT_DIR,\".ipynb_checkpoints\")\n",
    "if os.path.exists(ipypath):\n",
    "    os.removedirs(ipypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.195751,
     "end_time": "2021-12-23T10:17:25.614408",
     "exception": false,
     "start_time": "2021-12-23T10:17:23.418657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# jc_df=pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "\n",
    "# min_len = (jc_df['toxic'] == 1).sum()\n",
    "# df_y0_undersample = jc_df[jc_df['toxic'] == 0].sample(n=min_len, random_state=201)\n",
    "# comments_fold = pd.concat([jc_df[jc_df['toxic'] == 1], df_y0_undersample])\n",
    "\n",
    "# comments_fold.rename(columns={\"comment_text\":\"text\"},inplace=True)\n",
    "# comments_fold[\"toxic_value\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 666.119257,
     "end_time": "2021-12-23T10:28:31.783306",
     "exception": false,
     "start_time": "2021-12-23T10:17:25.664049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for fold in range(CONFIG[\"fold_num\"]):\n",
    "#     print(f\"fold{fold} dev start\")\n",
    "#     test_loader=make_dataloader_cv(comments_fold,CONFIG[\"DEV_BATCH_SIZE\"],MODEL_DIR,CONFIG[\"MAX_LENGTH\"])\n",
    "#     model=JigsawModel(MODEL_DIR)\n",
    "#     model.to(DEVICE)\n",
    "#     path=MODEL_PATHS[fold]\n",
    "\n",
    "#     model.load_state_dict(torch.load(path))\n",
    "#     preds = evaluate_cv(model, test_loader)\n",
    "#     comments_fold[\"toxic_value\"]=comments_fold[\"toxic_value\"]+preds\n",
    "#     del model,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T05:02:13.332672Z",
     "iopub.status.busy": "2022-01-03T05:02:13.332181Z",
     "iopub.status.idle": "2022-01-03T05:02:13.339008Z",
     "shell.execute_reply": "2022-01-03T05:02:13.33828Z",
     "shell.execute_reply.started": "2022-01-03T05:02:13.332597Z"
    },
    "papermill": {
     "duration": 1.114385,
     "end_time": "2021-12-23T10:28:32.946363",
     "exception": false,
     "start_time": "2021-12-23T10:28:31.831978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# toxicSeperateValue=comments_fold[\"toxic_value\"].min()+(comments_fold[\"toxic_value\"].max()-comments_fold[\"toxic_value\"].min())/2\n",
    "# comments_fold[\"toxic_predict\"]=comments_fold.apply(lambda row : 1 if row[\"toxic_value\"]>=toxicSeperateValue else 0,axis=1)\n",
    "# comments_fold[\"predict_acc\"]=comments_fold.apply(lambda row : True if row[\"toxic_predict\"]==row[\"toxic\"] else False,axis=1)\n",
    "# cv=comments_fold[\"predict_acc\"].mean()\n",
    "# print(\"cv in first competition data:\",cv)\n",
    "# if run_db==True:\n",
    "#     wandb.log({\"cv in first competition \":cv})\n",
    "#     run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
