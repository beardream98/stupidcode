{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import yaml\n",
    "import data\n",
    "from data.read_data_temp import select_data,TrainData,file_split,DataByFile,sample_negative\n",
    "from data.data_split import kfsplit\n",
    "from data.datasets import prepare_loaders\n",
    "from utils.wandb_init import get_run,wandb_utils\n",
    "from utils.train import get_score,train_set,get_score_list\n",
    "from utils.trivial import get_logger\n",
    "from model.head import OriginModel\n",
    "from model.trainer import train,predict\n",
    "import torch\n",
    "from transformers import logging\n",
    "\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "import gc \n",
    "gc.enable()\n",
    "from utils.trivial import set_seed\n",
    "\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madreambear\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/v-mxiong/.netrc\n"
     ]
    }
   ],
   "source": [
    "yaml_path=\"./config/train.yaml\"\n",
    "CONFIG,Logger,DEVICE=train_set(yaml_path,experimentName=None,upload=False,filename=\"./test/logs\",is_notebook=True)\n",
    "\n",
    "CONFIG[\"num_hidden_layers\"]=12\n",
    "CONFIG[\"DATA_NUM\"]=50000\n",
    "CONFIG[\"EPOCHS\"]=1\n",
    "CONFIG[\"DEBUG_MODEL\"]=False\n",
    "CONFIG[\"run_db\"]=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "column_name :['Query', 'label', 'dsat']\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "\n",
    "CONFIG[\"INPUT_DIR\"]=\"/vc_data/users/v-mxiong/qc/QueryTitle\"\n",
    "with open(os.path.join(CONFIG[\"INPUT_DIR\"],\"Schema\"),\"r\") as f:\n",
    "    line=f.readlines()[0].strip()\n",
    "    column_name=line.split(\"\\t\")\n",
    "    CONFIG[\"Logger\"].info(f\"column_name :{column_name}\")\n",
    "\n",
    "# trainDataObj=DataByFile(CONFIG,\"train\")\n",
    "# trainData=trainDataObj.get_data()\n",
    "# CONFIG[\"Logger\"].info(\"-\"*10+\"trainData label's value_counts\"+\"-\"*10)\n",
    "# CONFIG[\"Logger\"].info(trainData[\"label\"].value_counts())\n",
    "# CONFIG[\"Logger\"].info(\"-\"*10+\"trainData fold's value_counts\"+\"-\"*10)\n",
    "# CONFIG[\"Logger\"].info(trainData[\"fold\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.trivial import timer\n",
    "\n",
    "@timer\n",
    "def read_data_file(input_file,is_debug,data_num,head=[\"Query\",\"label\"]):\n",
    "    with open(input_file,\"r\",encoding=\"UTF-8\") as input_object:\n",
    "        if is_debug==True:\n",
    "            input_lines=[]\n",
    "            for _ in range(data_num):\n",
    "                input_lines.append(input_object.readline())\n",
    "        else:\n",
    "            input_lines=input_object.readlines()\n",
    "    input_lines=[ line.strip().split(\"\\t\") for line in input_lines]\n",
    "    # may return wrong number \n",
    "    input_lines=[ line for line in input_lines if len(line)==len(head)]\n",
    "    # input_lines=[ [line[0].split(\"$$\")[0],line[1]] for line in input_lines if len(line)==len(head)]\n",
    "    \n",
    "    # url+title\n",
    "    # input_lines=[ [\" \".join(line[0].split(\"$$\")[1:3]),line[1]] for line in input_lines if len(line)==len(head)]\n",
    "    \n",
    "    input_df=pd.DataFrame(input_lines,columns=head)\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import sys\n",
    "import queue\n",
    " \n",
    " \n",
    "class Reader(threading.Thread):\n",
    "    def __init__(self, thread_id,column_num):\n",
    "        super(Reader, self).__init__()\n",
    "        self.thread_id = thread_id\n",
    "        self.column_num=column_num\n",
    "        self.lines=[]\n",
    "    def run(self):\n",
    "        global q\n",
    " \n",
    "        input_lines = q.get()\n",
    "        input_lines=[ line.strip().split(\"\\t\") for line in input_lines]\n",
    "        input_lines=[ line for line in input_lines if len(line)==self.column_num]\n",
    "        self.lines=input_lines\n",
    " \n",
    "\n",
    "def wc_count(file_name):\n",
    "    import subprocess\n",
    "    out = subprocess.getoutput(\"wc -l %s\" % file_name)\n",
    "    return int(out.split()[0])\n",
    "\n",
    "class Partition(object):\n",
    "    def __init__(self, file_name, thread_num):\n",
    "        self.file_name = file_name\n",
    "        self.block_num = thread_num\n",
    " \n",
    "    #按照线程数对文件进行分块并存进queue中\n",
    "    \n",
    "    @timer \n",
    "    def part_and_queue(self):\n",
    "        pos_list = []\n",
    "        #文件总行数\n",
    "        file_size = wc_count(self.file_name)\n",
    "        #按照线程数分成对应块的大小\n",
    "        block_size = file_size / self.block_num\n",
    "        start_pos = 0\n",
    "        global q\n",
    " \n",
    "        for i in range(self.block_num):\n",
    "            if i == self.block_num - 1:\n",
    "                end_pos = file_size - 1\n",
    "                pos_list.append((start_pos, end_pos))\n",
    "                break\n",
    "            end_pos = start_pos + block_size - 1\n",
    "            if end_pos >= file_size:\n",
    "                end_pos = file_size - 1\n",
    "            if start_pos >= file_size:\n",
    "                break\n",
    "            pos_list.append((start_pos, end_pos))\n",
    "            start_pos = end_pos + 1\n",
    " \n",
    "        #读取每块内容存进queue中\n",
    "        fd = open(self.file_name, 'r')\n",
    "        for pos_tu in pos_list:\n",
    "            temp_text = []\n",
    "            start = pos_tu[0]\n",
    "            end = pos_tu[1]\n",
    " \n",
    "            while start <= end:\n",
    "                text = fd.readline().strip('\\n')\n",
    "                temp_text.append(text)\n",
    "                start = start + 1\n",
    " \n",
    "            q.put(temp_text)\n",
    "        fd.close()\n",
    " \n",
    " \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_data_file cost time: 193.264 s\n"
     ]
    }
   ],
   "source": [
    "input_file=os.path.join(CONFIG[\"INPUT_DIR\"],\"NegativeTest\")\n",
    "df1=read_data_file(input_file,CONFIG[\"DEBUG_MODEL\"],CONFIG[\"DATA_NUM\"],head=column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56243689 entries, 0 to 56243688\n",
      "Data columns (total 3 columns):\n",
      "Query    object\n",
      "label    object\n",
      "dsat     object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_and_queue cost time: 72.663 s\n"
     ]
    }
   ],
   "source": [
    "file_name =input_file\n",
    " \n",
    "#线程数量可配\n",
    "thread_num = 32\n",
    "q = queue.Queue()\n",
    "p = Partition(file_name, thread_num)\n",
    "t = []\n",
    "p.part_and_queue()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1 cost time: 170.273 s\n"
     ]
    }
   ],
   "source": [
    "@timer\n",
    "def test1():\n",
    "    for i in range(thread_num):\n",
    "        t.append(Reader(i,column_num=len(column_name)))\n",
    "    for i in range(thread_num):\n",
    "        t[i].start()\n",
    "    for i in range(thread_num):\n",
    "        t[i].join()\n",
    "        \n",
    "    input_lines=[]\n",
    "    for i in range(thread_num):\n",
    "        input_lines.extend(t[i].lines)\n",
    "\n",
    "    input_df=pd.DataFrame(input_lines,columns=column_name)\n",
    "    return input_df\n",
    "    \n",
    "input_df=test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56243663 entries, 0 to 56243662\n",
      "Data columns (total 3 columns):\n",
      "Query    object\n",
      "label    object\n",
      "dsat     object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "input_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_readline(f):\n",
    "    pos = f.tell()\n",
    "    while True:\n",
    "        try:\n",
    "            return f.readline()\n",
    "        except UnicodeDecodeError:\n",
    "            pos -= 1\n",
    "            f.seek(pos)\n",
    "            \n",
    "            \n",
    "def async_kd_tokenizer(filename, worker_id, num_workers,column_num):\n",
    "    with open(filename, 'r') as f:\n",
    "        size = os.fstat(f.fileno()).st_size  # 指针操作，所以无视文件大小\n",
    "        print(f'size {size}')\n",
    "        chunk_size = size // num_workers\n",
    "        offset = worker_id * chunk_size\n",
    "        end = offset + chunk_size\n",
    "        f.seek(offset)\n",
    "        print(f'offset {offset}')\n",
    "        if offset > 0:\n",
    "            safe_readline(f)    # drop first incomplete line\n",
    "        lines = []\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            line=line.strip().split(\"\\t\")\n",
    "            if len(line)==column_num:\n",
    "                lines.append(line)\n",
    "            if f.tell() > end:\n",
    "                break\n",
    "            line = f.readline()\n",
    "        return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "\n",
    "class FileHandlerThread(threading.Thread):\n",
    "\n",
    "    def __init__(self, func, args):\n",
    "        super(FileHandlerThread, self).__init__()\n",
    "        self.args = args\n",
    "        self.func = func\n",
    "        \n",
    "    def run(self):\n",
    "        self.result = self.func(*self.args)\n",
    "    \n",
    "    def get_result(self):\n",
    "        try:\n",
    "            return self.result\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    \n",
    "def encode_file_thread(path, workers=4):\n",
    "    assert os.path.exists(path)\n",
    "    results = []\n",
    "    workers_thread = []\n",
    "    for i in range(workers):\n",
    "        w = FileHandlerThread(async_kd_tokenizer, args=(path, i, workers,len(column_name)))\n",
    "        workers_thread.append(w)\n",
    "        w.start()\n",
    "    for w in workers_thread:\n",
    "        w.join()\n",
    "    for w in workers_thread:\n",
    "        result = w.get_result() \n",
    "        results.extend(result)\n",
    "    return results\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size 1085609355\n",
      "offset 135701169\n",
      "size 1085609355\n",
      "offset 0\n",
      "size 1085609355\n",
      "offset 271402338\n",
      "size 1085609355\n",
      "offset 407103507\n",
      "size 1085609355\n",
      "offset 542804676\n",
      "size 1085609355\n",
      "offset 678505845\n",
      "size 1085609355\n",
      "offset 814207014\n",
      "size 1085609355\n",
      "offset 949908183\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-95e06d03735b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults_th\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_file_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-bcdf03da2c33>\u001b[0m in \u001b[0;36mencode_file_thread\u001b[0;34m(path, workers)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworkers_thread\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworkers_thread\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_name =input_file\n",
    "\n",
    "results_th = encode_file_thread(file_name, workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
